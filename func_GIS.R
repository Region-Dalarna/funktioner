
if (!require("pacman")) install.packages("pacman")
p_load(sf,
       data.table,
       rio,
       glue,
       terra,
       openxlsx,
       mapview,
       RPostgres,
       keyring,
       httr,
       tidyverse)

source("https://raw.githubusercontent.com/Region-Dalarna/funktioner/main/func_API.R", encoding = "utf-8")
source("https://raw.githubusercontent.com/Region-Dalarna/funktioner/main/func_text.R", encoding = "utf-8")

options(scipen = 999)

# ===================================== hantera GIS i R ===============================================

kartifiera <- function(skickad_df, 
                       geom_nyckel, 
                       tatortspunkter = TRUE                   # anv√§nds bara om det √§r t√§torter, om TRUE returneras punkter, annars polygoner
){
  
  kartifiera_regionkoder <- unique(skickad_df[[geom_nyckel]])
  geom_nyckel_langd <- nchar(kartifiera_regionkoder) %>% unique()
  
  if (length(geom_nyckel_langd) > 1) {
    print("Skickad df:s geom_nyckel kan bara inneh√•lla v√§rden av samma typ. Kontrollera att s√• √§r fallet och f√∂rs√∂k igen.") 
  } else {
    
    # h√§r best√§ms vilken karttyp vi har att g√∂ra med
    if (geom_nyckel_langd == 2) kartifiera_karttyp <- "lan"
    if (geom_nyckel_langd == 4 & all(str_detect(kartifiera_regionkoder, "^[:digit:]+$"))) kartifiera_karttyp <- "kommun" 
    if (geom_nyckel_langd == 4 & !all(str_detect(kartifiera_regionkoder, "^[:digit:]+$"))) kartifiera_karttyp <- "nuts2"
    #if (geom_nyckel_langd == 9 & !all(str_detect(kartifiera_regionkoder, "^[:digit:]+$"))) kartifiera_karttyp <- "deso"
    if (geom_nyckel_langd == 9 & all(str_sub(kartifiera_regionkoder, 5, 5) %in% c("A", "B", "C"))) kartifiera_karttyp <- "deso"
    #if (geom_nyckel_langd == 8 & !all(str_detect(kartifiera_regionkoder, "^[:digit:]+$"))) kartifiera_karttyp <- "regso"
    if (geom_nyckel_langd == 8 & all(str_sub(kartifiera_regionkoder, 5, 5) %in% c("R"))) kartifiera_karttyp <- "regso"
    if (geom_nyckel_langd == 9 & all(str_sub(kartifiera_regionkoder, 5, 5) %in% c("T"))) kartifiera_karttyp <- "tatorter"
    
    if (kartifiera_karttyp == "tatorter" & tatortspunkter) kartifiera_karttyp <- "tatortspunkter"
    
    # vi h√§mtar gislagret f√∂r aktuell karttyp, f√∂r de geom_nyckelkoder som skickats med
    gis_lager <- hamta_karta(karttyp = kartifiera_karttyp, regionkoder = kartifiera_regionkoder)
    
    # h√§r l√§gger vi till rader (dvs. tabeller) som ska vara h√§mtbara fr√•n geodatabasen med hamta_karta()-funktionen
    tabell_df <- hamta_karttabell()
    
    vald_karta <- tabell_df %>%
      mutate(ord_match = map_lgl(sokord, ~ kartifiera_karttyp %in% .)) %>% 
      filter(ord_match)
    
    # om medskickade kartyp inte finns bland s√∂korden f√•r pg_tabell v√§rdet "finns ej" och d√• k√∂rs inte skriptet nedan
    if (nrow(vald_karta) == 0) pg_tab_idkol <- "finns ej" else pg_tab_idkol <- vald_karta$id_kol
    
    join_sf <- skickad_df %>% 
      left_join(gis_lager, by = setNames(pg_tab_idkol, geom_nyckel)) %>% 
      st_as_sf()
    
    return(join_sf)
  } # slut if-sats om det finns fler l√§ngder p√• geom_nyckel
}

hamta_karttabell <- function(){
  
  # h√§r l√§gger vi till nya kolumner om det beh√∂vs
  kolumn_namn <- c("namn", "id_kol", "lankol", "kommunkol", "sokord")
  
  antal_kol <- length(kolumn_namn)                            # r√§kna kolumnnamn i vektorn som vi skapar ovan
  karttabell_df <- as.data.frame(matrix(nrow = 0, ncol = antal_kol)) %>%             # skapa df med 0 rader och lika m√•nga kolumner som vi har kolumnnamn ovan
    setNames(kolumn_namn) %>%                                              # d√∂p kolumnnamn efter vektorn vi skapade ovan
    mutate(across(1:(antal_kol-1), as.character),                          # alla kolumner ska vara text, utom sista kolumnen som ska vara en lista med s√∂kord
           sokord = sokord %>% as.list())                                  # som vi initierar h√§r
  
  # h√§r l√§gger vi till rader (dvs. tabeller) som ska vara h√§mtbara fr√•n geodatabasen med hamta_karta()-funktionen
  karttabell_df <- karttabell_df %>%  
    add_row(namn = "kommun_scb", id_kol = "knkod", lankol = "lanskod_tx", kommunkol = "knkod", sokord = list(c("kommun", "kommuner", "kommunpolygoner"))) %>% 
    add_row(namn = "kommun_lm", id_kol = "kommunkod", lankol = "lankod", kommunkol = "kommunkod", sokord = list(c("kommun_lm", "kommuner_lm", "kommunpolygoner_lm"))) %>% 
    add_row(namn = "lan_scb", id_kol = "lnkod", lankol = "lnkod", kommunkol = NA, sokord = list(c("lan", "lanspolygoner"))) %>% 
    add_row(namn = "lan_lm", id_kol = "lankod", lankol = "lankod", kommunkol = NA, sokord = list(c("lan_lm", "lanspolygoner_lm"))) %>% 
    add_row(namn = "tatorter", id_kol = "tatortskod", lankol = "lan", kommunkol = "kommun", sokord = list(c("tatort", "t√§tort", "tatorter", "t√§torter", "tatortspolygoner", "t√§tortspolygoner"))) %>% 
    add_row(namn = "tatortspunkter", id_kol = "tatortskod", lankol = "lan", kommunkol = "kommun", sokord = list(c("tatortspunkter", "t√§tortspunkter"))) %>% 
    add_row(namn = "regso", id_kol = "regsokod",  lankol = "lanskod", kommunkol = "kommunkod", sokord = list(c("regso", "regsopolygoner"))) %>% 
    add_row(namn = "deso", id_kol = "deso", lankol = "lanskod", kommunkol = "kommunkod", sokord = list(c("deso", "desopolygoner"))) %>% 
    add_row(namn = "distrikt", id_kol = "distriktskod", lankol = "lankod", kommunkol = "kommunkod", sokord = list(c("distrikt"))) %>% 
    add_row(namn = "nuts2", id_kol = "id", lankol = "id", kommunkol = "cntr_code", sokord = list(c("nuts2", "nuts2-omr√•den"))) %>% 
    add_row(namn = "laregion_scb", id_kol = "lakod", lankol = "lan", kommunkol = "kommun", sokord = list(c("la", "laomraden", "la-omraden", "la-omr√•den", "la-omraden"))) %>% 
    add_row(namn = "varlden", id_kol = "Landskod", lankol = NA, kommunkol = NA, sokord = list(c("varlden", "varldskarta", "v√§rlden", "v√§rldskarta"))) %>% 
    add_row(namn = "varldsdelar", id_kol = "Landskod", lankol = NA, kommunkol = NA, sokord = list(c("varldsdelskarta", "varldsdelar", "v√§rldsdelskarta", "v√§rldsdelar")))
  
  return(karttabell_df)
}

hamta_karta <- function(karttyp = "kommuner", regionkoder = NA, tabellnamn = NA) {
  
  # h√§r l√§gger vi till rader (dvs. tabeller) som ska vara h√§mtbara fr√•n geodatabasen med hamta_karta()-funktionen
  tabell_df <- hamta_karttabell()
  
  df_rad <- suppressWarnings(str_which(tabell_df$sokord, karttyp))             # vi letar upp den rad som parametern karrtyp finns p√•
  
  # om det blir fler tr√§ffar, kolla vilken karta d√§r s√∂kordet st√§mmer helt med karttyp
  if (length(df_rad) > 0) df_rad <- df_rad[map_lgl(df_rad, ~ karttyp %in% tabell_df$sokord[[.x]])]
  
  # om medskickade kartyp inte finns bland s√∂korden f√•r pg_tabell v√§rdet "finns ej" och d√• k√∂rs inte skriptet nedan
  if (length(df_rad) == 0) pg_tabell <- "finns ej" else pg_tabell <- tabell_df$namn[df_rad] 
  
  # kontrollera om karttypen som skickats med i funktionen finns, om inte s√• k√∂rs inte skriptet nedan utan ett felmeddelande visas ist√§llet
  if (pg_tabell != "finns ej"){
    
    # skriv query utifr√•n medskickade regionkoder, om ingen √§r medskickad g√∂rs en query f√∂r att h√§mta allt
    if (all(!is.na(regionkoder)) & all(regionkoder != "00")) {
      kommunkoder <- regionkoder[nchar(regionkoder) == 4]
      if (karttyp == "nuts2") kommunkoder <- regionkoder[nchar(regionkoder) == 2]
      lanskoder <- regionkoder[nchar(regionkoder) == 2 & regionkoder != "00"]
      if (karttyp == "nuts2") lanskoder <- regionkoder[nchar(regionkoder) == 4]
    } else {
      kommunkoder <- NULL
      lanskoder <- NULL
    }
    # if (is.na(kommunkoder)) kommunkoder <- NULL
    # if (is.na(lanskoder)) lanskoder <- NULL 
    # 
    grundquery <- paste0("SELECT * FROM karta.", pg_tabell) 
    
    if ((length(kommunkoder) == 0) & (length(lanskoder) == 0)) skickad_query <- paste0(grundquery, ";") else {
      
      # det finns lan- eller kommunkoder, s√• vi l√§gger p√• ett WHERE p√• grundqueryn
      skickad_query <- paste0(grundquery, " WHERE ")
      
      # kolla om det finns l√§nskoder i regionkoder, om s√• l√§gger vi p√• l√§nskoder i queryn
      if (length(lanskoder) != 0 & !is.na(tabell_df$lankol[df_rad])) {
        skickad_query <- paste0(skickad_query, tabell_df$lankol[df_rad], " IN (", paste0("'", lanskoder, "'", collapse = ", "), ")")
      }
      
      # kolla om det finns b√•de l√§ns- och kommunkoder i regionkoder, i s√• fall l√§gger vi till ett OR mellan 
      # de b√•da IN-satserna - d√• m√•ste tabellen ha b√•de kommun- och l√§nskod
      if ((length(lanskoder) != 0 & !is.na(tabell_df$lankol[df_rad])) & (length(kommunkoder) != 0 & !is.na(tabell_df$kommunkol[df_rad]))) mellanquery <- " OR " else mellanquery <- ""
      
      if (length(kommunkoder) != 0 & !is.na(tabell_df$kommunkol[df_rad])){     # om det finns kommunkoder, l√§gg p√• det p√• tidigare query
        skickad_query <- paste0(skickad_query, mellanquery, tabell_df$kommunkol[df_rad], " IN (", paste0("'", kommunkoder, "'", collapse = ", "), ");")
      } else {                           # om det inte finns kommunkoder, avsluta med ett semikolon
        skickad_query <- paste0(skickad_query, ";") 
      }   
      
    } # slut if-sats f√∂r om regionkoder √§r medskickade, om inte s√• h√§mtas alla regioner 
    # query klar, anv√§nd inloggningsuppgifter med keyring och skicka med v√•r serveradress 
    
    retur_sf <- suppress_specific_warning(
      postgis_postgistabell_till_sf(schema = "karta",
                                    tabell = pg_tabell,
                                    query = skickad_query),
      "Invalid time zone 'UTC', falling back to local time.")
    
    return(retur_sf)
    
    
  } else {
    warning(paste0("Karttypen ", karttyp, " finns inte i databasen."))
  } # slut if-sats karttyp
  
} # slut funktion



# ========================================== hantera rutor med GIS ========================================================

sf_fran_df_med_x_y_kol <- function(skickad_df, 
                                   x_kol, 
                                   y_kol,
                                   rutstorlek = NA,              # om man vill ange sj√§lv, annars kontrolleras f√∂r det automatiskt.
                                   polygonlager = TRUE,          # polygonlager = FALSE -> punktlager
                                   vald_crs = 3006){
  
  if(is.na(rutstorlek)) rutstorlek = rutstorlek_estimera(skickad_df[[x_kol]], skickad_df[[y_kol]])
  
  
  
  retur_sf <- intern_funktion_sf_skapa_fran_df_med_rutkolumner(skickad_df = skickad_df, x_kol = x_kol, 
                                                               y_kol = y_kol, rutstorlek = rutstorlek, vald_crs = vald_crs)
  
  if (polygonlager) retur_sf <- st_buffer(retur_sf,(rutstorlek/2), endCapStyle = "SQUARE")
  
  return(retur_sf)
  
} # slut funktion



intern_funktion_sf_skapa_fran_df_med_rutkolumner <- function(skickad_df, x_kol, y_kol, rutstorlek = NA, vald_crs = 3006){
  
  if (is.na(rutstorlek)) rutstorlek <- rutstorlek_estimera(skickad_df[[x_kol]], skickad_df[[y_kol]])
  
  # skapa en punktgeometri av x- och y-kolumnerna d√§r koordinaten √§r nedre v√§nstra h√∂rnet
  retur_sf <- skickad_df %>% 
    mutate(
      across(all_of(c(x_kol, y_kol)), as.character),
      x_temp = if_else(nchar(!!sym(x_kol)) == 7 & nchar(!!sym(y_kol)) == 6, !!sym(y_kol), !!sym(x_kol)),
      y_temp = if_else(nchar(!!sym(x_kol)) == 7 & nchar(!!sym(y_kol)) == 6, !!sym(x_kol), !!sym(y_kol)),
      x_ny = as.numeric(x_temp) + as.numeric(rutstorlek)/2,
      y_ny = as.numeric(y_temp) + as.numeric(rutstorlek)/2) %>%
    st_as_sf(coords = c("x_ny", "y_ny"), crs = vald_crs) %>% 
    st_cast("POINT")
  
  return(retur_sf)
  
}


rutstorlek_estimera <- function(x, y) {
  
  # Kombinera x- och y-koordinaterna till en enda vektor
  coords <- c(x ,y) %>% as.numeric()
  
  # Kontrollera om det finns n√•got v√§rde som slutar p√• 100, 200, 300 eller 400
  if (any(coords %% 1000 %in% c(100, 200, 300, 400))) {
    return(100)
  }
  
  # Kontrollera om det finns v√§rden som slutar p√• 500 och p√• 1000
  if (any(coords %% 1000 == 500) && any(coords %% 1000 == 0)) {
    return(500)
  }
  
  # Om alla v√§rden slutar p√• 1000
  if (all(coords %% 1000 == 000)) {
    return(1000)
  }
  
  # Default, if no match is found (this case shouldn't happen given your rules)
  return(NA)
}

berakna_mittpunkter <- function(df, xruta, yruta, rutstorlek, 
                                xkolnamn = "mitt_x", ykolnamn = "mitt_y"){
  
  # Denna funktion ber√§knar mittpunkter f√∂r tv√• kolumner med x- och y-koordinater i 
  # textform, om koordinaterna √§r i nedre v√§nstra h√∂rnet (som SCB:s rutor).
  #
  # Funktionen  beh√∂ver: 
  # - en dataframe som inneh√•ller kolumner med x- och y-koordinater
  # - namn p√• x- och y-kolumnerna som text
  # - ett numeriskt v√§rde f√∂r rutstorleken
  # - namn f√∂r de nya x- och y-kolumnerna med mittpunkter, annars d√∂ps de till "mitt_x" och "mitt_y"
  #
  # Retur: en df som √§r likadan som den som skickades men med 2 nya kolumner som
  #        inneh√•ller mittpunkter f√∂r x- och y-koordinaten
  #
  
  # ber√§kna de nya kolumnerna
  df[xkolnamn] <- df[xruta]+(rutstorlek/2)
  df[ykolnamn] <- df[yruta]+(rutstorlek/2)
  # flytta de nya kolumnerna och l√§gg dem efter x- och y-kolumnerna
  df <- df %>% 
    relocate(all_of(xkolnamn), .after = all_of(yruta)) %>% 
    relocate(all_of(ykolnamn), .after = all_of(xkolnamn))
  
  return(df)
}

# ============================================ geometriska funktioner =================================================

st_largest_ring <- function(x) {
  
  # Kod h√§mtad fr√•n: https://github.com/r-spatial/sf/issues/1302#issuecomment-606473789
  # Anv√§nds av funktionen .st_centroid_within_geo nedan
  #
  #' Find largest ring of a multipolygon
  #'
  #' Assumes dealing with polygons
  #'
  #' @param x (sf object of polygons)
  #'
  #' @return (sf object) replaced with centroids
  #'
  #' @seealso sf:::largest_ring()
  #'
  
  if (nrow(x) < 1)
    return(x)
  
  seq(1, nrow(x)) %>%
    lapply(function(i){
      x[i, ] %>%
        sf::st_set_agr("identity") %>%
        sf::st_cast("POLYGON") %>%
        mutate(st_area = sf::st_area(st_geometry(.))) %>%
        top_n(1, st_area) %>%
        select(-st_area)
    }) %>%
    data.table::rbindlist() %>%
    sf::st_as_sf()
}



st_centroid_within_geo <- function(
    x
    , ensure_within = TRUE                   # tvingar centroiden att vara innanf√∂r polygonen
    , of_largest_polygon = TRUE              # s√§kerst√§ller att centroiden √§r i den st√∂rsta polygonen om det finns fler (om det √§r en multipolygon)
) {
  
  # Kod h√§mtad fr√•n: https://github.com/r-spatial/sf/issues/1302#issuecomment-606473789
  #' tar ut centroider i polygoner
  #'
  #' reference:
  #' https://stackoverflow.com/questions/52522872/r-sf-package-centroid-within-polygon
  #' https://stackoverflow.com/questions/44327994/calculate-centroid-within-inside-a-spatialpolygon
  #'
  #' @param x (sf) spatial polygon
  #' @param ensure_within (logical) TRUE to ensure point within polygon.
  #' @param of_largest_polygon (logical) TRUE to use largest polygon when
  #'   determining centroid.
  #'
  #' Will return the usual geometric centroid when \code{ensure_within} is FALSE.
  #'
  #' Otherwise the point returned will be the geometric centroid if it lies within
  #' the polygon else a point determined by st_point_on_surface.
  #'
  #' In all cases an attempt is made to observe \code{of_largest_polygon} (see
  #' sf::st_centroid()).
  #'
  #' \code{of_largest_polygon} used when determining geometric centroid.  An
  #' effort to apply this idea to sf::st_point_on_surface() routine.
  #'
  #' @return (sf) spatial object with centroids within spatial feature.
  #'
  
  cx <- sf::st_centroid(
    sf::st_set_agr(x, "identity")
    , of_largest_polygon = of_largest_polygon
  )
  
  if (ensure_within) {
    
    i_within <- sf::st_within(cx, x, sparse = TRUE) %>%
      as.data.frame() %>%
      filter(row.id == col.id) %>%
      dplyr::pull(row.id)
    
    i_nwithin <- setdiff(seq(1, nrow(x)), i_within)
    
    sf::st_geometry(cx[i_nwithin, ]) <- (
      x[i_nwithin, ] %>% {
        if (of_largest_polygon == TRUE)
          st_largest_ring(.)
        else
          .
      } %>%
        sf::st_geometry() %>%
        sf::st_point_on_surface()
    )
  }
  
  return(cx)
}

skapa_linje_langs_med_punkter <- function(skickad_sf,                   # skickad_sf = skickat sf-objekt med punkter
                                          kol_ord,                      # kol_ord = den kolumn som inneh√•ller nummer som rangordnar mellan vilka punkter som linjen ska dras, den dras i samma ordning som i denna kolumn
                                          names,                        # namn p√• punkterna om man vill ha med det (oklart om vi vill det)
                                          names_bara_startpunkt = TRUE  # om man bara vill ha namn fr√•n startpunkten, annars blir namnet "startnamn - slutnamn"
) {
  
  # skicka ett sf-objekt med punkter. En kolumn i objektet inneh√•ller en numerisk kolumn utifr√•n vilken
  # linjer dras mellan punkterna, fr√•n f√∂rsta till andra punkten, fr√•n andra till tredje punkten osv.
  # till den sista punkten. Det g√•r ocks√• att skicka med korrekt crs som ska vara samma som 
  
  skickad_sf_crs <- st_crs(skickad_sf)
  
  skickad_sf <- skickad_sf %>% arrange(!!as.symbol(kol_ord))
  
  # dataframe med ordningsf√∂ljd utifr√•n en kolumn (sorteras s√• linjer mellan punkter dras alltid i nummer ordning)
  idx <- data.frame(start = c(1:(nrow(skickad_sf)-1)),
                    end = c(2:nrow(skickad_sf))) 
  
  
  # cycle over the combinations
  for (i in seq_along(idx$start)) {
    
    # line object from two points
    
    start_punkt <- skickad_sf[idx$start[i], ] %>% st_coordinates() %>% sum()
    slut_punkt <- skickad_sf[idx$end[i], ] %>% st_coordinates() %>% sum()
    
    if (start_punkt >= slut_punkt){
      wrk_line  <- skickad_sf[c(idx$start[i], idx$end[i]), ] %>% 
        st_coordinates() %>% 
        st_linestring() %>% 
        st_sfc(crs = skickad_sf_crs)  
    } else {
      wrk_line  <- skickad_sf[c(idx$end[i], idx$start[i]), ] %>% 
        st_coordinates() %>% 
        st_linestring() %>% 
        st_sfc(crs = skickad_sf_crs)
    }
    
    # wrk_line  <- skickad_sf[c(idx$start[i], idx$end[i]), ] %>% 
    #   st_coordinates() %>% 
    #   st_linestring() %>% 
    #   st_sfc(crs = skickad_sf_crs)  
    
    
    # a single row of results dataframe
    
    # skapa etiketten, fr√•n till etikett om names_bara_startpunkt = FALSE, annars bara etikett f√∂r startpunkt
    label_varde <- ifelse(names_bara_startpunkt, pull(skickad_sf, names)[idx$start[i]], 
                          paste(pull(skickad_sf, names)[idx$start[i]], "-", pull(skickad_sf, names)[idx$end[i]]))
    
    line_data <- data.frame(
      start = pull(skickad_sf, kol_ord)[idx$start[i]],
      end = pull(skickad_sf, kol_ord)[idx$end[i]],
      label =label_varde,
      geometry = wrk_line
    )
    
    # bind results rows to a single object
    if (i == 1) {
      res <- line_data
      
    } else {
      res <- dplyr::bind_rows(res, line_data)
      
    } # /if - saving results
    
  } # /for
  
  # finalize function result
  res <- sf::st_as_sf(res, crs = skickad_sf_crs)
  
  return(res)
  
} # /function


# ============================================ l√§s in GIS-filer ==========================================================


las_gisfil_fran_zipfil_via_url <- function(skickad_url){
  
  # l√§s en gisfil som ligger i en zipfil direkt fr√•n url - packar upp 
  cur_tempfile <- tempfile()              # skapa tempor√§r fil som vi laddar ner fr√•n url
  download.file(url = skickad_url, destfile = cur_tempfile)      # ladda ner fil fr√•n url till tempfil 
  out_directory <- tempfile()             # skapa outputmapp att spara uppackad zipfil till
  unzip(cur_tempfile, exdir = out_directory)        # packa upp fil fr√•n url till outputmapp
  
  retur_sf <- st_read(out_directory) #read_sf also works here
  return(retur_sf)
  
}


las_gisfil_fran_zipfil_via_sokvag <- function(skickad_sokvag) {
  
  # l√§s en gisfil direkt fr√•n en zipfil
  out_directory <- tempfile()                  # skapa outputmapp att spara uppackad zipfil till
  unzip(skickad_sokvag, exdir = out_directory)        # packa upp fil fr√•n skickad s√∂kv√§g till outputmapp
  
  retur_sf <- st_read(out_directory) #read_sf also works here
  return(retur_sf)
  
}


unzip_zipfil_med_zipfiler <- function(skickad_url){
  
  # det h√§r √§r en specialfunktion som anv√§nds f√∂r att ladda ner polygoner f√∂r FA- och LA-regioner samt
  # l√§ns- och kommungr√§nser med kustgr√§nser (blir snyggare kartor) de ligger som zipfiler i en zipfil
  # s√• man m√•ste packa upp dessa i tv√• steg
  cur_tempfile <- tempfile()
  download.file(url = skickad_url, destfile = cur_tempfile)
  out_directory <- tempfile()
  unzip(cur_tempfile, exdir = out_directory)
  
  zipfillista <- list.files(out_directory, full.names = TRUE)
  return(zipfillista)
  
}


# =================================== Supercross-funktioner =====================================


geopackage_skapa_fran_rutor_csv_xlsx_supercross <- function(sokvag_filnamn_vekt,         # vektor med full s√∂kv√§g, dvs mapp + filnamn, kan vara flatten csv eller xlsx fr√•n Superross
                                                            byt_ut_c_mot_varde = 2.5,    # om det finns v√§rden som √§r "..C" s√• byts dessa ut mot detta v√§rde, vill man beh√•lla "..C" s√• k√∂r man NA h√§r
                                                            output_mapp = NA             # om NA, samma som indatamapp
) {
  
  # 
  #
  # Skript f√∂r att l√§sa in csv-filer med rutor fr√•n Supercross och exportera en f√§rdig geopackage-fil, d√§r rutan √§r runt mittpunkten och
  # inte i nedre v√§nstra h√∂rnet d√§r koordinaten egentligen √§r. CSV-filen sparas som flattend CSV-fil i Supercross.
  #
  # 
  
  if (!require("pacman")) install.packages("pacman")
  p_load(tidyverse,
         readxl,
         sf)
  
  walk2(sokvag_filnamn_vekt, basename(sokvag_filnamn_vekt), function(full_sokvag, filnamn) {
    
    if (str_sub(filnamn, -4) == ".csv") {
      
      # extrahera enhet (dvs. befolkning eller sysselsatta) ur csv-filen fr√•n Supercross 
      inlas_typ <- readLines(full_sokvag, n = 5, encoding = "latin1") %>% .[1]
      rut_storlek <- str_extract(inlas_typ, '(?<=\").*?(?=\")') %>% 
        str_remove("SWEREF99") %>% 
        parse_number()
      antal_enhet <- if(str_detect(tolower(filnamn), "syss")) "syss" else "bef"
      ar_txt <- parse_number(filnamn)
      
      rut_txt <- if (rut_storlek == 1000) "km" else paste0(rut_storlek, "m")
      
      # h√§r l√§ser vi in sj√§lva csv-filen
      in_df <- read_csv(full_sokvag, col_names = TRUE, show_col_types = FALSE) %>%
        select(-any_of(c("Region", "Dagbefolkning"))) %>% 
        rename(rutid = 1, !!sym(antal_enhet) := 2) %>%
        mutate(rutid = rutid %>% as.character()) %>% 
        mutate(x_koord = as.character(as.numeric(str_sub(rutid, 1,6))+(rut_storlek/2)),                           # flytta x-koordinaten halva rutstorleken f√∂r att f√• en mittpunkt i rutan
               y_koord = as.character(as.numeric(str_sub(rutid, 7,13))+(rut_storlek/2)),                            # flytta y-koordinaten halva rutstorleken f√∂r att f√• en mittpunkt i rutan
               ar = ar_txt) %>% 
        filter(!!sym(antal_enhet) > 0) %>% 
        relocate(ar, .before = 1) %>% 
        relocate(!!sym(antal_enhet), .after = last_col())
    } else if (str_sub(filnamn, -5) == ".xlsx") {
      
      inlas_typ <- read_xlsx(full_sokvag, skip = 2, n_max = 1) %>% dplyr::pull()
      rut_storlek <- inlas_typ %>% 
        str_remove("SWEREF99") %>% 
        parse_number()
      antal_enhet <- if(str_detect(tolower(filnamn), "syss")) "syss" else "bef"
      ar_txt <- parse_number(filnamn %>% str_remove(as.character(rut_storlek)))
      
      rut_txt <- if (rut_storlek == 1000) "km" else paste0(rut_storlek, "m")
      
      in_df <- read_xlsx(full_sokvag) %>% 
        rename(rutid = 1, !!sym(antal_enhet) := 2) %>%
        filter(!is.na(!!sym(antal_enhet))) %>% 
        mutate(rutid = rutid %>% as.character()) %>% 
        mutate(x_koord = as.character(as.numeric(str_sub(rutid, 1,6))+(rut_storlek/2)),                           # flytta x-koordinaten halva rutstorleken f√∂r att f√• en mittpunkt i rutan
               y_koord = as.character(as.numeric(str_sub(rutid, 7,13))+(rut_storlek/2)),                            # flytta y-koordinaten halva rutstorleken f√∂r att f√• en mittpunkt i rutan
               ar = ar_txt) %>% 
        relocate(ar, .before = 1) %>% 
        relocate(!!sym(antal_enhet), .after = last_col())
      
      if (!is.na(byt_ut_c_mot_varde)) {
        in_df <- in_df %>% 
          mutate(!!sym(antal_enhet) := if_else(as.character(!!sym(antal_enhet)) == "..C", 
                                               as.character(byt_ut_c_mot_varde), 
                                               as.character(!!sym(antal_enhet))) %>%
                   as.numeric())
      } 
      
    } else {
      stop("Filen √§r inte en csv-fil eller xlsx-fil, denna funktion fungerar bara med dessa tv√• format") 
    }
    
    if (is.na(output_mapp)) {
      utmapp <- dirname(full_sokvag)
    } else {
      utmapp <- output_mapp
    }
    
    # kontrollera att utmapp slutar med /, annars l√§gger vi till det p√• slutet
    utmapp <- if_else(str_ends(utmapp, "/"), utmapp, str_c(utmapp, "/"))
    
    gis_punkt <- st_as_sf(in_df, coords = c("x_koord", "y_koord"), crs = 3006)
    gis_export <- st_buffer(gis_punkt, (rut_storlek/2) , endCapStyle = "SQUARE")
    st_write(gis_export, paste0(utmapp, rut_txt, "rut_", antal_enhet, "_", ar_txt,  ".gpkg"), delete_dsn = TRUE)
  })
} # slut funktion



skapa_supercross_recode_fran_rutlager <- function(gis_lager,
                                                  rutid_kol = NA,      # finns en funktion f√∂r att hitta rutid-kolumnen men man kan skicka med den h√§r 
                                                  recode_kol,
                                                  databastyp,          # "Syss bel√§genhet", "Bef bel√§genhet", "Flytt bel√§genhet", "Syss relationsbel√§genhet", "Flytt relationsbel√§genhet" 
                                                  outputmapp, 
                                                  outputfilnamn,
                                                  namn_pa_recode,      # vad recoden ska heta i Supercross
                                                  rutstorlek = NA,
                                                  lanskod = "20", 
                                                  header = c("HEADER", "\tVERSION 2", "\tUNICODE", "\tESCAPE_CHAR & ITEM_BY_CODE", "END HEADER", "")) {
  
  # Rutlager till recode-fil
  # Instruktioner
  # Denna algoritm skapar en recode-fil i textformat (.txt) fr√•n ett rutlager (polygon). Nya geografiska omr√•den kan skapas av rutorna i ett rutlager och dessa omr√•den m√•ste sparas i en egen kolumn.
  # S√•ledes kr√§vs tv√• kolumner i ett polygonlager f√∂r att algoritmen ska kunna k√∂ras, en med RutID och en med de omr√•den som ska bli recodes i Supercross. N√•gra inst√§llningar beh√∂ver g√∂ras f√∂r att textrecode-filen ska fungera att ladda in i Supercross p√• Mona.
  # 
  # Inst√§llningar
  # F√∂ljande inst√§llningar m√•ste g√∂ras f√∂r att algoritmen ska kunna k√∂ras:
  #   Rutlager (polygon)
  # RutID-kolumn (i rutlagret)
  # Kolumn med omr√•den som ska g√∂ras recode p√• (i rutlagret)
  # Rutstorlek
  # Typ av databas i Supercross
  # F√∂rsta raderna i recode-filen (ska normalt sett inte √§ndras)
  # Prefix f√∂r RutID som anv√§nds i recode-filen (normalt sett l√§nskoden)
  # Utdatafil (v√§lj var den skapade recodefilen ska heta och i vilken mapp den ska sparas)
  # 
  # Output
  # Utdata fr√•n algoritmen √§r en fil med en textrecode som kan laddas upp p√• Mona genom att v√§lja sidan My Files fr√•n Monas inloggningsmeny och d√§refter Upload. N√§r filen har laddats upp kan den h√§mtas i mappen InBox i Documents p√• den egna Mona-lagringsytan. Filen kan kopieras d√§rifr√•n till valfri mapp och d√§rifr√•n laddas in i Supercross som en textrecode via knappen Load som finns i Fields-dialogrutan.
  
  
  
  # kolla om bara en kolumn heter n√•got med rut, i s√• fall √§r det rutid-kolumnen
  if (is.na(rutid_kol[1]) & sum(str_detect(tolower(names(gis_lager)), "rut")) == 1) rutid_kol <- names(gis_lager)[str_which(tolower(names(gis_lager)), "rut")]
  
  # om det inte bara √§r en kolumn som heter n√•got med "rut", v√§lj den f√∂rsta kolumnen i gis_lager som rutid-kolumn
  if (is.na(rutid_kol[1])) rutid_kol <- names(gis_lager)[1]
  
  # hitta rutstorlek genom att kontrollera tecken 11 i rutid-kolumnen. Om det √§r km-rutor √§r det bara "0" d√§r, om det √§r 500-metersrutor √§r det bara "0" eller "5" d√§r, och 
  # om det √§r 100 metersrutor kan alla siffror finnas d√§r, bland annat "1", "2", "3", "4" som inte kan finnas i √∂vriga rutor. Kan bli fel om man har v√§ldigt f√• rutor men
  # sannolikheten att det ska h√§nda √§r extremt liten, men d√• finns m√∂jligheten att skicka med ett v√§rde f√∂r rutstorlek
  if (is.na(rutstorlek)) {
    test_vekt <- gis_lager[[rutid_kol]] %>% str_sub(11,11)
    rutstorlek <- case_when(all(test_vekt == "0") ~ 1000,
                            all(test_vekt %in% c("0", "5")) ~ 500,
                            any(test_vekt %in% c("1", "2", "3", "4", "6", "7", "8", "9")) ~ 100)
  }
  
  # skapa databasvektor som fyller recodes utifr√•n vilken typ av databas vi har
  databas_vekt <- case_when(databastyp == "Syss bel√§genhet" ~ c("Rutid ", " m SWEREF99", "Personer", "kSaRutid", "_SWEREF99"),
                            databastyp == "Bef bel√§genhet" ~ c("Rutid ", " m SWEREF99", "fBBefolkning", "kBRutid", "_SWEREF99"),
                            databastyp == "Flytt bel√§genhet" ~ c("Rutid ", " m SWEREF99", "fFlyttning", "kFRutid", "_SWEREF99"),
                            databastyp == "Syss relationsbel√§genhet" ~ c("RelationsRutid ", " m SWEREF99", "Personer", "kSaRutid", "_SWEREF99"),
                            databastyp == "Flytt relationsbel√§genhet" ~ c("Rutid ", " m SWEREF99 flyttningsrelation", "fFlyttning", "kFRutid", "_SWEREF99"))
  
  # f√∂rsta recode-raden som anger var variabeln kommer ifr√•n och vilken tabell
  recode_vekt <- paste0('RECODE "', recode_kol, '" FROM "', databas_vekt[1], rutstorlek, databas_vekt[2], '" FACTTABLE "', databas_vekt[3], '"')
  
  # result-raderna, en rad f√∂r varje v√§rde i recoden
  result_vekt <- map_chr(unique(gis_lager[[recode_kol]]), ~ paste0('RESULT "', .x, '"'))
  
  # h√§r kopplas alla rutor till ett av v√§rdena ovan
  mapcode_vekt <- map2_chr(gis_lager[[rutid_kol]], gis_lager[[recode_kol]], ~ 
                             paste0('MAP CODE "', lanskod, .x, '" VALUESET "', databas_vekt[4], rutstorlek, databas_vekt[5], '" TO "', .y, '"'))
  
  # vi s√§tter ihop alla delar och l√§gger till END RECODE p√• slutet
  recodefil_vekt <- c(header, recode_vekt, result_vekt, mapcode_vekt, 'END RECODE')
  
  # sen skriver vi filen med write.table
  write.table(as.data.frame(recodefil_vekt), paste0(outputmapp, outputfilnamn), quote = FALSE, col.names = FALSE, row.names = FALSE, fileEncoding = "utf-8")
  
  # har testat med writeLines() och write_csv, men ingen av dem fungerade. writeLines blev inte i utf-8 och d√• blev det problem med √•, √§ och √∂ i Supercross
  # p√• Mona. Med write_csv s√• fick man pl√∂tsligt dubletter bland rut-id, vilket inte finns i datasetet, mycket m√§rkligt!
  #write_csv(as.data.frame(recodefil_vekt), paste0(outputmapp, outputfilnamn), escape = "none", quote = "none", col_names = FALSE)
  #writeLines(recodefil_vekt, paste0(outputmapp, outputfilnamn))
  
} # slut funktion


spatial_join_med_ovrkat <- function(gislager_grunddata, 
                                    gislager_omr,
                                    omrade_kol = "omrade",
                                    ovrig_varde = "√ñvriga omr√•den") {
  # g√∂r en spatial join
  retur_gis <- st_join(gislager_grunddata, gislager_omr)
  
  # koda de som inte √§r inom gislager_omr med v√§rde fr√•n ovrig_varde
  # retur_gis <- retur_gis %>% 
  #   mutate({{omrade_kol}} := ifelse(is.na(!!sym(omrade_kol)), ovrig_varde, !!sym(omrade_kol)))
  # 
  retur_gis <- retur_gis %>% 
    mutate(!!sym(omrade_kol) := ifelse(is.na(!!sym(omrade_kol)), ovrig_varde, !!sym(omrade_kol)))
  
  return(retur_gis)
  
} # slut funktion


skapa_sf_fran_csv_eller_excel_supercross <- function(fil_med_sokvag,               # fil som ska bearbetas, dvs. ett uttag fr√•n Supercross 
                                                     rutid_kol = NA,               # finns en funktion f√∂r att hitta rutid-kolumnen men man kan skicka med den h√§r
                                                     rutstorlek = NA,              # om man vill ange sj√§lv, annars kontrolleras f√∂r det automatiskt.
                                                     vald_crs = 3006) {
  
  # funktion f√∂r att skapa en gpkg-fil fr√•n ett uttag ur supercross d√§r rutid √§r en kolumn
  
  rut_df <- import(fil_med_sokvag)
  
  # kolla om bara en kolumn heter n√•got med rut, i s√• fall √§r det rutid-kolumnen
  if (is.na(rutid_kol[1]) & sum(str_detect(tolower(names(rut_df)), "rut")) == 1) rutid_kol <- names(rut_df)[str_which(tolower(names(rut_df)), "rut")]
  
  # om det inte bara √§r en kolumn som heter n√•got med "rut", v√§lj den f√∂rsta kolumnen i rut_df som rutid-kolumn
  if (is.na(rutid_kol[1])) rutid_kol <- names(rut_df)[1]
  
  # hitta rutstorlek genom att kontrollera tecken 11 i rutid-kolumnen. Om det √§r km-rutor √§r det bara "0" d√§r, om det √§r 500-metersrutor √§r det bara "0" eller "5" d√§r, och 
  # om det √§r 100 metersrutor kan alla siffror finnas d√§r, bland annat "1", "2", "3", "4" som inte kan finnas i √∂vriga rutor. Kan bli fel om man har v√§ldigt f√• rutor men
  # sannolikheten att det ska h√§nda √§r extremt liten, men d√• finns m√∂jligheten att skicka med ett v√§rde f√∂r rutstorlek
  if (is.na(rutstorlek)) {
    test_vekt <- rut_df[[rutid_kol]] %>% str_sub(11,11)
    rutstorlek <- case_when(all(test_vekt == "0") ~ 1000,
                            all(test_vekt %in% c("0", "5")) ~ 500,
                            any(test_vekt %in% c("1", "2", "3", "4")) ~ 100)
  }
  
  # skapa x- och y-koordinater fr√•n rutid-kolumnen, de l√§ggs i mitten av rutan ist√§llet f√∂r nedre v√§nstra h√∂rnet som utg√∂r rutid:t 
  rut_df <- rut_df %>% 
    rename(rutid = !!rutid_kol) %>% 
    mutate(x_koord = paste0(as.character(as.numeric(substr(rutid, 1,6))+(rutstorlek/2))),
           y_koord = paste0(as.character(as.numeric(substr(rutid, 7,13))+(rutstorlek/2))),
           rutid = rutid %>% as.character())
  
  rut_gis <- st_as_sf(rut_df, coords = c("x_koord", "y_koord"), crs = 3006)
  
  rut_gis_cell <- st_buffer(rut_gis,(rutstorlek/2), endCapStyle = "SQUARE")
  
  return(rut_gis_cell)
  
} # slut funktion


# ============================== postgres-funktioner (f√∂r att hantera databaser) ============================================


uppkoppling_adm <- function(databas = "geodata") {
  uppkoppling_db(service_name = "rd_geodata", db_name = databas)
}

uppkoppling_db <- function(
    
  # 0. Funktion f√∂r att koppla upp mot databasen. Kan anv√§ndas med defaultv√§rden enligt nedan eller egna parametrar.
  # Anv√§nds av andra funktioner som default om inget eget objekt med databasuppkoppling har skickats till dessa funktioner
  # OBS! √Ñndra default f√∂r db_name till "geodata" sen
  
  service_name = NA,                                 # "rd_geodata"
  db_host = "WFALMITVS526.ltdalarna.se",
  db_port = 5432,
  db_name = "geodata",                  
  db_options = "-c search_path=public",
  db_user = NA,
  db_password = NA
) {
  
  # om inte service_name har ett v√§rde s√• √§r default-v√§rdet "geodata_las"
  if (!is.na(service_name)) {
    if (is.na(db_user)) db_user <- key_list(service = service_name)$username
    if (is.na(db_password)) db_password <- key_get(service_name, key_list(service = service_name)$username)
  } else {
    if (is.na(db_user)) db_user <- "geodata_las"
    if (is.na(db_password)) db_password <- "geodata_las"
  }
  
  current_hostname <- Sys.info()[["nodename"]] 
  
  if (str_detect(toupper(db_host), toupper(current_hostname))) {
    db_host <- "localhost"
  } else {
    db_host <- if(is.na(db_host)) "WFALMITVS526.ltdalarna.se" else db_host
  }
  
  tryCatch({
    # Etablera anslutningen
    
    con <- suppress_specific_warning(
      dbConnect(          
        RPostgres::Postgres(),
        bigint = "integer",  
        user = db_user,
        password = db_password,
        host = db_host,
        port = db_port,
        dbname = db_name,
        #timezon = "UTC",
        options=db_options),
      "Invalid time zone 'UTC', falling back to local time.")
    
    
    # Returnerar anslutningen om den lyckas
    return(con)
  }, error = function(e) {
    # Skriver ut felmeddelandet och returnerar NULL
    print(paste("Ett fel intr√§ffade vid anslutning till databasen:", e$message))
    return(NULL)
  })
  
}

# funktion f√∂r att skapa en ny databas p√• servern som man arbetar i
postgres_databas_skapa <- function(con, databasnamn) {
  
  sql_create <- glue::glue("CREATE DATABASE {DBI::dbQuoteIdentifier(con, databasnamn)};")
  
  tryCatch({
    DBI::dbExecute(con, sql_create)
    message(glue::glue("‚úÖ Databasen '{databasnamn}' har skapats."))
  }, error = function(e) {
    message("‚ùå Kunde inte skapa databasen: ", e$message)
  })
}

# funktion f√∂r att ta bort en hel databas i postgres - anv√§nd med st√∂rsta f√∂rsiktighet!
postgres_databas_ta_bort <- function(con, databasnamn) {
  svar <- readline(prompt = glue::glue("‚ö†Ô∏è  √Ñr du s√§ker p√• att du vill ta bort databasen '{databasnamn}'? Skriv 'ja' f√∂r att bekr√§fta: "))
  
  if (tolower(svar) != "ja") {
    message("‚ùå √Ötg√§rden avbr√∂ts ‚Äì databasen togs inte bort.")
    return(invisible(FALSE))
  }
  
  sql_drop <- glue::glue("DROP DATABASE IF EXISTS {DBI::dbQuoteIdentifier(con, databasnamn)};")
  
  tryCatch({
    DBI::dbExecute(con, sql_drop)
    message(glue::glue("üóëÔ∏è Databasen '{databasnamn}' har tagits bort."))
  }, error = function(e) {
    message("‚ùå Kunde inte ta bort databasen: ", e$message)
  })
}


logga_event <- function(meddelande, 
                        log_file                # kan tex vara log_file <- "C:/auto_scheduler/loggfiler/logg.txt"
) {
  # funktion som loggar h√§ndelser till en loggfil
  
  # F√• den aktuella tidst√§mpeln
  timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
  
  # Skapa loggmeddelandet
  log_message <- paste(timestamp, meddelande, sep=" - ")
  
  # Skriv meddelandet till loggfilen
  cat(log_message, "\n", file = log_file, append = TRUE)
}

postgres_lista_databaser <- function(con = "default", 
                                     meddelande_tid = FALSE) {
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  databaser <- dbGetQuery(con, "SELECT datname FROM pg_database WHERE datistemplate = false;") %>% 
    rename(databas = datname)
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(databaser)
}

postgres_lista_scheman_tabeller <- function(con = "default", 
                                            visa_system_tabeller = FALSE,
                                            meddelande_tid = FALSE
) {
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  # H√§mta alla scheman i databasen
  scheman <- dbGetQuery(con, "SELECT schema_name FROM information_schema.schemata")
  
  
  if (!visa_system_tabeller) scheman <- scheman %>%
    filter(!str_detect(schema_name, "pg_"),
           !schema_name %in% c("public", "information_schema"))
  
  # Initiera en lista f√∂r att spara tabellerna f√∂r varje schema
  scheman_tabeller <- list()
  
  # Loopa igenom varje schema och h√§mta tabeller
  for (schema in scheman$schema_name) {
    tabeller <- dbGetQuery(con, sprintf(
      "SELECT table_name AS tabell_namn FROM information_schema.tables WHERE table_schema = '%s' AND (table_type IN ('BASE TABLE', 'VIEW', 'MATERIALIZED VIEW'))",
      #"SELECT table_name AS tabell_namn FROM information_schema.tables WHERE table_schema = '%s'",
      schema
    ))
    
    # L√§gg till tabellerna i listan f√∂r respektive schema
    scheman_tabeller[[schema]] <- tabeller$tabell_namn
    
    # H√§mta materialiserade vyer f√∂r respektive schema
    matviews <- dbGetQuery(con, sprintf(
      "SELECT matviewname AS tabell_namn FROM pg_matviews WHERE schemaname = '%s'",
      schema
    ))
    
    # L√§gg till materialiserade vyer till listan f√∂r respektive schema
    scheman_tabeller[[schema]] <- c(scheman_tabeller[[schema]], matviews$tabell_namn)
    
  }
  
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(scheman_tabeller)
}


postgres_lista_roller_anvandare <- function(con = "default",
                                            meddelande_tid = FALSE
) {
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  # Lista alla roller och anv√§ndare
  query <- "
    SELECT rolname, rolsuper, rolinherit, rolcreaterole, rolcreatedb, rolcanlogin
    FROM pg_roles;
  "
  
  roles_and_users <- dbGetQuery(con, query)                      # Exekvera SQL-fr√•gan och spara resultatet
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(roles_and_users)
  
} # slut funktion


postgres_lista_behorighet_till_scheman <- function(con = "default",
                                                   meddelande_tid = FALSE
) {
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  query <- "
  WITH privilege_summary AS (
    SELECT
      grantee AS role_or_user,
      table_schema,
      CASE
        WHEN STRING_AGG(privilege_type, ',') LIKE '%INSERT%' OR
             STRING_AGG(privilege_type, ',') LIKE '%UPDATE%' OR
             STRING_AGG(privilege_type, ',') LIKE '%CREATE%' OR
             STRING_AGG(privilege_type, ',') LIKE '%DELETE%' THEN 'write'
        WHEN STRING_AGG(privilege_type, ',') LIKE '%SELECT%'THEN 'read'
        ELSE 'no access'
      END AS access_type
    FROM
      information_schema.role_table_grants
    GROUP BY
      grantee, table_schema
  )
  SELECT
    role_or_user,
    table_schema,
    MAX(access_type) AS access_level
  FROM
    privilege_summary
  GROUP BY
    role_or_user, table_schema
  ORDER BY
    role_or_user, table_schema;
"
  
  
  
  
  
  
  
  # Exekvera SQL-fr√•gan och spara resultatet
  permissions_per_schema <- dbGetQuery(con, query)
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(permissions_per_schema)
  
}

postgres_lista_kolumnnamn_i_schema <- function(con = "default",
                                               schema = NA,
                                               meddelande_tid = FALSE
) {
  
  if (is.na(schema)) stop("Schema m√•ste anges")
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  kol_namn <- dbGetQuery(con, glue("
  SELECT 
    table_name,
    column_name,
    data_type
  FROM information_schema.columns
  WHERE table_schema = '{schema}'
  ORDER BY table_name, ordinal_position;
"))
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(kol_namn)
  
}

postgres_test <- function(con = "default", 
                          meddelande_tid = FALSE) {
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE  
  
  query <- "
  SELECT 
    member.rolname AS user_or_role,
    role.rolname AS inherited_role
  FROM 
    pg_auth_members m
  JOIN 
    pg_roles member ON m.member = member.oid
  JOIN 
    pg_roles role ON m.roleid = role.oid
  ORDER BY 
    member.rolname, role.rolname;
"
  # Exekvera SQL-fr√•gan och spara resultatet
  test <- dbGetQuery(con, query)
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(test)
}

# postgres_alla_rattigheter <- function(con = "default", 
#                                       meddelande_tid = FALSE
# ) {
#   
#   starttid <- Sys.time()                                        # Starta tidstagning
#   
#   # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
#   if(is.character(con) && con == "default") {
#     con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
#     default_flagga = TRUE
#   } else  default_flagga = FALSE  
#   
#   
#   query <- "
#   WITH recursive role_inheritance AS (
#     -- Start med att samla alla anv√§ndare och roller de √§r medlemmar i
#     SELECT 
#       member.oid AS user_oid,
#       member.rolname AS user_or_role,
#       role.oid AS inherited_role_oid,
#       role.rolname AS inherited_role
#     FROM 
#       pg_auth_members m
#     JOIN 
#       pg_roles member ON m.member = member.oid
#     JOIN 
#       pg_roles role ON m.roleid = role.oid
#     
#     UNION ALL
#     
#     -- Rekursivt h√§mta √§rvda roller l√§ngre upp i hierarkin
#     SELECT 
#       ri.user_oid,
#       ri.user_or_role,
#       role.oid AS inherited_role_oid,
#       role.rolname AS inherited_role
#     FROM 
#       role_inheritance ri
#     JOIN 
#       pg_auth_members m ON ri.inherited_role_oid = m.member
#     JOIN 
#       pg_roles role ON m.roleid = role.oid
#   ),
#   all_users AS (
#     SELECT oid AS user_oid, rolname AS role_or_user, rolsuper FROM pg_roles WHERE rolcanlogin = TRUE
#   ),
#   all_schemas AS (
#     SELECT schema_name 
#     FROM information_schema.schemata
#     WHERE schema_name NOT LIKE 'pg_%' AND schema_name != 'information_schema'
#   ),
#   privileges AS (
#     SELECT 
#       grantee AS role_or_user,
#       table_schema,
#       CASE
#         WHEN STRING_AGG(privilege_type, ',') LIKE '%INSERT%' OR
#              STRING_AGG(privilege_type, ',') LIKE '%UPDATE%' OR
#              STRING_AGG(privilege_type, ',') LIKE '%DELETE%' THEN 'write'
#         WHEN STRING_AGG(privilege_type, ',') LIKE '%SELECT%' THEN 'read'
#         ELSE 'no access'
#       END AS access_type
#     FROM 
#       information_schema.role_table_grants
#     GROUP BY 
#       grantee, table_schema
#   ),
#   combined_access AS (
#     SELECT 
#       u.role_or_user,
#       s.schema_name,
#       CASE
#         -- Om anv√§ndaren √§r en superanv√§ndare, ge dem skrivbeh√∂righeter till alla scheman
#         WHEN u.rolsuper THEN 'write'
#         -- Annars, h√§mta de faktiska beh√∂righeterna
#         ELSE COALESCE(p.access_type, 'no access')
#       END AS access_type
#     FROM 
#       (SELECT role_or_user, rolsuper FROM all_users UNION SELECT inherited_role AS role_or_user, FALSE AS rolsuper FROM role_inheritance) u
#     CROSS JOIN 
#       all_schemas s
#     LEFT JOIN 
#       privileges p ON u.role_or_user = p.role_or_user AND s.schema_name = p.table_schema
#   )
#   -- Eliminera dubbletter och prioritera 'write' √∂ver 'read' och 'no access'
#   SELECT role_or_user, schema_name, 
#          MAX(CASE 
#                WHEN access_type = 'write' THEN 'write'
#                WHEN access_type = 'read' THEN 'read'
#                ELSE 'no access'
#              END) AS access_level
#   FROM combined_access
#   GROUP BY role_or_user, schema_name
#   ORDER BY role_or_user, schema_name;
# "
#   
#   # Exekvera SQL-fr√•gan och spara resultatet
#   user_schema_permissions <- dbGetQuery(con, query)
#   
#   if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
#   berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
#   if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
#   
#   return(user_schema_permissions)
#   
# }


postgres_alla_rattigheter <- function(con = "default", 
                                      anvandarnamn = NULL,
                                      meddelande_tid = FALSE) {
  starttid <- Sys.time()
  
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  filter_anvandare <- if (!is.null(anvandarnamn)) glue::glue("WHERE u.role_or_user = '{anvandarnamn}'") else ""
  
  query <- glue::glue("
    WITH recursive role_inheritance AS (
      SELECT 
        member.oid AS user_oid,
        member.rolname AS user_or_role,
        role.oid AS inherited_role_oid,
        role.rolname AS inherited_role
      FROM pg_auth_members m
      JOIN pg_roles member ON m.member = member.oid
      JOIN pg_roles role ON m.roleid = role.oid
      UNION ALL
      SELECT 
        ri.user_oid,
        ri.user_or_role,
        role.oid AS inherited_role_oid,
        role.rolname AS inherited_role
      FROM role_inheritance ri
      JOIN pg_auth_members m ON ri.inherited_role_oid = m.member
      JOIN pg_roles role ON m.roleid = role.oid
    ),
    all_users AS (
      SELECT oid AS user_oid, rolname AS role_or_user, rolsuper FROM pg_roles WHERE rolcanlogin = TRUE
    ),
    all_schemas AS (
      SELECT schema_name 
      FROM information_schema.schemata
      WHERE schema_name NOT LIKE 'pg_%' AND schema_name != 'information_schema'
    ),
    privileges AS (
      SELECT 
        grantee AS role_or_user,
        table_schema,
        STRING_AGG(privilege_type, ',') AS privileges
      FROM information_schema.role_table_grants
      GROUP BY grantee, table_schema
    ),
    schema_create_privileges AS (
      SELECT 
        r.rolname AS role_or_user,
        n.nspname AS table_schema,
        'CREATE' AS privilege_type
      FROM pg_roles r
      CROSS JOIN pg_namespace n
      WHERE has_schema_privilege(r.rolname, n.nspname, 'CREATE')
    ),
    merged_privileges AS (
      SELECT * FROM privileges
      UNION ALL
      SELECT 
        role_or_user,
        table_schema,
        privilege_type AS privileges
      FROM schema_create_privileges
    ),
    access_levels AS (
      SELECT 
        role_or_user,
        table_schema,
        CASE
          WHEN STRING_AGG(privileges, ',') LIKE '%INSERT%' OR
               STRING_AGG(privileges, ',') LIKE '%UPDATE%' OR
               STRING_AGG(privileges, ',') LIKE '%DELETE%' OR
               STRING_AGG(privileges, ',') LIKE '%CREATE%' THEN 'write'
          WHEN STRING_AGG(privileges, ',') LIKE '%SELECT%' THEN 'read'
          ELSE 'no access'
        END AS access_type
      FROM merged_privileges
      GROUP BY role_or_user, table_schema
    ),
    combined_access AS (
      SELECT 
        u.role_or_user,
        s.schema_name,
        CASE
          WHEN u.rolsuper THEN 'write'
          ELSE COALESCE(p.access_type, 'no access')
        END AS access_type
      FROM 
        (SELECT role_or_user, rolsuper FROM all_users 
         UNION 
         SELECT inherited_role AS role_or_user, FALSE AS rolsuper FROM role_inheritance) u
      CROSS JOIN all_schemas s
      LEFT JOIN access_levels p ON u.role_or_user = p.role_or_user AND s.schema_name = p.table_schema
    )
    SELECT role_or_user, schema_name, 
           MAX(CASE 
                 WHEN access_type = 'write' THEN 'write'
                 WHEN access_type = 'read' THEN 'read'
                 ELSE 'no access'
               END) AS access_level
    FROM combined_access
    {filter_anvandare}
    GROUP BY role_or_user, schema_name
    ORDER BY role_or_user, schema_name;
  ")
  
  resultat <- DBI::dbGetQuery(con, query)
  
  if (default_flagga) DBI::dbDisconnect(con)
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)
  if (meddelande_tid) cat(glue::glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(resultat)
}




postgres_alla_rattigheter <- function(con = "default", 
                                      anvandarnamn = NULL,
                                      meddelande_tid = FALSE) {
  starttid <- Sys.time()
  
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  filter_anvandare <- if (!is.null(anvandarnamn)) glue::glue("WHERE u.role_or_user = '{anvandarnamn}'") else ""
  
  query <- glue::glue("
    WITH recursive role_inheritance AS (
      SELECT 
        member.oid AS user_oid,
        member.rolname AS user_or_role,
        role.oid AS inherited_role_oid,
        role.rolname AS inherited_role
      FROM pg_auth_members m
      JOIN pg_roles member ON m.member = member.oid
      JOIN pg_roles role ON m.roleid = role.oid
      UNION ALL
      SELECT 
        ri.user_oid,
        ri.user_or_role,
        role.oid AS inherited_role_oid,
        role.rolname AS inherited_role
      FROM role_inheritance ri
      JOIN pg_auth_members m ON ri.inherited_role_oid = m.member
      JOIN pg_roles role ON m.roleid = role.oid
    ),
    all_users AS (
      SELECT oid AS user_oid, rolname AS role_or_user, rolsuper FROM pg_roles WHERE rolcanlogin = TRUE
    ),
    all_schemas AS (
      SELECT schema_name 
      FROM information_schema.schemata
      WHERE schema_name NOT LIKE 'pg_%' AND schema_name != 'information_schema'
    ),
    privileges AS (
      SELECT 
        grantee AS role_or_user,
        table_schema,
        STRING_AGG(privilege_type, ',') AS privileges
      FROM information_schema.role_table_grants
      GROUP BY grantee, table_schema
    ),
    schema_create_privileges AS (
      SELECT 
        r.rolname AS role_or_user,
        n.nspname AS table_schema,
        'CREATE' AS privilege_type
      FROM pg_roles r
      CROSS JOIN pg_namespace n
      WHERE has_schema_privilege(r.rolname, n.nspname, 'CREATE')
    ),
    merged_privileges AS (
      SELECT * FROM privileges
      UNION ALL
      SELECT 
        role_or_user,
        table_schema,
        privilege_type AS privileges
      FROM schema_create_privileges
    ),
    access_levels AS (
      SELECT 
        role_or_user,
        table_schema,
        CASE
          WHEN STRING_AGG(privileges, ',') LIKE '%INSERT%' OR
               STRING_AGG(privileges, ',') LIKE '%UPDATE%' OR
               STRING_AGG(privileges, ',') LIKE '%DELETE%' OR
               STRING_AGG(privileges, ',') LIKE '%CREATE%' THEN 'write'
          WHEN STRING_AGG(privileges, ',') LIKE '%SELECT%' THEN 'read'
          ELSE 'no access'
        END AS access_type
      FROM merged_privileges
      GROUP BY role_or_user, table_schema
    ),
    combined_access AS (
      SELECT 
        u.role_or_user,
        s.schema_name,
        CASE
          WHEN u.rolsuper THEN 'write'
          ELSE COALESCE(p.access_type, 'no access')
        END AS access_type
      FROM 
        (SELECT role_or_user, rolsuper FROM all_users 
         UNION 
         SELECT inherited_role AS role_or_user, FALSE AS rolsuper FROM role_inheritance) u
      CROSS JOIN all_schemas s
      LEFT JOIN access_levels p ON u.role_or_user = p.role_or_user AND s.schema_name = p.table_schema
    )
    SELECT role_or_user, schema_name, 
           MAX(CASE 
                 WHEN access_type = 'write' THEN 'write'
                 WHEN access_type = 'read' THEN 'read'
                 ELSE 'no access'
               END) AS access_level
    FROM combined_access
    {filter_anvandare}
    GROUP BY role_or_user, schema_name
    ORDER BY role_or_user, schema_name;
  ")
  
  resultat <- DBI::dbGetQuery(con, query)
  
  if (default_flagga) DBI::dbDisconnect(con)
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)
  if (meddelande_tid) cat(glue::glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(resultat)
}






# Funktion f√∂r att l√§gga till en anv√§ndare och ge r√§ttigheter till flera databaser
postgres_anvandare_lagg_till <- function(con = "default", 
                                         anvandarnamn, 
                                         losenord,
                                         meddelande_tid = FALSE
) {
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  starttid <- Sys.time()                                        # Starta tidstagning
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  # Skapa anv√§ndaren med specifikt l√∂senord (om anv√§ndaren inte redan finns)
  skapa_anvandare_query <- paste0("CREATE USER ", anvandarnamn, " WITH PASSWORD '", losenord, "';")
  tryCatch({
    dbExecute(con, skapa_anvandare_query)
  }, error = function(e) {
    message("Anv√§ndaren finns redan eller n√•got annat fel uppstod: ", e$message)
  })
  
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
}

# Funktion f√∂r att ta bort en anv√§ndare helt fr√•n PostgreSQL-servern
postgres_anvandare_ta_bort <- function(con = "default", 
                                       anvandarnamn,
                                       meddelande_tid = FALSE
) {
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  starttid <- Sys.time()                                        # Starta tidstagning
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  # Kontrollera f√∂rst om anv√§ndaren har n√•gra beroenden (√§gare till objekt etc.)
  kontroll_query <- paste0("SELECT COUNT(*) AS antal FROM pg_authid WHERE rolname = '", anvandarnamn, "';")
  antal <- dbGetQuery(con, kontroll_query)$antal
  
  if (antal == 0) {
    message(paste("Anvandaren", anvandarnamn, "finns inte p√• servern."))
    return()
  }
  
  # Om anv√§ndaren finns, f√∂rs√∂k ta bort den
  tryCatch({
    drop_user_query <- paste0("DROP ROLE ", anvandarnamn, ";")
    dbExecute(con, drop_user_query)
    message(paste("Anvandaren", anvandarnamn, "har tagits bort fr√•n servern."))
  }, error = function(e) {
    message(paste("Ett fel uppstod vid f√∂rs√∂k att ta bort anvandaren:", anvandarnamn))
    message("Felmeddelande:", e$message)
  })
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
}


postgres_rattigheter_anvandare_lagg_till <- function(con = "default", 
                                                     anvandarnamn,
                                                     schema = "alla", 
                                                     rattigheter = c("CONNECT", "SELECT", "USAGE"),
                                                     meddelande_rattigheter = TRUE,
                                                     meddelande_tid = FALSE
){
  starttid <- Sys.time()  # Starta tidtagning
  
  # f√∂r l√§sr√§ttigheter s√• kan c("CONNECT", "SELECT", "USAGE") anv√§ndas
  # f√∂r skrivr√§ttigheter s√• kan "alla" anv√§ndas
  # √§r typ c("CONNECT", "SELECT", "USAGE", "INSERT", "UPDATE", "DELETE", "CREATE") anv√§ndas
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  # l√§gg databasnamnet i variabeln db som anv√§nds nedan
  db <- dbGetInfo(con)$dbname
  
  if (all(rattigheter == "alla")) rattigheter <- postgres_lista_giltiga_rattigheter()$Rattighet
  
  # Lista √∂ver system-scheman som ska undantas
  system_scheman <- c("pg_catalog", "information_schema", "pg_toast")
  
  
  # Steg 1: Tilldela anslutningsr√§ttigheter till den specifika databasen (CONNECT p√• databasniv√•)
  if ("CONNECT" %in% rattigheter ) {
    tilldela_atkomst_query <- paste0("GRANT CONNECT ON DATABASE ", db, " TO ", anvandarnamn, ";")
    tryCatch({
      dbExecute(con, tilldela_atkomst_query)
      if (meddelande_rattigheter) message(paste("CONNECT-r√§ttighet har lagts till f√∂r anv√§ndaren", anvandarnamn, "till databasen", db))
    }, error = function(e) {
      message(paste("Kunde inte l√§gga till CONNECT-r√§ttighet f√∂r anv√§ndaren", anvandarnamn, "i databasen", db, ":", e$message))
    })
  }
  
  scheman_att_bearbeta <- postgres_lista_scheman_tabeller(con = con) %>% names()
  if (!all(schema == "alla")) scheman_att_bearbeta <- scheman_att_bearbeta[scheman_att_bearbeta %in% schema] 
  if (length(scheman_att_bearbeta) < 1) stop(glue("Scheman {schema %>% list_komma_och()} finns inte i databasen. Kontrollera uppgifterna och f√∂rs√∂k igen."))
  
  # Steg 2: Tilldela r√§ttigheter p√• schemaniv√•
  for (schema_namn in scheman_att_bearbeta) {
    
    # Tilldela USAGE r√§ttighet till schemat
    if ("USAGE" %in% rattigheter) {
      tilldela_usage_query <- paste0("GRANT USAGE ON SCHEMA ", schema_namn, " TO ", anvandarnamn, ";")
      tryCatch({
        dbExecute(con, tilldela_usage_query)
        if (meddelande_rattigheter) message(paste("USAGE-r√§ttighet har lagts till f√∂r schemat", schema_namn, "f√∂r anv√§ndaren", anvandarnamn))
      }, error = function(e) {
        message(paste("Kunde inte l√§gga till USAGE-r√§ttighet f√∂r schemat", schema_namn, "f√∂r anv√§ndaren", anvandarnamn, ":", e$message))
      })
    }
    # Tilldela CREATE r√§ttighet till schemat
    if ("CREATE" %in% rattigheter) {
      tilldela_create_query <- paste0("GRANT CREATE ON SCHEMA ", schema_namn, " TO ", anvandarnamn, ";")
      tryCatch({
        dbExecute(con, tilldela_create_query)
        if (meddelande_rattigheter) message(paste("CREATE-r√§ttighet har lagts till f√∂r schemat", schema_namn, "f√∂r anv√§ndaren", anvandarnamn))
      }, error = function(e) {
        message(paste("Kunde inte l√§gga till CREATE-r√§ttighet f√∂r schemat", schema_namn, "f√∂r anv√§ndaren", anvandarnamn, ":", e$message))
      })
    }
    
    # h√§mta alla materialiserade vyer i det schema som hanteras
    matviews <- dbGetQuery(con, glue::glue(
      "SELECT quote_ident(nspname) || '.' || quote_ident(relname) AS full_name
   FROM pg_class
   JOIN pg_namespace ON pg_namespace.oid = pg_class.relnamespace
   WHERE relkind = 'm' AND nspname = '{schema_namn}'"
    ))
    
    # Tilldela r√§ttigheter p√• tabellniv√•
    for (rattighet in setdiff(rattigheter, c("CONNECT", "USAGE", "CREATE"))) {
      if (rattighet %in% postgres_lista_giltiga_rattigheter()$Rattighet) {
        tilldela_rattigheter_query <- paste0("GRANT ", rattighet, " ON ALL TABLES IN SCHEMA ", schema_namn, " TO ", anvandarnamn, ";")
        # R√§ttigheter f√∂r tabeller
        tryCatch({
          dbExecute(con, tilldela_rattigheter_query)
          if (meddelande_rattigheter) message(paste("R√§ttigheten", rattighet, "har lagts till f√∂r anv√§ndaren", anvandarnamn, "i schemat", schema_namn))
          
          # om det finns materialiserade vyer i schemat, l√§gg till r√§ttigheten p√• dem ocks√•
          if (nrow(matviews) > 0) {
            for (mv in matviews$full_name) {
              query_mv <- glue::glue("GRANT {rattighet} ON {mv} TO {anvandarnamn};")
              tryCatch({
                dbExecute(con, query_mv)
                if (meddelande_rattigheter) message(glue::glue("R√§ttigheten {rattighet} har lagts till f√∂r anv√§ndaren {anvandarnamn} p√• materialiserad vy {mv}"))
              }, error = function(e) {
                message(glue::glue("Kunde inte l√§gga till r√§ttigheten {rattighet} p√• materialiserad vy {mv}: {e$message}"))
              })
            }
          }
          
          
        }, error = function(e) {
          message(paste("Kunde inte l√§gga till r√§ttigheten", rattighet, "f√∂r anv√§ndaren", anvandarnamn, "i schemat", schema_namn, ":", e$message))
        })
        
      } else {
        message(paste("Ogiltig r√§ttighet:", rattighet, "- denna r√§ttighet har inte lagts till."))
      }
    }
  }
  
  if (default_flagga) dbDisconnect(con)  # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)  # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
} # slut funktion


# Funktion f√∂r att ta bort r√§ttigheter fr√•n anv√§ndare
postgres_rattigheter_anvandare_ta_bort <- function(con = "default", 
                                                   anvandarnamn,
                                                   schema = "alla",
                                                   rattigheter = "alla",
                                                   meddelande_rattigheter = TRUE,
                                                   meddelande_tid = FALSE
) {
  
  # f√∂r skrivr√§ttigheter s√• kan c("INSERT", "UPDATE", "DELETE", "CREATE") anv√§ndas
  # f√∂r l√§sr√§ttigheter s√• r√§cker det att ta bort r√§ttigheter f√∂r "CONNECT"
  starttid <- Sys.time()  # Starta tidtagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  # h√§mta giltiga r√§ttigheter och f√∂rdela per kategori
  giltiga_rattigheter <- postgres_lista_giltiga_rattigheter()$Rattighet
  rattigheter_databas <- c("CONNECT", "TEMP")
  rattigheter_tabell <- c("SELECT", "INSERT", "UPDATE", "DELETE", "TRUNCATE", "REFERENCES")     # "TRIGGER"
  rattigheter_schema <- c("USAGE", "CREATE")
  
  if (all(rattigheter == "alla")) rattigheter <- postgres_lista_giltiga_rattigheter()$Rattighet
  db <- dbGetInfo(con)$dbname
  
  
  # h√§mta scheman f√∂r vald databas (som styrs med con)
  scheman_att_bearbeta <- postgres_lista_scheman_tabeller() %>% names()
  if (!all(schema == "alla")) scheman_att_bearbeta <- scheman_att_bearbeta[scheman_att_bearbeta %in% schema] 
  if (length(scheman_att_bearbeta) < 1) stop(glue("Scheman {schema %>% list_komma_och()} finns inte i databasen. Kontrollera uppgifterna och f√∂rs√∂k igen."))
  
  # Ta bort r√§ttigheter f√∂r databasen
  databas_rattigheter <- intersect(rattigheter, rattigheter_databas)
  if (length(databas_rattigheter) > 0) {
    for (rattighet in databas_rattigheter) {
      ta_bort_atkomst_query <- glue("REVOKE {rattighet} ON DATABASE {db} FROM {anvandarnamn};")
      dbExecute(con, ta_bort_atkomst_query)
      if (meddelande_rattigheter) message(glue("R√§ttigheten {rattighet} har tagits bort fr√•n anv√§ndaren {anvandarnamn} i databasen {dbGetInfo(con)$dbname}."))
    }
  }
  
  # Ta bort andra r√§ttigheter f√∂r scheman
  schema_rattigheter <- intersect(rattigheter, rattigheter_schema)
  if (length(schema_rattigheter) > 0) {
    for (schema_loop in scheman_att_bearbeta) {
      for (rattighet in schema_rattigheter) {
        ta_bort_schema_query <- glue("REVOKE {rattighet} ON SCHEMA {schema_loop} FROM {anvandarnamn};")
        dbExecute(con, ta_bort_schema_query)
        if (meddelande_rattigheter) message(glue("R√§ttigheten {rattighet} har tagits bort fr√•n anv√§ndaren {anvandarnamn} p√• schemat {schema_loop}."))
      }
    }
  }
  
  # Ta bort r√§ttigheter f√∂r tabeller
  tabell_rattigheter <- intersect(rattigheter, rattigheter_tabell)
  if (length(tabell_rattigheter) > 0) {
    for (schema_loop in scheman_att_bearbeta) {
      for (rattighet in tabell_rattigheter) {
        ta_bort_rattigheter_query <- glue("REVOKE {rattighet} ON ALL TABLES IN SCHEMA {schema_loop} FROM {anvandarnamn};")
        dbExecute(con, ta_bort_rattigheter_query)
        if (meddelande_rattigheter) message(glue("R√§ttigheten {rattighet} har tagits bort fr√•n anv√§ndaren {anvandarnamn} i schemat {schema_loop}."))
      }
    }
  }

  if (default_flagga) dbDisconnect(con)  # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)  # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
}

# Funktion som listar r√§ttigheterna i PostgreSQL
postgres_lista_giltiga_rattigheter <- function() {
  
  postgres_giltiga_rattigheter <- c(
    "CONNECT", "SELECT", "INSERT", "UPDATE", "DELETE",
    "TRUNCATE", "REFERENCES", "USAGE", "EXECUTE",
    "CREATE", "TEMP"
  )
  
  # Skapa en dataframe med r√§ttighetsnamn och deras beskrivningar
  rattigheter_df <- data.frame(
    Rattighet = postgres_giltiga_rattigheter,
    Beskrivning = c(
      "Ger anv√§ndaren r√§ttigheten att ansluta till en specifik databas.",
      "Ger anv√§ndaren r√§ttigheten att anv√§nda SELECT-f√∂rfr√•gningar f√∂r att l√§sa fr√•n tabeller och vyer.",
      "Ger anv√§ndaren r√§ttigheten att l√§gga till nya rader i en specifik tabell.",
      "Ger anv√§ndaren r√§ttigheten att uppdatera befintliga data i en tabell eller specifika kolumner.",
      "Ger anv√§ndaren r√§ttigheten att ta bort rader fr√•n en specifik tabell.",
      "Ger anv√§ndaren r√§ttigheten att t√∂mma en tabell helt utan att utl√∂sa triggers.",
      "Ger anv√§ndaren r√§ttigheten att skapa foreign keys som refererar till kolumner i en annan tabell.",
      "Ger anv√§ndaren r√§ttigheten att anv√§nda objekt som sekvenser, scheman eller typer.",
      "Ger anv√§ndaren r√§ttigheten att k√∂ra lagrade procedurer eller funktioner i databasen.",
      "Ger anv√§ndaren r√§ttigheten att skapa nya objekt, s√•som tabeller, i ett schema.",
      "Ger anv√§ndaren r√§ttigheten att skapa tempor√§ra tabeller i databasen."
    ),
    stringsAsFactors = FALSE
  )
  
  return(rattigheter_df)
}

postgres_losenord_byt_for_anvandare <- function(con = "default", 
                                                anvandarnamn, 
                                                nytt_losenord) {
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  # SQL-fr√•ga f√∂r att √§ndra l√∂senordet
  satt_losenord_query <- paste0("ALTER ROLE ", anvandarnamn, " WITH PASSWORD '", nytt_losenord, "';")
  
  # K√∂r SQL-fr√•gan och hantera fel
  tryCatch({
    dbExecute(con, satt_losenord_query)
    message(paste("L√∂senordet har √§ndrats f√∂r anv√§ndaren", anvandarnamn))
  }, error = function(e) {
    message(paste("Kunde inte √§ndra l√∂senordet f√∂r anv√§ndaren", anvandarnamn, ":", e$message))
  })
  
  # Koppla ner anslutningen om den skapades som default
  if (default_flagga) dbDisconnect(con)
}

postgres_tabell_till_df <- function(con = "default", 
                                    schema, 
                                    tabell,
                                    query = NA,
                                    meddelande_info = FALSE,
                                    meddelande_tid = FALSE
) {
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  # SQL-fr√•ga f√∂r att l√§sa in tabellen fr√•n ett specifikt schema
  if (is.na(query)) sql_query <- paste0("SELECT * FROM ", schema, ".", tabell)
  
  # K√∂r SQL-fr√•gan och h√§mta tabellen som en dataframe
  tryCatch({
    retur_df <- dbGetQuery(con, sql_query)
    if (meddelande_info) message(paste("Tabellen", tabell, "fr√•n schemat", schema, "har l√§sts in."))
  }, error = function(e) {
    message(paste("Kunde inte l√§sa tabellen", tabell, "fr√•n schemat", schema, ":", e$message))
    retur_df <- NULL
  })
  
  # Koppla ner anslutningen om den skapades som default
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(retur_df)
}


postgres_meta <- function(tabell = "aktuell_version",
                          con = "default",
                          schema = "metadata",
                          query = NA,
                          meddelande_info = FALSE,
                          meddelande_tid = FALSE) {
  
  starttid <- Sys.time()  # Starta tidtagning
  
  # Skapa standarduppkoppling om con √§r "default"
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Funktion f√∂r standarduppkoppling till databasen
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  sql_query <- paste0("SELECT * FROM ", schema, ".", tabell)
  # Konstruera SQL-fr√•gan
  if (!is.na(query)) sql_query <- paste0(sql_query, " ", query)
  
  
  # F√∂rs√∂k l√§sa in data fr√•n databasen
  tryCatch({
    retur_df <- dbGetQuery(con, sql_query)
    if (meddelande_info) {
      message(paste("Tabellen", tabell, "fr√•n schemat", schema, "har l√§sts in."))
    }
  }, error = function(e) {
    message(paste("Kunde inte l√§sa tabellen", tabell, "fr√•n schemat", schema, ":", e$message))
    retur_df <- NULL
  })
  
  # Koppla ner om standardanslutningen anv√§ndes
  if (default_flagga) {
    dbDisconnect(con)
  }
  
  # Ber√§kna tid f√∂r processen och visa om beg√§rt
  berakningstid <- round(as.numeric(difftime(Sys.time(), starttid, units = "secs")), 1)
  if (meddelande_tid) {
    cat(glue::glue("Processen tog {berakningstid} sekunder att k√∂ra.\n"))
  }
  
  return(retur_df)
}

postgres_tabell_ta_bort <- function(con = "default", 
                                    schema, 
                                    tabell,
                                    drop_cascade = FALSE,
                                    meddelande_tid = FALSE) {
  
  starttid <- Sys.time()  # Starta tidstagning
  
  # Kombinera schema och tabellnamn
  schema_tabell <- paste0(schema, ".", tabell)
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  # Kontrollera om tabellen existerar
  tabell_finns <- dbExistsTable(con, Id(schema = schema, table = tabell))
  
  if (!tabell_finns) {
    message("Tabellen '", schema_tabell, "' existerar inte. Ingen √•tg√§rd vidtogs.")
  } else {
    # Bygg SQL-fr√•gan baserat p√• parametern drop_cascade
    sql <- paste0(
      "DROP TABLE ", 
      DBI::dbQuoteIdentifier(con, schema), ".", 
      DBI::dbQuoteIdentifier(con, tabell), 
      if (drop_cascade) " CASCADE;" else ";"
    )
    
    # Utf√∂r DROP TABLE
    dbExecute(con, sql)
    if (drop_cascade) {
      message("Tabellen '", schema_tabell, "' har tagits bort med CASCADE.")
    } else {
      message("Tabellen '", schema_tabell, "' har tagits bort.")
    }
  }
  
  # Koppla ner anslutningen om den skapades som default
  if (default_flagga) dbDisconnect(con)  # Koppla ner om defaultuppkopplingen har anv√§nts
  
  # Ber√§kna och skriv ut tids√•tg√•ng
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)
  if (meddelande_tid) cat(glue::glue("Processen tog {berakningstid} sekunder att k√∂ra"))
}

postgres_tabell_finns <- function(
    con = "default", 
    schema, 
    tabell,
    meddelande_tid = FALSE
    ) {
  
  starttid <- Sys.time()  # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  tabell_finns <- dbExistsTable(con, Id(schema = schema, table = tabell))
  
  # Koppla ner anslutningen om den skapades som default
  if (default_flagga) dbDisconnect(con)  # Koppla ner om defaultuppkopplingen har anv√§nts
  
  # Ber√§kna och skriv ut tids√•tg√•ng
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)
  if (meddelande_tid) cat(glue::glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(tabell_finns)
  
  
}



postgres_schema_finns <- function(con, 
                                  schema_namn) {
  query <- sprintf("
    SELECT EXISTS (
      SELECT 1
      FROM information_schema.schemata
      WHERE schema_name = '%s'
    ) AS schema_exists;
  ", schema_namn)
  
  result <- dbGetQuery(con, query)
  return(result$schema_exists[1])
}

postgres_schema_skapa_om_inte_finns <- function(schema_namn, 
                                                meddelande_tid = FALSE,
                                                con = "default"){
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  # k√∂r sql-kod f√∂r att skapa ett nytt schema med namn definierat ovan
  dbExecute(con, paste0("create schema if not exists ", schema_namn, ";"))
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
}

postgres_schema_ta_bort <- function(con, 
                                    schema,
                                    meddelande_tid = FALSE
) {
  
  starttid <- Sys.time()  # Starta tidstagning
  
  
  # Kontrollera om schemat existerar
  schema_finns <- postgres_schema_finns(con, schema)
  
  if (!schema_finns) {
    message("Schemat '", schema, "' existerar inte. Ingen √•tg√§rd vidtogs.")
  } else {
    # H√§mta alla tabeller i schemat
    tabeller <- dbGetQuery(con, paste0("
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = '", schema, "';"))
    
    if (nrow(tabeller) > 0) {
      # Om schemat inneh√•ller tabeller, skriv ut deras namn och avbryt borttagning
      message("Schemat '", schema, "' inneh√•ller f√∂ljande tabeller och kan inte tas bort:")
      print(tabeller)
      message("Ta bort dessa tabeller innan du f√∂rs√∂ker ta bort schemat.")
    } else {
      # Om inga tabeller finns, ta bort schemat
      sql <- paste0("DROP SCHEMA ", DBI::dbQuoteIdentifier(con, schema), ";")
      dbExecute(con, sql)
      message("Schemat '", schema, "' har tagits bort.")
    }
  }
  
  # Koppla ner anslutningen om den skapades som default
  #if (default_flagga) dbDisconnect(con)
  
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)  # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
}

postgres_metadata_uppdatera <- function(con, schema, tabell, version_datum = NA, version_tid = NA,
                                        uppdaterad_datum = Sys.Date(), uppdaterad_tid = format(Sys.time(), "%H:%M:%S"),
                                        lyckad_uppdatering, kommentar = NA) {
  
  # Funktion f√∂r att uppdatera metadata-tabellen varje g√•ng en tabell i geodatabasen
  # uppdateras
  
  # Kontrollera att schema och tabell √§r angivna
  if (missing(schema) || missing(tabell)) {
    stop("Parametrarna 'schema' och 'tabell' √§r obligatoriska. Ge dessa parametrar ett v√§rde och f√∂rs√∂k igen.")
  }
  
  # om version_datum och version_tid = NA s√• tar de samma v√§rde som uppdaterad_datum och uppdaterad_tid
  if (is.na(version_datum)) version_datum <- uppdaterad_datum
  if (is.na(version_tid)) version_tid <- uppdaterad_tid
  
  # Kontrollera om schemat och tabellen metadata.uppdateringar finns, skapa om n√∂dv√§ndigt
  query_schema_exists <- paste0(
    "SELECT EXISTS (
      SELECT 1 
      FROM information_schema.schemata 
      WHERE schema_name = 'metadata'
    );"
  )
  
  schema_exists <- dbGetQuery(con, query_schema_exists)$exists
  
  if (!schema_exists) {
    dbExecute(con, "CREATE SCHEMA IF NOT EXISTS metadata;")
  }
  
  query_table_exists <- paste0(
    "SELECT EXISTS (
      SELECT 1 
      FROM information_schema.tables 
      WHERE table_schema = 'metadata' AND table_name = 'uppdateringar'
    );"
  )
  
  table_exists <- dbGetQuery(con, query_table_exists)$exists
  
  if (!table_exists) {
    dbExecute(con, paste0(
      "CREATE TABLE metadata.uppdateringar (
        id SERIAL PRIMARY KEY,
        schema TEXT NOT NULL,
        tabell TEXT NOT NULL,
        version_datum DATE,
        version_tid TIME,
        uppdaterad_datum DATE DEFAULT CURRENT_DATE,
        uppdaterad_tid TIME DEFAULT CURRENT_TIME,
        lyckad_uppdatering BOOLEAN,
        kommentar TEXT
      );"
    ))
  }
  
  # Infoga metadata
  insert_query <- paste0(
    "INSERT INTO metadata.uppdateringar (
      id,
      schema,
      tabell,
      version_datum,
      version_tid,
      uppdaterad_datum,
      uppdaterad_tid,
      lyckad_uppdatering,
      kommentar
   ) VALUES (
      (SELECT COALESCE(MAX(id), 0) + 1 FROM metadata.uppdateringar),
      $1, $2, $3, $4, $5, $6, $7, $8
   );"
  )
  
  
  dbExecute(con, insert_query, params = list(
    schema, tabell, version_datum, version_tid,
    uppdaterad_datum, uppdaterad_tid, lyckad_uppdatering, kommentar
  ))
  
  message("Metadata har lagts till f√∂r tabellen: ", schema, ".", tabell)
}

postgres_finns_schema_tabell_kolumner <- function(con = "default",        # uppkoppling, vilken databas ansluter vi till
                                                  schema = NULL,          # vilket schema vill vi kontrollera om det finns
                                                  tabell = NULL,          # vilken tabell vill vi kontrollera om den finns
                                                  kolumner = NULL,        # vilka kolumner vill vi kontrollera om de finns, kan uteslutas
                                                  stoppa_vid_fel = TRUE   # vid TRUE returneras ingenting utan koden stoppas
) {
  
  if (is.null(schema) | is.null(tabell) | is.null(kolumner)) stop("Parametrarna schema, tabell och kolumner m√•ste anges f√∂r att funktionen ska kunna k√∂ras.")
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  # Kontrollera att schema finns
  schema_finns <- DBI::dbGetQuery(con, glue::glue("
    SELECT EXISTS (
      SELECT 1 FROM information_schema.schemata 
      WHERE schema_name = '{schema}'
    ) AS finns;
  "))$finns
  
  if (!schema_finns) {
    fel <- glue::glue("Schemat '{schema}' finns inte.")
    if (stoppa_vid_fel) stop(fel)
    return(list(allt_finns = FALSE, felmeddelande = fel))
  }
  
  # Kontrollera att tabellen finns i schemat
  tabell_finns <- DBI::dbGetQuery(con, glue::glue("
    SELECT EXISTS (
      SELECT 1 FROM information_schema.tables 
      WHERE table_schema = '{schema}' AND table_name = '{tabell}'
    ) AS finns;
  "))$finns
  
  if (!tabell_finns) {
    fel <- glue::glue("Tabellen '{tabell}' i schemat '{schema}' finns inte.")
    if (stoppa_vid_fel) stop(fel)
    return(list(allt_finns = FALSE, felmeddelande = fel))
  }
  
  # Kontrollera om angivna kolumner finns i tabellen
  if (!is.null(kolumner)) {
    kolumner_i_tabell <- DBI::dbGetQuery(con, glue::glue("
      SELECT column_name FROM information_schema.columns
      WHERE table_schema = '{schema}' AND table_name = '{tabell}'
    "))$column_name
    
    saknade_kolumner <- kolumner[!kolumner %in% kolumner_i_tabell]
    
    if (length(saknade_kolumner) > 0) {
      fel <- glue::glue(
        "Kolumn{if(length(saknade_kolumner)==1) '' else 'er'} '{paste(saknade_kolumner, collapse = \"', '\")}' i {schema}.{tabell} finns inte."
      )
      if (stoppa_vid_fel) stop(fel)
      return(list(allt_finns = FALSE, felmeddelande = fel))
    }
  }
  
  # Om allt finns
  if (stoppa_vid_fel) {
    #stop(felmeddelande, call. = FALSE)
    return(invisible(NULL))  # tekniskt on√•bar kod men g√∂r inget
  } else {
    return(list(allt_finns = TRUE, felmeddelande = NULL))  
  }
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  
} # slut funktion postgres_finns_schema_tabell_kolumner()



# ================================= postgis-funktioner ================================================

# 
postgis_installera_i_postgres_db <- function(con) {
  
  installera_postgis_query <- "CREATE EXTENSION IF NOT EXISTS postgis;"
  DBI::dbExecute(con, installera_postgis_query)
}

postgis_sf_till_postgistabell <- 
  function(con = "default",
           inlas_sf,
           schema = "karta",
           tabell,   # de tabellnamn de nya filerna ska f√• i postgis
           postgistabell_id_kol,
           postgistabell_geo_kol = NA,
           skapa_spatialt_index = TRUE,
           nytt_schema_oppet_for_geodata_las = TRUE,             # om TRUE s√• √∂ppnas l√§sr√§ttigheter f√∂r anv√§ndaren geodata_las (vilket √§r det som ska anv√§ndas om det inte finns mycket goda sk√§l att l√•ta bli)
           #postgistabell_till_crs,
           meddelande_tid = FALSE
  ) {
    # Skript f√∂r att l√§sa in ett sf-objekt till en postgistabell 
    #
    # F√∂ljande parametrar skickas med funktionen:
    # inlas_mapp = mapp i vilken tabellen finns som inneh√•ller m√•lpunkterna, m√•ste inneh√•lla kolumner
    #              f√∂r x- och y- koordinat
    # inlas_filer = en vektor med den eller de filer som ska l√§sas in, m√•ste finnas i inlas_mapp
    # tabell      = en textstr√§ng eller vektor om det finns flera filer med tabellnamnet som 
    #                    m√•lpunkterna ska ha i postgisdatabasen (b√∂r vara gemener och utan konstiga tecken)
    # schema = det schema i postgisdatabasen som m√•lpunktstabellen ska ligga under
    # postgistabell_id_kol = den kolumn som inneh√•ller ett unikt ID och g√∂rs till prim√§rnyckelkolumn, m√•ste finnas!
    # postgistabell_geo_kol = geometry-kolumnen
    
    if (all(is.na(postgistabell_geo_kol)) & skapa_spatialt_index) stop("postgistabell_geo_kol m√•ste skickas med om skapa_spatialt_index √§r satt till TRUE. Om du vill skapa en tabell utan geografi m√•ste skapa_spatialt_index s√§ttas till FALSE.")
    
    starttid <- Sys.time()                                        # Starta tidstagning
    
    # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
    if(is.character(con) && con == "default") {
      con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
      default_flagga = TRUE
    } else  default_flagga = FALSE  
    
    
    # s√§kerst√§ll att alla kolumnnamn √§r i gemener, st√§ller inte till problem i postgis d√•
    names(inlas_sf) <- tolower(names(inlas_sf))
    tabell <- tabell %>% tolower()
    
    # k√∂r sql-kod f√∂r att skapa ett nytt schema med namn definierat ovan om det inte redan finns
    schema_finns <- postgres_schema_finns(con, schema)
    
    if (!schema_finns) {
      dbExecute(con, paste0("create schema if not exists ", schema, ";"))
      
      if (nytt_schema_oppet_for_geodata_las) {
        sql_command <- sprintf("                                          # skapa sql-kommando f√∂r att √∂ppna schemat och framtida tabeller f√∂r geodata_las
        ALTER DEFAULT PRIVILEGES IN SCHEMA %s
        GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO %s;
        ", schema, "geodata_las")
        dbExecute(con, sql_command)                               # k√∂r sql-kommandot som skapats ovan
      } 
    }
    
    # Kontrollera om tabellen redan finns
    tabell_finns <- DBI::dbExistsTable(con, DBI::Id(schema = schema, table = tabell))
    
    if (tabell_finns) { 
      # T√∂m tabellen men beh√•ll struktur och beh√∂righeter
      dbExecute(con, paste0("TRUNCATE TABLE ", schema, ".", tabell, ";"))
      
      # Infoga ny data
      system.time({
        st_write(
          obj = inlas_sf,
          dsn = con,
          layer = DBI::Id(schema = schema, table = tabell),
          append = FALSE)                  # h√§r har jag √§ndrat till FALSE pga uppstod problem d√• vi ju vill skriva √∂ver och inte bara l√§gga till rader
      }) # slut system.time
      
    } else { 
      
      # Skriv data och skapa ny tabell
      system.time({
        st_write(
          obj = inlas_sf,
          dsn = con,
          layer = DBI::Id(schema = schema, table = tabell),
          append = FALSE)
      }) # slut system.time
    }
    
    # # skriv rut-lagren till postgis 
    # starttid = Sys.time()
    # st_write(obj = inlas_sf,
    #          dsn = con,
    #          Id(schema=schema, table = tabell))
    # print(paste0("Det tog ", round(difftime(Sys.time(), starttid, units = "sec"),1), " sekunder att l√§sa in ", tabell, " till postgis."))
    
    # skapa spatialt index, finns det sedan tidigare, ta bort - loopa s√• att man kan skicka fler geokolumner
    if (skapa_spatialt_index) {
      for (geokol in 1:length(postgistabell_geo_kol)) {
        dbExecute(con, paste0("DROP INDEX IF EXISTS ", schema, ".", postgistabell_geo_kol[geokol], "_idx;")) 
        dbExecute(con, paste0("CREATE INDEX ", postgistabell_geo_kol[geokol], "_idx ON ", schema, ".", tabell, " USING GIST (", postgistabell_geo_kol[geokol], ");"))
      }  
    }
    # g√∂r id_kol till id-kolumn i tabellen
    dbExecute(con, paste0("ALTER TABLE ", schema, ".", tabell, " ADD PRIMARY KEY (", postgistabell_id_kol ,");"))
    
    if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
    berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
    if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
    
  } # slut funktion

postgis_postgistabell_till_sf <- function(
    con = "default",
    schema,                 # det schema i vilken tabellen finns som man vill h√§mta
    tabell,                 # den tabell i postgisdatabasen man vill h√§mta
    query = NA,     # om man inte skickar med n√•gon query h√§mtas hela tabellen
    meddelande_tid = FALSE
){
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE 
  
  
  if (is.na(query)) query <- paste0("SELECT * FROM ", schema, ".", tabell)
  retur_sf <- st_read(con, query = query)
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
  return(retur_sf)
} # slut funktion

postgis_kopiera_tabell <- function(con = "default",
                                   schema_fran, 
                                   tabell_fran,
                                   schema_till,
                                   tabell_till,
                                   skriv_over = FALSE,       # skriver √∂ver tabell-till om den finns
                                   meddelande_tid = FALSE
) {
  
  # funktion f√∂r att kopiera en tabell i en postgisdatabas till en annan tabell
  # i samma schema eller under ett annat schema
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  # kontroll om den tabell som ska kopieras finns, annars stoppas skriptet
  if (!postgres_tabell_finns(con = con, schema = schema_fran, tabell = tabell_fran)) {
    stop(glue("Tabellen {tabell_fran} i schemat {schema_fran} finns inte, kontrollera namnet p√• schemat och tabellen och f√∂rs√∂k igen."))
  }
  
  # kollar om tabell-till redan finns, i s√• fall stannar vi skriptet om inte skriv_over √§r satt till TRUE
  if (postgres_tabell_finns(con = con, schema = schema_till, tabell = tabell_till)) {
    if (skriv_over) {
      postgres_tabell_ta_bort(con = con, schema = schema_till, tabell = tabell_till)
    } else {
      stop(glue("Tabellen {tabell_till} i schemat {schema_till} finns redan, v√§lj ett annat namn eller s√§tt skriv_over till TRUE om du vill skriva √∂ver befintlig tabell."))
    }
    
  }
  # skapa tabell som har samma struktur som den tabell vi ska kopiera
  dbExecute(con, paste0("CREATE TABLE ", schema_till, ".", tabell_till, " (LIKE ", schema_fran, ".", tabell_fran, " INCLUDING ALL);"))
  
  # fyll p√• den nya tabellen med data fr√•n tabellen vi kopierar fr√•n
  dbExecute(con, paste0("INSERT INTO ", schema_till, ".", tabell_till, " SELECT * ",  
                        "FROM ", schema_fran, ".", tabell_fran, ";"))
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
}                      

postgis_kopiera_tabell_mellan_databaser <- function(
    con_fran_databas,           # en con-uppkoppling f√∂r den databas vi kopierar tabellen fr√•n 
    con_till_databas,           # en con-uppkoppling f√∂r den databas vi kopierar tabellen till, dvs. en annan √§n con_fran_databas
    schema_fran,                # schema i den databas vi kopierar tabellen fr√•n
    tabell_fran,                # tabell i den databas vi kopierar tabellen fr√•n
    schema_till,                # schema i den databas vi kopierar tabellen till
    tabell_till,                # tabell i den databas vi kopierar tabellen till
    lagg_till_metadata_i_till_databas = FALSE,      # om TRUE s√• l√§ggs metadata till enligt standardf√∂rfarande i tilldatabasen
    meddelande_tid = FALSE      # TRUE om vi vill ha meddelande om hur l√•ng tid det tog att k√∂ra funktionen, FALSE √§r default
) {
  
  # funktion f√∂r att kopiera en tabell i en postgisdatabas till en annan tabell
  # i samma schema eller under ett annat schema
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con_fran_databas) && con_fran_databas == "default") {
    con_fran_databas <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga_input = TRUE
  } else  default_flagga_input = FALSE
  
  tryCatch({
    # 1. L√§s in tabellen (som sf-objekt om den inneh√•ller geometri)
    #input_data <- st_read(con_fran_databas, query = glue("SELECT * FROM {schema_fran}.{tabell_fran}"))
    input_data <- st_read(con_fran_databas, layer = DBI::Id(schema = schema_fran, table = tabell_fran))
    
    # 2. Skriv till den andra databasen
    st_write(dsn = con_till_databas,
             obj = input_data,
             layer = DBI::Id(schema = schema_till, table = tabell_till),
             append = FALSE)
    
    # s√§kerst√§ll att 
    srid <- st_crs(input_data)$epsg
    geom_kol <- attr(input_data, "sf_column")
    
    if (!is.na(srid) && !is.null(geom_kol)) {
      dbExecute(con_till_databas, glue(
        "SELECT UpdateGeometrySRID('{schema_till}', '{tabell_till}', '{geom_kol}', {srid});"
      ))
    }
    
    meta_frantabell <- postgres_meta(
      con = con_geodb,
      query = glue("WHERE schema = '{schema_fran}' AND tabell = '{tabell_fran}'")
    ) %>% 
      select(version_datum, version_tid, kommentar)
    
    
    if (nrow(meta_frantabell) == 0) {
    # om det inte finns n√•gon rad i metadata-tabellen
      nu <- now()
      dag <- as.integer(format(with_tz(nu, tzone = Sys.timezone()), "%d"))
      manad_ar <- tolower(format(with_tz(nu, tzone = Sys.timezone()), "%b%Y"))
      tid <- format(nu, "%H%M")
      frantabell_ver <- paste0(dag, manad_ar, "_", tid)
      
      frantabell_ver_db <- glue("{schema_fran}.{tabell_fran} ver: {frantabell_ver}")
      ver_datum <- format(nu, "%Y-%m-%d")
      ver_tid <- format(nu, "%H:%M")
    } else {
      # om det finns en rad i metadatatabellen anv√§nds den
      ver_datum <- meta_frantabell$version_datum
      ver_tid <- meta_frantabell$version_tid
      frantabell_ver_db <- meta_frantabell$kommentar
    }
    lyckad_uppdatering <- TRUE
    
  }, error = function(e) {
    # Skriv ett felmeddelande om n√•got g√•r fel
    frantabell_ver_db <- glue("{e$message}")
    lyckad_uppdatering <- FALSE
    
  }, finally = {
    # kod som k√∂rs oavsett om skriptet fungerade att k√∂ra eller inte
    # h√§mta metadata f√∂r fran-tabellen
    
    postgres_metadata_uppdatera(
      con = con_till_databas,
      schema = schema_till,
      tabell = tabell_till,
      version_datum = ver_datum,
      version_tid = ver_tid,
      lyckad_uppdatering = lyckad_uppdatering,
      kommentar = frantabell_ver_db
    )
  }) # slut finally och tryCatch()
  
  if(default_flagga_input) dbDisconnect(con_fran_databas)                                        # Koppla ner om defaultuppkopplingen har anv√§nts
  #dbDisconnect(con_till_databas)                                        
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
}


postgis_flytta_tabell <- function(con = "default",
                                  schema_fran,
                                  tabell_fran,
                                  schema_till,
                                  meddelande_tid = FALSE
) {
  
  # funktion f√∂r att flytta en tabell fr√•n ett schema till ett annat
  
  starttid <- Sys.time()                                        # Starta tidstagning
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if(is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga = TRUE
  } else  default_flagga = FALSE
  
  # byt schema f√∂r en tabell
  dbExecute(con_flytt, paste0("ALTER TABLE ", schema_fran, ".", tabell_fran, " SET SCHEMA ", schema_till, ";"))
  
  if(default_flagga) dbDisconnect(con)                                                    # Koppla ner om defaultuppkopplingen har anv√§nts
  berakningstid <- as.numeric(Sys.time() - starttid, units = "secs") %>% round(1)         # Ber√§kna och skriv ut tids√•tg√•ng
  if (meddelande_tid) cat(glue("Processen tog {berakningstid} sekunder att k√∂ra"))
  
}

postgis_aktivera_i_postgres_db <- function(con = "default") {
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_db()  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  # SQL-fr√•ga f√∂r att aktivera PostGIS
  aktivera_postgis_query <- "CREATE EXTENSION IF NOT EXISTS postgis;"
  
  # K√∂r SQL-fr√•gan och hantera fel
  tryCatch({
    dbExecute(con, aktivera_postgis_query)
    message("PostGIS-till√§gget har aktiverats i databasen.")
  }, error = function(e) {
    message("Kunde inte aktivera PostGIS-till√§gget:", e$message)
  })
  
  # Koppla ner anslutningen om den skapades som default
  if (default_flagga) dbDisconnect(con)
}

postgis_isokroner_bil <- function(
    punkter_sf = NULL,
    schema_punkt = NULL,             # tex "punktlager",
    tabell_punkt = NULL,             # tex "akutmottagningar",
    idkol_punkt = "id",
    nodkolumn_punkt = "nid_nvdb_bil_adresser",    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = "namn",
    intervall_varden = c(15, 30, 45, 60),
    spara_schema = NULL,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = NULL,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = TRUE,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = TRUE   # TRUE s√• returneras polygoner utan √∂verlappning, annars t√§cker de st√∂rre polygonerna √§ven ytan f√∂r de mindre polygonerna, med TRUE blir det som "ringar"
    
) {
  retur_sf <- postgis_isokroner_skapa(
    punkter_sf = punkter_sf,
    schema_punkt = schema_punkt,             
    tabell_punkt = tabell_punkt,
    idkol_punkt = idkol_punkt,
    nodkolumn_punkt = nodkolumn_punkt,    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = namnkol_punkt,
    tabell_graf = "nvdb_bil_adresser",
    idkol_graf = "rad_id",
    kostnadskol_graf_f = "kostnad_bil_f_min",
    kostnadskol_graf_b = "kostnad_bil_b_min",
    intervall_varden = intervall_varden,
    kostnad_enhet = "auto",
    spara_schema = spara_schema,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = spara_tabell,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = returnera_sf,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = dela_upp_polygoner   
  )
  
} # slut funktion isokron_bil

postgis_isokroner_meter <- function(
    punkter_sf = NULL,
    schema_punkt = NULL,             # tex "punktlager",
    tabell_punkt = NULL,             # tex "akutmottagningar",
    idkol_punkt = "id",
    nodkolumn_punkt = "nid_nvdb_alla_adresser",    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = "namn",
    intervall_varden = c(1000, 5000, 10000, 20000),
    spara_schema = NULL,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = NULL,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = TRUE,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = TRUE   # TRUE s√• returneras polygoner utan √∂verlappning, annars t√§cker de st√∂rre polygonerna √§ven ytan f√∂r de mindre polygonerna, med TRUE blir det som "ringar"
    
) {
  retur_sf <- postgis_isokroner_skapa(
    punkter_sf = punkter_sf,
    schema_punkt = schema_punkt,             
    tabell_punkt = tabell_punkt,
    idkol_punkt = idkol_punkt,
    nodkolumn_punkt = nodkolumn_punkt,    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = namnkol_punkt,
    tabell_graf = "nvdb_alla_adresser",
    idkol_graf = "rad_id",
    kostnadskol_graf_f = "kostnad_meter",
    kostnadskol_graf_b = NULL,
    intervall_varden = intervall_varden,
    kostnad_enhet = "auto",
    spara_schema = spara_schema,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = spara_tabell,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = returnera_sf,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = dela_upp_polygoner   
  )
  
} # slut funktion isokron_meter

postgis_isokroner_gang <- function(
    punkter_sf = NULL,
    schema_punkt = NULL,             # tex "punktlager",
    tabell_punkt = NULL,             # tex "akutmottagningar",
    idkol_punkt = "id",
    nodkolumn_punkt = "nid_nvdb_alla_adresser",    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = "namn",
    intervall_varden = c(15, 30, 45, 60),
    spara_schema = NULL,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = NULL,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = TRUE,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = TRUE   # TRUE s√• returneras polygoner utan √∂verlappning, annars t√§cker de st√∂rre polygonerna √§ven ytan f√∂r de mindre polygonerna, med TRUE blir det som "ringar"
    
) {
  retur_sf <- postgis_isokroner_skapa(
    punkter_sf = punkter_sf,
    schema_punkt = schema_punkt,             
    tabell_punkt = tabell_punkt,
    idkol_punkt = idkol_punkt,
    nodkolumn_punkt = nodkolumn_punkt,    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = namnkol_punkt,
    tabell_graf = "nvdb_alla_adresser",
    idkol_graf = "rad_id",
    kostnadskol_graf_f = "kostnad_gang_min",
    kostnadskol_graf_b = NULL,
    intervall_varden = intervall_varden,
    kostnad_enhet = "auto",
    spara_schema = spara_schema,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = spara_tabell,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = returnera_sf,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = dela_upp_polygoner   
  )
  
} # slut funktion isokron_gang

postgis_isokroner_cykel <- function(
    punkter_sf = NULL,
    schema_punkt = NULL,             # tex "punktlager",
    tabell_punkt = NULL,             # tex "akutmottagningar",
    idkol_punkt = "id",
    nodkolumn_punkt = "nid_nvdb_alla_adresser",    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = "namn",
    intervall_varden = c(15, 30, 45, 60),
    spara_schema = NULL,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = NULL,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = TRUE,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = TRUE   # TRUE s√• returneras polygoner utan √∂verlappning, annars t√§cker de st√∂rre polygonerna √§ven ytan f√∂r de mindre polygonerna, med TRUE blir det som "ringar"
    
) {
  retur_sf <- postgis_isokroner_skapa(
    punkter_sf = punkter_sf,
    schema_punkt = schema_punkt,             
    tabell_punkt = tabell_punkt,
    idkol_punkt = idkol_punkt,
    nodkolumn_punkt = nodkolumn_punkt,    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = namnkol_punkt,
    tabell_graf = "nvdb_alla_adresser",
    idkol_graf = "rad_id",
    kostnadskol_graf_f = "kostnad_cykel_min",
    kostnadskol_graf_b = NULL,
    intervall_varden = intervall_varden,
    kostnad_enhet = "auto",
    spara_schema = spara_schema,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = spara_tabell,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = returnera_sf,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = dela_upp_polygoner   
  )
  
} # slut funktion isokron_cykel

postgis_isokroner_elcykel <- function(
    punkter_sf = NULL,
    schema_punkt = NULL,             # tex "punktlager",
    tabell_punkt = NULL,             # tex "akutmottagningar",
    idkol_punkt = "id",
    nodkolumn_punkt = "nid_nvdb_alla_adresser",    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = "namn",
    intervall_varden = c(15, 30, 45, 60),
    spara_schema = NULL,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = NULL,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = TRUE,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = TRUE   # TRUE s√• returneras polygoner utan √∂verlappning, annars t√§cker de st√∂rre polygonerna √§ven ytan f√∂r de mindre polygonerna, med TRUE blir det som "ringar"
    
) {
  retur_sf <- postgis_isokroner_skapa(
    punkter_sf = punkter_sf,
    schema_punkt = schema_punkt,             
    tabell_punkt = tabell_punkt,
    idkol_punkt = idkol_punkt,
    nodkolumn_punkt = nodkolumn_punkt,    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = namnkol_punkt,
    tabell_graf = "nvdb_alla_adresser",
    idkol_graf = "rad_id",
    kostnadskol_graf_f = "kostnad_elcykel_min",
    kostnadskol_graf_b = NULL,
    intervall_varden = intervall_varden,
    kostnad_enhet = "auto",
    spara_schema = spara_schema,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = spara_tabell,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = returnera_sf,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = dela_upp_polygoner   
  )
  
} # slut funktion isokron_elcykel

postgis_isokroner_skapa <- function(
    con = "default",
    punkter_sf = NULL,               # om man vill skicka med ett sf-objekt ist√§llet f√∂r en punkttabell i postgis
    schema_punkt = NULL,             # tex "punktlager",
    tabell_punkt = NULL,             # tex "akutmottagningar",
    idkol_punkt = "id",
    nodkolumn_punkt = "nid_nvdb_alla_adresser",    # NULL, eller om man har ett punktlager som redan √§r kopplat till en graf kan kolumnen f√∂r noderna l√§ggas till h√§r
    namnkol_punkt = "namn",
    schema_graf = "grafer",
    tabell_graf = "nvdb_alla_adresser",
    idkol_graf = "rad_id",
    kostnadskol_graf_f = "kostnad_meter",
    kostnadskol_graf_b = NULL,
    intervall_varden = c(5000, 10000, 20000, 30000),
    kostnad_enhet = "auto",     # avg√∂rs av om "meter", "min" etc. ing√•r i kostnadskol_graf_f
    spara_schema = NULL,        # om man vill spara i databasen, ange schema h√§r
    spara_tabell = NULL,        # om man vill spara i databasen, ange tabell h√§r
    returnera_sf = TRUE,        # om man vill returnera ett sf-objekt
    dela_upp_polygoner = TRUE,  # TRUE s√• returneras polygoner utan √∂verlappning, annars t√§cker de st√∂rre polygonerna √§ven ytan f√∂r de mindre polygonerna, med TRUE blir det som "ringar"
    polygon_metod = "concave",  # eller "buffer", "convex"
    buffer_m = 100,             # s√§tter en buffer p√• v√§gar n√§r man vill bygga polygonerna runt v√§garna (l√•ngsammare √§n convex hull och concave hull)
    simplify_tol = 100,         # f√∂r att f√∂renkla polygoner ju h√∂gre desto mer f√∂renkling, n√§ra 0 n√§stan ingen f√∂renkling, anv√§nds bara i buffer-metoden
    visa_meddelanden = FALSE,   # om man vill se vad som g√∂rs i postgis, oftast vill man inte det
    felsokning_meddelanden = FALSE    # f√∂r att se vad som h√§nder i fels√∂kning
) {
  # man m√•ste ha skickat med ett sf-objekt eller en tabell i den databas man jobbar i
  stopifnot(!is.null(punkter_sf) || (!is.null(schema_punkt) && !is.null(tabell_punkt)))
  # man m√•ste returnera ett sf-objekt eller spara i den databas man jobbar i
  stopifnot(returnera_sf || (!is.null(spara_schema) && !is.null(spara_tabell)))
  
  # Kontrollera om anslutningen √§r en teckenstr√§ng och skapa uppkoppling om s√• √§r fallet
  if (is.character(con) && con == "default") {
    con <- uppkoppling_adm("ruttanalyser")  # Anropa funktionen f√∂r att koppla upp mot db med defaultv√§rden
    default_flagga <- TRUE
  } else {
    default_flagga <- FALSE
  }
  
  # st√§ng av meddelanden om visa_meddelanden = FALSE
  if (!visa_meddelanden) DBI::dbExecute(con, "SET client_min_messages TO warning;")
  
  if (is.null(kostnadskol_graf_b)) kostnadskol_graf_b <- kostnadskol_graf_f
  
  # skriv punkter_sf till ett tempor√§r tabell i postgis eller anv√§nd den som skickats med
  if (!is.null(punkter_sf)) {
    postgres_schema_skapa_om_inte_finns(con = con, schema_namn = "temp")
    sf::st_write(punkter_sf, con, DBI::Id(schema = "temp", table = "franpunkter"), delete_layer = TRUE)
    temptabell <- "temp.franpunkter"
    schema_punkt <- "temp"
    tabell_punkt <- "franpunkter"
  } else {
    temptabell <- paste0(schema_punkt, ".", tabell_punkt)
  }
  
  # kontrollera om namnkolumn finns
  namnkolumn_finns <- postgres_lista_kolumnnamn_i_schema(con = con, schema = schema_punkt) %>% 
    filter(table_name == tabell_punkt,
           column_name == namnkol_punkt) %>% 
    nrow > 0
  
  namnkol_punkt_sql <- if (namnkolumn_finns) paste0(', "', namnkol_punkt, '"') else ""
  
  if (!is.null(nodkolumn_punkt)) {
    nodkolumn_finns <- postgres_lista_kolumnnamn_i_schema(con = con, schema = schema_punkt) %>% 
      filter(table_name == tabell_punkt,
             column_name == nodkolumn_punkt) %>% 
      nrow > 0
  } else nodkolumn_finns <- FALSE
  
  if (!nodkolumn_finns) {
    DBI::dbExecute(con, glue::glue("
    ALTER TABLE {temptabell}
    ADD COLUMN IF NOT EXISTS toponode INTEGER;"))
    
    DBI::dbExecute(con, glue::glue("
    UPDATE {temptabell} p
    SET toponode = g.target
    FROM (
      SELECT p.id,
             g.target
      FROM {temptabell} p
      JOIN LATERAL (
        SELECT target
        FROM {schema_graf}.{tabell_graf}
        ORDER BY p.geom <-> geom
        LIMIT 1
      ) g ON true
    ) AS g
    WHERE p.id = g.id;
  "))
    nodkolumn_punkt <- "toponode"
  } 
  
  if (felsokning_meddelanden) {
    cat("üß™ Kontroll: Finns kolumnen", nodkolumn_punkt, "i", temptabell, "?\n")
    print(DBI::dbReadTable(con, DBI::Id(schema = "temp", table = "franpunkter")))
  }
  # Ta bort den tempor√§ra tabellen om den redan finns
  DBI::dbExecute(con, "DROP TABLE IF EXISTS noder_start")
  DBI::dbExecute(con, glue::glue("
    CREATE TEMP TABLE noder_start AS
    SELECT {idkol_punkt}{namnkol_punkt_sql}, {nodkolumn_punkt} AS node
    FROM {temptabell}
    WHERE {nodkolumn_punkt} IS NOT NULL;
  "))
  
  # stanna om inte noder_start skapas
  stopifnot("noder_start" %in% DBI::dbListTables(con))
  
  # ordna intervallerna
  from_vals <- c(0, head(intervall_varden, -1) + 1)
  to_vals   <- intervall_varden
  max_cost <- max(intervall_varden)
  
  if (tolower(kostnad_enhet) == "auto") {
    kostnad_enhet <- case_when(
      str_detect(kostnadskol_graf_f, "meter") ~ " meter",
      str_detect(kostnadskol_graf_f, "min") ~ " minuter",
      str_detect(kostnadskol_graf_f, "sek") ~ " sekunder",
      str_detect(kostnadskol_graf_f, "tim") ~ " timmar",
      TRUE ~ ""
    ) # slut case_when
  } else kostnad_enhet <- ""
  
  # Skapa CASE WHEN-uttryck som SQL-s√§ker str√§ng
  case_when_uttryck <- paste0(
    "CASE\n",
    glue::glue_collapse(
      glue::glue("  WHEN d.agg_cost <= {to} THEN '{from}‚Äì{to}{kostnad_enhet}'",
                 from = from_vals, to = to_vals),
      sep = "\n"
    ),
    glue::glue("\n  ELSE '> {max(intervall_varden) }'\nEND AS kostnadsintervall")
  )
  
  # L√§s in punkternas ID och nod
  noder <- DBI::dbReadTable(con, "noder_start")
  if (felsokning_meddelanden) {
    cat("Noder: \n")
    print(noder)
  } 
  
  sql_per_punkt <- purrr::map_chr(noder[[idkol_punkt]], function(pid) {
    node <- noder$node[noder[[idkol_punkt]] == pid]
    glue::glue("
    SELECT {pid} AS punkt_id, d.*, {case_when_uttryck}, e.*
    FROM pgr_drivingDistance(
      'SELECT {idkol_graf} AS id, source, target,
        CASE 
          WHEN {kostnadskol_graf_f} IS NOT NULL THEN {kostnadskol_graf_f} 
          ELSE -1 
          END AS cost,
          CASE 
          WHEN {kostnadskol_graf_b} IS NOT NULL THEN {kostnadskol_graf_b} 
          ELSE -1 
          END AS reverse_cost 
       FROM {schema_graf}.{tabell_graf}',
      {node}, {max_cost}
    ) d
    JOIN {schema_graf}.{tabell_graf} e ON d.edge = e.{idkol_graf}
  ")
  })
  
  # Kombinera till en fullst√§ndig SQL-str√§ng
  sql_union <- glue::glue_collapse(sql_per_punkt, sep = "\nUNION ALL\n")
  
  # Ta bort den tempor√§ra tabellen om den redan finns
  DBI::dbExecute(con, "DROP TABLE IF EXISTS isokron_edges")
  # Skapa tempor√§r tabell med alla rutter
  DBI::dbExecute(con, glue::glue("
  CREATE TEMP TABLE isokron_edges AS
  {sql_union}
"))
  if (felsokning_meddelanden) {
    DBI::dbGetQuery(con, "SELECT COUNT(*) FROM isokron_edges")
    DBI::dbGetQuery(con, "SELECT punkt_id, kostnadsintervall, ST_AsText(geom) FROM isokron_edges LIMIT 5")
    cat(sql_union)
  } 
  
  # Ta bort den tempor√§ra tabellen om den redan finns
  DBI::dbExecute(con, "DROP TABLE IF EXISTS isokron_polygons")
  if (polygon_metod == "concave") {
    DBI::dbExecute(con, glue::glue("
      CREATE TEMP TABLE isokron_polygons AS
      SELECT punkt_id{namnkol_punkt_sql},
             e.kostnadsintervall,
             ST_ConcaveHull(ST_Collect(geom), 0.5) AS geom
      FROM isokron_edges AS e
      LEFT JOIN noder_start n ON e.punkt_id = n.id
      GROUP BY punkt_id{namnkol_punkt_sql}, e.kostnadsintervall;"))
  } else if (polygon_metod == "buffer") {
    DBI::dbExecute(con, glue::glue("
      CREATE TEMP TABLE isokron_polygons AS
      SELECT punkt_id{namnkol_punkt_sql},
             kostnadsintervall,
             ST_Buffer(ST_Union(ST_Simplify(geom, {simplify_tol})), {buffer_m}) AS geom
      FROM isokron_edges AS e
      LEFT JOIN noder_start n ON e.punkt_id = n.id
      GROUP BY punkt_id{namnkol_punkt_sql}, kostnadsintervall
    "))
    # gamla: ST_Simplify(ST_Buffer(ST_Union(geom), {buffer_m}), {simplify_tol}) AS geom
  } else if (polygon_metod == "convex") {
    DBI::dbExecute(con, glue::glue("
      CREATE TEMP TABLE isokron_polygons AS
      SELECT punkt_id{namnkol_punkt_sql},
             kostnadsintervall,
             ST_ConvexHull(ST_Collect(geom)) AS geom
      FROM isokron_edges AS e
      LEFT JOIN noder_start n ON e.punkt_id = n.id
      GROUP BY punkt_id{namnkol_punkt_sql}, kostnadsintervall;"))
  }
  
  # efterbearbetning n√§r man k√∂r med buffer-metoden
  # 1. L√§s in polygonerna
  iso_polys <- st_read(con, query = "SELECT * FROM isokron_polygons") 
  iso_polys <- iso_polys %>% 
    mutate(kostnadsintervall = factor(kostnadsintervall, levels = iso_polys$kostnadsintervall %>%
                                        unique() %>%
                                        stringr::str_extract("^\\d+") %>%     # extrahera startv√§rdet
                                        as.numeric() %>%
                                        order() %>%
                                        {\(i) unique(iso_polys$kostnadsintervall)[i]}()
    )) %>%
    arrange(punkt_id, desc(kostnadsintervall))
  
  # f√∂r testning
  #dark_greens <- colorRampPalette(tail(RColorBrewer::brewer.pal(9, "Greens"), 5))(length(unique(iso_polys$kostnadsintervall)))
  #mapview(iso_polys, zcol = "kostnadsintervall", col.regions = rev(dark_greens))
  
  if (dela_upp_polygoner) {
    iso_polys <- postgis_isokroner_dela_upp_polygoner(
      skickad_sf = iso_polys,
      kategori_kol = "kostnadsintervall",
      isoid_kol = "punkt_id",
      geom_kol = "geom"
    )
  }
  
  if (!is.null(spara_schema) && !is.null(spara_tabell)) {
    sf::st_write(
      iso_polys,
      dsn = con,
      layer = DBI::Id(schema = spara_schema, table = spara_tabell),
      delete_layer = TRUE
    )
  }
  
  # ta bort temptabell och tempschema om de finns
  if (postgres_schema_finns(con = con, schema_namn = "temp")) {
    suppressMessages(postgres_tabell_ta_bort(con = con, schema = "temp", tabell = "franpunkter"))
    suppressMessages(postgres_schema_ta_bort(con = con, schema = "temp"))
  }
  # √•terst√§ll s√• att postgis skickar meddelanden igen
  if (!visa_meddelanden) DBI::dbExecute(con, "SET client_min_messages TO notice;")
  if(default_flagga) dbDisconnect(con)
  
  if (returnera_sf) {
    return(iso_polys)
  } else {
    return(invisible(NULL))
  }
} # slut funktion


postgis_isokroner_dela_upp_polygoner <- function(
    skickad_sf,            # sf-objekt med isokroner som ska delas upp s√• ingen √∂verlappar
    kategori_kol,          # kolumn med kategorier f√∂r isokronerna
    isoid_kol,             # kolumn med id-nummer f√∂r isokroner utfall att det finns flera
    geom_kol               # kolumn som inneh√•ller geometri
) {
  
  # Sortera intervallen i r√§tt ordning (viktigt!)
  nivaa_ordning <- sort(unique(skickad_sf[[kategori_kol]]))
  
  # Unionera per punkt_id och intervall (om inte redan gjort)
  iso_union <- skickad_sf %>%
    group_by(across(everything())) %>% 
    #group_by(across(all_of(c(isoid_kol, kategori_kol)))) %>%
    summarise(!!geom_kol := st_union(.data[[geom_kol]]), .groups = "drop")
  
  # Initiera resultat
  iso_utan_overlapp <- list()
  
  # Loop per niv√•
  for (i in seq_along(nivaa_ordning)) {
    aktuell_niva <- nivaa_ordning[i]
    
    aktuella <- iso_union %>% 
      filter(.data[[kategori_kol]] == aktuell_niva)
    
    if (i == 1) {
      iso_utan_overlapp[[i]] <- aktuella
    } else {
      tidigare <- bind_rows(iso_utan_overlapp[1:(i - 1)])
      
      # Klipp bort √∂verlappningar punkt f√∂r punkt
      klippt <- map_dfr(unique(aktuella[[isoid_kol]]), function(pid) {
        denna <- aktuella %>% 
          filter(.data[[isoid_kol]] == pid)
        tidigare_pid <- tidigare %>% 
          filter(.data[[isoid_kol]] == pid)
        
        if (nrow(tidigare_pid) == 0) return(denna)
        
        union_tidigare <- st_union(tidigare_pid[[geom_kol]])
        denna[[geom_kol]] <- st_difference(denna[[geom_kol]], union_tidigare)
        denna
      })
      
      iso_utan_overlapp[[i]] <- klippt
    }
  }
  
  # Sl√• ihop till ett sf-objekt
  iso_unik_sf <- bind_rows(iso_utan_overlapp)
  return(iso_unik_sf)
}

postgis_kopiera_punkttabell_koppla_till_pgr_graf <- function(
    con_fran_databas = uppkoppling_db(),                   # databas fr√•n vilket punktlagret kopieras, default √§r geodatabasen
    con_till_databas = uppkoppling_adm("ruttanalyser"),    # databas till vilket punktlagret kopieras, default √§r ruttanalyser
    schema_fran,                     # schema i geodatabasen d√§r adresserna finns
    tabell_fran,                     # tabell i geodatabasen d√§r adresserna finns
    schema_till,                     # schema i ruttanalyser-databasen d√§r adresserna ska kopieras till
    tabell_till,                     # tabell i ruttanalyser-databasen d√§r adresserna ska kopieras till
    geom_kol_punkter = "geom",             # geometri-kolumnen i punkttabellen som ska kopieras, default √§r geom
    id_kol_punkter = "id",             # id-kolumnen i punkttabellen, default √§r id
    schema_natverk = "grafer",             # schema d√§r grafen finns, ska normalt inte √§ndras
    lagg_till_metadata_i_till_databas = TRUE,        # punkttabellen l√§ggs till i 
    stang_db_anslutningar = TRUE
) {
  
  # om man har en punkttabell i en databas som man vill kopiera till ruttanalyser och koppla till befintliga grafer
  # s√• kan man k√∂ra denna funktion
  
  # f√∂rst kopierar vi tabellen fr√•n en databas till en annan
  postgis_kopiera_tabell_mellan_databaser(
    con_fran_databas = con_fran_databas,                # fr√•n geodatabasen
    con_till_databas = con_till_databas,                 # till ruttanalyser-databasen
    schema_fran = schema_fran,                    # schema i geodatabasen d√§r adresserna finns
    tabell_fran = tabell_fran,                     # tabell i geodatabasen d√§r adresserna finns
    schema_till = schema_till,                  # schema i ruttanalyser-databasen d√§r adresserna ska kopieras till
    tabell_till = tabell_till,            # tabell i ruttanalyser-databasen d√§r adresserna ska kopieras till
    lagg_till_metadata_i_till_databas = lagg_till_metadata_i_till_databas
  )
  
  # vi kollar i ruttanalyser-db vilka grafer som finns
  natverkstyper <- postgres_lista_scheman_tabeller(con = con_rutt) %>%
    pluck(schema_natverk) %>% 
    .[!str_detect(., "vertices_pgr")]
  
  # d√§refter kopplar vi punkttabellen till samtliga grafer som finns i ruttanalyser i schemat grafer 
  walk(natverkstyper, ~ {
    pgrouting_punkttabell_koppla_till_pgr_graf(
      con = con_rutt,                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
      schema_punkter = schema_till,                  # schema d√§r punkterna finns, default √§r punktlager
      tabell_punkter = tabell_till,            # tabell med punkter som ska kopplas till grafen, default √§r adresser_dalarna
      geom_kol_punkter = geom_kol_punkter,                      # geometri-kolumnen i punkttabellen, default √§r geom
      id_kol_punkter = id_kol_punkter,                      # id-kolumnen i punkttabellen, default √§r gml_id
      schema_natverk = schema_natverk,                        # schema d√§r grafen finns, default √§r nvdb
      tabell_natverk = .x                    # tabell med grafen som ska anv√§ndas, default √§r graf_nvdb_adresser_dalarna
    )
  })
  
  # st√§nger anslutningar (default)
  if (stang_db_anslutningar) {
    dbDisconnect(con_fran_databas)
    dbDisconnect(con_till_databas)
  }
  
} # slut funktion

postgis_databas_uppdatera_med_metadata <- function(
    con,
    inlas_sf,
    schema,
    tabell, 
    postgistabell_geo_kol = "geometry",
    postgistabell_id_kol = "id",
    felmeddelande_medskickat = NA,
    kommentar_metadata = NA
) {
  
  tryCatch({
    
    if (!is.na(felmeddelande_medskickat)) {
      # om h√§mtningen har g√•tt fel s√• skickas felmeddelandet med och l√§ggs in i metadata
      geo_db_resultat <<- felmeddelande_medskickat
      lyckad_uppdatering <<- FALSE
    } else {
      suppress_specific_warning(
        postgis_sf_till_postgistabell(con = con,
                                      inlas_sf = inlas_sf,
                                      schema = schema,
                                      tabell = tabell,
                                      postgistabell_geo_kol = postgistabell_geo_kol,
                                      postgistabell_id_kol = postgistabell_id_kol),
        "Invalid time zone 'UTC', falling back to local time.")
      
      geo_db_resultat <<- NA
      lyckad_uppdatering <<- TRUE
    }
  }, error = function(e) {
    # Skriv ett felmeddelande om n√•got g√•r fel
    geo_db_resultat <<- glue("{e$message}")
    lyckad_uppdatering <<- FALSE
    
  }, finally = {
    # kod som k√∂rs oavsett om skriptet fungerade att k√∂ra eller inte
    postgres_metadata_uppdatera(
      con = con,
      schema = schema,
      tabell = tabell,
      lyckad_uppdatering = lyckad_uppdatering,
      kommentar = geo_db_resultat
    )
  })
}


# ======================================= pgrouting-funktioner ================================================

# funktion f√∂r att installera pgrouting i en postgisdatabas

pgrouting_installera_i_postgis_db <- function(con) {
  
  # SQL-fr√•ga f√∂r att installera pgrouting
  installera_pgrouting_query <- "CREATE EXTENSION IF NOT EXISTS pgrouting;"
  
  # K√∂r SQL-fr√•gan och hantera fel
  tryCatch({
    dbExecute(con, installera_pgrouting_query)
    message("pgrouting-till√§gget har installerats i databasen.")
  }, error = function(e) {
    message("Kunde inte installera pgrouting-till√§gget:", e$message)
  })
  
}

# ------------- Funktioner f√∂r att g√∂ra rutt analyser
# Funktionerna som finns nedan √§r ett paket av funktioner som skapar olika typer av rutt-
# analyser.Funktionerna √§r byggda av v√•r tidigare GIS-praktikant Mikael Leonidsson √•r 2024 och har d√§refter utvecklats vidare av 
# Sebastian Roos Tanse v√•ren 2025 d√• han var GIS-praktikant p√• RUF-Samh√§llsanalys.
# Funktionerna som √§r fr√•n b√∂rjan skrivna f√∂r ett specifikt projekt men har efter hand skrivits om 
# f√∂r att kunna anv√§ndas till allehanda olika analyser. I juli 2025 lade Peter M√∂ller en hand √∂ver skripten
# f√∂r att √•tg√§rda vissa fel och en viss optimering av befintliga skript.


# ----------------- 1. Funktion f√∂r att klippa ett n√§tverk (standard √§r nvdb) utanf√∂r en gr√§ns med 
# buffer_m antal meter. T.ex. att klippa nvdb 3 mil utanf√∂r l√§nsgr√§nsen f√∂r att f√• med 
# rutter som g√•r en bit √∂ver l√§nsgr√§nsen. D√§refter platta till n√§tverket (Force2D) 
# och g√∂ra om Multi till Linestring (f√∂r att resten ska funka). Egentligen ingen pgrouting-funktion
# men f√∂rberedelse inf√∂r att skapa en graf
pgrouting_klipp_natverk_skapa_tabell <- function(
    con,                                   # Uppkoppling, finns ingen default f√∂r det beh√∂vs en anv√§ndare med skrivbeh√∂righet f√∂r att kunna k√∂ra denna funktion
    con_till_databas = "ruttanalyser",     # NULL om man vill l√§gga resultatet (klippt n√§tverk, oftast nvdb) i samma databas, annars g√∂r man en uppkoppling till ny databas genom att skicka med ett con-objekt alternativt namnet p√• den databas som man vill koppla upp sig mot (b√•da funkar)
    buffer_m = 30000,                      # Om man vill klippa n√§tverket utanf√∂r en gr√§ns (tex. l√§nsgr√§ns), ange hur m√•nga meter
    natverk_schema = "nvdb",               # schema i vilket n√§tverket finns, default √§r nvdb
    natverk_tabell = "dala_med_grannlan",  # tabell som anv√§nds att klippa i, default √§r dala_med_grannlan
    #natverk_id,                           # verkar inte beh√∂vas 
    natverk_geokol = "geom",               # geometry-kolumnen i n√§tverkstabellen, default √§r geom
    region_schema = "karta",               # schema f√∂r region att klippa n√§tverk med, default √§r karta
    region_tabell = "lan_lm",              # tabell f√∂r region att klippa n√§tverk med, default √§r lan_lm, som √§r l√§nsgr√§nser som √§r korrekta men inte snygga (som scb:s l√§ns- och kommungr√§nser)
    regionkod_kol = "lankod",              # regionkoderna ligger i denna kolumn, tex. l√§nskoder eller kommunkoder
    regionkoder = "20",                    # man kan ha en eller skicka med en vektor med regionkoder, t.ex. c("20", "21")
    region_geokol = "geom",                # geometry-kolumnen i region-tabellen, default √§r geom
    output_schema = "grafer",                # schema att spara output-tabellen i, default √§r nvdb
    output_tabell = "nvdb_alla",           # tabell att spara output i, default √§r nvdb_alla     (alla f√∂r bil + g√•ng och cykelv√§g, annars tex bil), detta lager √§r klippt f√∂r att koppla b√§ttre mot adresspunkterna
    urval_fran_natverk = ""                # om man vill v√§lja n√•got specifikt fr√•n n√§tverkstabellen, ska d√• vara i formatet "WHERE vagtrafiknat_nattyp = 1"
) {
  # Starta tidtagning
  starttid <- Sys.time()
  
  # om man skickat med ett con_till_databas (dvs. ska skriva resultatet till annan databas)
  if (!is.null(con_till_databas)) {
    # testar om det √§r ett con-objekt, i s√• fall g√∂r vi ingenting utan utg√•r fr√•n att det √§r korrekt
    if (!inherits(con_till_databas, "DBIConnection")){
      # om det inte √§r ett con-objekt s√• beh√∂ver vi skapa det men d√• kr√§vs keyring-paketet och en service som heter rd_geodata
      if (!requireNamespace("keyring", quietly = TRUE)) {
        stop("Funktionen kr√§ver paketet 'keyring' f√∂r att hantera databasuppkopplingar. Installera det med install.packages('keyring').")
      }
      # om man har paketet keyring m√•ste ocks√• servicen "rd_geodata" finnas, som ska inneh√•lla inloggningsuppgifter till databasen
      if (!"rd_geodata" %in%  keyring::key_list()$service) {
        stop("Keyring-service 'rd_geodata' saknas. Skapa den och l√§gg in anv√§ndare och l√∂senord till databasen d√§r.")
      }
      
      con_till_databas <- uppkoppling_adm(con_till_databas)
      skapad_i_funktionen <- TRUE
      
    } else skapad_i_funktionen <- FALSE # slut test om att det inte √§r ett con-objekt, om det √§r ett con-objekt g√∂rs inget mer utan vi anv√§nder det bara
  } else {
    con_till_databas <- con                  # om con_till_databas √§r NA s√• antar det samma v√§rde som con (jobba i samma databas)
    skapad_i_funktionen <- FALSE
  } 
  
  # ====== kontrollera att alla scheman, tabeller och kolumner finns
  postgres_finns_schema_tabell_kolumner(con, natverk_schema, natverk_tabell, natverk_geokol, stoppa_vid_fel = TRUE)     # kontrollera att n√§tverket finns
  postgres_finns_schema_tabell_kolumner(con, region_schema, region_tabell, c(regionkod_kol, region_geokol), stoppa_vid_fel = TRUE)
  
  # Formatera regionkoder till SQL-str√§ng
  regionkoder_str <- paste0("'", paste(regionkoder, collapse = "', '"), "'")
  
  tryCatch({
    # Skapa spatialt index p√• region-tabellen om det inte finns 
    sql_index <- glue("CREATE INDEX IF NOT EXISTS {region_tabell}_geom_idx 
                       ON {region_schema}.{region_tabell} USING GIST({region_geokol});")
    dbExecute(con, sql_index)
    
    # Klipp n√§tverket med ST_Intersects (beh√•ll hela linjer)
    dbExecute(con_till_databas, glue("DROP TABLE IF EXISTS {output_schema}.{output_tabell};"))
    sql_clip_network <- glue("
      WITH region_buffer AS (
        SELECT ST_Union(ST_Buffer({region_geokol}, {buffer_m})) AS {region_geokol}
        FROM {region_schema}.{region_tabell}
        WHERE {regionkod_kol} IN ({regionkoder_str})
      )
      SELECT l.*
      FROM {natverk_schema}.{natverk_tabell} l
      JOIN region_buffer d
      ON ST_Intersects(l.{natverk_geokol}, d.{region_geokol}){urval_fran_natverk} ;
    ")
    klippt_natverk <- dbGetQuery(con, sql_clip_network)           # k√∂r queryn och spara i r-objektet
    
    if (nrow(klippt_natverk) == 0) {
      stop("Inga rader hittades i det klippta n√§tverket. Kontrollera regionkoder och n√§tverkstabell.")
    }
    # skriv det klippta n√§tverket till den nya databasen
    st_write(obj = klippt_natverk,
             dsn = con_till_databas,
             layer = DBI::Id(schema = output_schema, table = output_tabell),
             append = FALSE)  # skriv √∂ver tabellen om den finns, annars skapa ny
    print(glue("‚úÖ N√§tverket klippt!"))
    
    
    # Konvertera till 2D
    # Denna raden √§r utbytt f√∂r att det skapar problem f√∂r att vi har defingerat att det ska vara en multilinestring 
    # och f√∂r att uppdatara detta m√•ste vi g√∂ra den uppdaterade skriptet ist√§llet. 
    # sql_2d <- glue("UPDATE {output_schema}.{output_tabell} SET {natverk_geokol} = ST_LineMerge(ST_Force2D({natverk_geokol}));")
    
    sql_2d <- glue("ALTER TABLE {output_schema}.{output_tabell} ALTER COLUMN geom TYPE geometry(LineString, 3006) USING ST_LineMerge(ST_Force2D({natverk_geokol}));")
    
    dbExecute(con_till_databas, sql_2d)
    print("Geometrin utplattad (2d) och MultiLinestrings omgjorda till linestrings.")
    
    # Skapa index p√• geometrin
    index_namn <- glue("{output_schema}_{output_tabell}_geom_idx")
    dbExecute(con_till_databas, glue("DROP INDEX IF EXISTS {index_namn};"))
    dbExecute(con_till_databas, glue("CREATE INDEX {index_namn} ON {output_schema}.{output_tabell} USING GIST({natverk_geokol});"))
    dbExecute(con_till_databas, glue("ANALYZE {output_schema}.{output_tabell};"))
    
    # h√§mta nvdb-version i metadata-tabell
    meta_nvdb <- postgres_meta(
      con = con,
      query = "WHERE schema = 'nvdb' AND tabell = 'dala_med_grannlan'") %>% 
      select(version_datum, version_tid)
  

    dag <- as.integer(format(with_tz(meta_nvdb$version_datum, tzone = Sys.timezone()), "%d"))
    manad_ar <- tolower(format(with_tz(meta_nvdb$version_datum, tzone = Sys.timezone()), "%b%Y"))
    tid <- paste0(str_sub(meta_nvdb$version_tid, 1, 2), str_sub(meta_nvdb$version_tid, 4, 5))
    nvdb_ver <- paste0(dag, manad_ar, "_", tid)
    
    nvdb_ver_db <- paste0("nvdb ver: ", nvdb_ver)
    lyckad_uppdatering <- TRUE
    
  }, error = function(e) {
    # Skriv ett felmeddelande om n√•got g√•r fel
    nvdb_ver_db <- glue("{e$message}")
    lyckad_uppdatering <- FALSE
    
  }, finally = {
    # kod som k√∂rs oavsett om skriptet fungerade att k√∂ra eller inte
    postgres_metadata_uppdatera(
      con = con_till_databas,
      schema = output_schema,
      tabell = output_tabell,
      version_datum = meta_nvdb$version_datum,
      version_tid = meta_nvdb$version_tid,
      lyckad_uppdatering = lyckad_uppdatering,
      kommentar = nvdb_ver_db
    )
  })
  
  # St√§ng anslutningen om den var tempor√§r
  if (skapad_i_funktionen) dbDisconnect(con_till_databas)
  
  # Tidtagning
  sluttid <- Sys.time()
  message(glue("Resultatet har sparats i {output_schema}.{output_tabell}.\n‚è± Processen tog {round(sluttid - starttid, 2)} sekunder att k√∂ra"))
}

# ---------- 2. Funktion f√∂r att ut√∂ka n√§tverk med nya noder
# denna funktion anv√§nds f√∂r att skapa b√§ttre anslutningar fr√•n ett punktlager till ett n√§tverk (oftast nvdb). I default k√∂r
# vi p√• adresser som √§r det vi kommer att anv√§nda mest men vill man k√∂ra med andra punkter s√• kan man g√∂ra det.
# som det √§r nu m√•ste punkter flyttas √∂ver till databasen "ruttanalyser" d√§r allt k√∂rs f√∂r att skapa grafer
# d√• kopplas i en senare funktion ocks√• nid till varje punkt s√• att det g√•r att g√∂ra k√∂rningar med pgrouting utifr√•n
# dessa punkter

pgrouting_hitta_narmaste_punkt_pa_natverk <- function(
    con = "ruttanalyser",                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
    schema_punkter_fran = "punktlager",             # att k√∂ra med adresser √§r default, men det g√•r att k√∂ra med andra tabeller, schema och fr√•n annan databas
    tabell_punkter_fran = "adresser",       # tabellen som anv√§nds, default √§r "dalarna" som √§r alla adresser i Dalarna
    geometri_kol_punkter_fran = "geom",             # geometri-kolumnen i punkttabellen fr√•n. 
    id_kol_punkter_fran = "gml_id",                 # id-kolumnen i punkttabellen fr√•n, default √§r "gml_id"
    schema_graf = "grafer",                           # schema f√∂r grafen, dvs. n√§tverket som ska anv√§ndas, default √§r nvdb
    tabell_graf = "nvdb_alla",                      # tabell f√∂r grafen, dvs. n√§tverket som ska anv√§ndas, default √§r graf_nvdb
    geometri_graf = "geom",                         # geometri-kolumnen i grafen, dvs. n√§tverket som ska anv√§ndas, default √§r geom
    id_graf = "rad_id",                             # id-kolumnen i grafen, dvs. n√§tverket som ska anv√§ndas, default √§r rad_id
    kostnadsfalt = "",                              # lite oklart i nul√§get vilket syfte detta har, beh√∂vs sannolikt inte
    tolerans_avstand = 3                            # f√∂r att bygga kluster av punkter och spara k√∂rtid, 0 = d√• skapar vi i praktiken inga kluster
) {
  starttid <- Sys.time()
  
  # om man skickat med ett con (dvs. ska skriva resultatet till annan databas)
  if (!is.null(con)) {
    # testar om det √§r ett con-objekt, i s√• fall g√∂r vi ingenting utan utg√•r fr√•n att det √§r korrekt
    if (!inherits(con, "DBIConnection")){
      # om det inte √§r ett con-objekt s√• beh√∂ver vi skapa det men d√• kr√§vs keyring-paketet och en service som heter rd_geodata
      if (!requireNamespace("keyring", quietly = TRUE)) {
        stop("Funktionen kr√§ver paketet 'keyring' f√∂r att hantera databasuppkopplingar. Installera det med install.packages('keyring').")
      }
      # om man har paketet keyring m√•ste ocks√• servicen "rd_geodata" finnas, som ska inneh√•lla inloggningsuppgifter till databasen
      if (!"rd_geodata" %in%  keyring::key_list()$service) {
        stop("Keyring-service 'rd_geodata' saknas. Skapa den och l√§gg in anv√§ndare och l√∂senord till databasen d√§r.")
      }
      con <- uppkoppling_adm(con)
      skapad_i_funktionen <- TRUE
    } else skapad_i_funktionen <- FALSE # slut test om att det inte √§r ett con-objekt, om det √§r ett con-objekt g√∂rs inget mer utan vi anv√§nder det bara
  } else {
    stop("En anslutning till databasen m√•ste skickas med, som con-objekt eller som namn p√• databasen man vill koppla upp mot.")
  } 
  
  tabell_ny_natverk <- glue("{tabell_graf}_{tabell_punkter_fran}")
  # h√§r b√∂rjar vi k√∂rningen, vi k√∂r med dbBegin() f√∂r att kunna rulla 
  dbBegin(con)
  tryCatch({
    # 1. N√§rmaste punkt p√• n√§tverket
    # Ta bort eventuell gammal tabell
    dbExecute(con, glue("DROP TABLE IF EXISTS {schema_graf}.{tabell_ny_natverk}_narmaste_punkt;"))
    sql_narmaste <- glue("
      CREATE TABLE {schema_graf}.{tabell_ny_natverk}_narmaste_punkt AS
      WITH closest_points AS (
        SELECT
          f.{id_kol_punkter_fran} AS adress_id,
          g.{id_graf} AS graf_id,
          ST_ClosestPoint(g.{geometri_graf}, f.{geometri_kol_punkter_fran}) AS punkt_pa_natverk,
          ST_DWithin(ST_ClosestPoint(g.{geometri_graf}, f.{geometri_kol_punkter_fran}), ST_StartPoint(g.{geometri_graf}), {tolerans_avstand}) AS is_near_start_point,
          ST_DWithin(ST_ClosestPoint(g.{geometri_graf}, f.{geometri_kol_punkter_fran}), ST_EndPoint(g.{geometri_graf}), {tolerans_avstand}) AS is_near_end_point
        FROM {schema_punkter_fran}.{tabell_punkter_fran} f,
        LATERAL (
          SELECT {id_graf}, {geometri_graf}
          FROM {schema_graf}.{tabell_graf}
          ORDER BY f.{geometri_kol_punkter_fran} <-> {geometri_graf}
          LIMIT 1
        ) g
      )
      SELECT adress_id, graf_id, punkt_pa_natverk
      FROM closest_points
      WHERE NOT is_near_start_point AND NOT is_near_end_point;
    ")
    
    dbExecute(con, sql_narmaste)
    
    n_narmaste <- dbGetQuery(con, glue("SELECT COUNT(*) FROM {schema_graf}.{tabell_ny_natverk}_narmaste_punkt"))$count
    print(glue("‚úÖ Antal nya n√§rmaste punkter: {n_narmaste}"))
    
    if (n_narmaste == 0) stop("üö´ Inga giltiga punkter hittades p√• n√§tverket.")
    
    # 2. Skapa kluster av n√§rmaste punkter
    dbExecute(con, glue("DROP TABLE IF EXISTS {schema_graf}.{tabell_ny_natverk}_klusterpunkt;"))
    sql_kluster <- glue("
      CREATE TABLE {schema_graf}.{tabell_ny_natverk}_klusterpunkt AS
      WITH clusters AS (
        SELECT
          ST_ClusterDBSCAN(punkt_pa_natverk, eps := {tolerans_avstand}, minpoints := 1) OVER(PARTITION BY graf_id) AS cid,
          punkt_pa_natverk,
          graf_id
        FROM {schema_graf}.{tabell_ny_natverk}_narmaste_punkt
      ), cluster_centroids AS (
        SELECT
          cid, graf_id,
          ST_Centroid(ST_Collect(punkt_pa_natverk)) AS centroid
        FROM clusters
        GROUP BY cid, graf_id
      ), representant_punkter AS (
        SELECT DISTINCT ON (c.cid, c.graf_id)
          c.cid,
          c.graf_id,
          c.punkt_pa_natverk AS representant_punkt,
          ST_LineLocatePoint(n.{geometri_graf}, c.punkt_pa_natverk) AS line_location
        FROM clusters c
        JOIN {schema_graf}.{tabell_graf} n ON c.graf_id = n.{id_graf}
        JOIN cluster_centroids cc ON c.cid = cc.cid AND c.graf_id = cc.graf_id
        ORDER BY c.cid, c.graf_id, ST_Distance(c.punkt_pa_natverk, cc.centroid)
      )
      SELECT
        cid,
        graf_id,
        representant_punkt,
        line_location
      FROM representant_punkter
      ORDER BY graf_id, line_location;
    ")
    
    dbExecute(con, sql_kluster)
    n_kluster <- dbGetQuery(con, glue("SELECT COUNT(*) FROM {schema_graf}.{tabell_ny_natverk}_klusterpunkt"))$count
    print(glue("‚úÖ Antal klusterrepresentanter: {n_kluster}"))
    
    if (n_kluster == 0) stop("üö´ Klustring misslyckades ‚Äì inga punkter valda som representanter.")
    
    # 3. Skapa nytt n√§tverk
    dbExecute(con, glue("DROP TABLE IF EXISTS {schema_graf}.{tabell_ny_natverk};"))
    print(glue("Tabell {tabell_ny_natverk} droppades om den fanns."))
    
    
    # Plocka ut alla kolumner ur grafen utom geometrin och shape_length, stoppa i en str√§ng f√∂r att anv√§nda i SQL:n nedan.
    # OBS! De tre f√∂rsta kolumnnamnen √§r obligatoriska, resterande (i det h√§r fallet from_ och to_measure) kan fyllas p√• med fler eller tas bort beroende p√• hur mycket info man vill ha med i grafen 
    col_query <- glue("
      SELECT column_name
      FROM information_schema.columns
      WHERE table_schema = '{schema_graf}'
        AND table_name = '{tabell_graf}'
        AND column_name NOT IN ('{geometri_graf}', 'shape_length', 'rad_id', 'from_measure', 'to_measure');
    ")
    
    cols <- dbGetQuery(con, col_query)$column_name
    col_string <- paste0('n.\"', cols, '\"', collapse = ", ")
    
    sql_create <- glue("
      CREATE TABLE {schema_graf}.{tabell_ny_natverk} AS 
      WITH locus AS (
        SELECT {id_graf} AS gid, 0 AS l FROM {schema_graf}.{tabell_graf}
        UNION ALL
        SELECT {id_graf} AS gid, 1 AS l FROM {schema_graf}.{tabell_graf}
        UNION ALL
        SELECT graf_id AS gid, line_location AS l FROM {schema_graf}.{tabell_ny_natverk}_klusterpunkt
      ),
      loc_with_idx AS (
        SELECT gid, l, RANK() OVER (PARTITION BY gid ORDER BY l) AS idx
        FROM locus
      ),
      segment AS (
        SELECT
          ROW_NUMBER() OVER (ORDER BY loc1.gid, loc1.idx) AS {id_graf},
          {col_string},
          ST_LineSubstring(n.{geometri_graf}, loc1.l, loc2.l) AS {geometri_graf},
          ST_Length(ST_LineSubstring(n.{geometri_graf}, loc1.l, loc2.l)) AS kostnad_meter
        FROM 
          loc_with_idx loc1
          JOIN loc_with_idx loc2 USING (gid)
          JOIN {schema_graf}.{tabell_graf} n ON loc1.gid = n.{id_graf}
        WHERE loc2.idx = loc1.idx + 1
      )
      SELECT
        * {kostnadsfalt}
      FROM segment;
    ")
    
    
    dbExecute(con, sql_create)
    # Skapa index p√• geometrin
    index_namn <- glue("{schema_graf}_{tabell_ny_natverk}_geom_idx")
    dbExecute(con, glue("DROP INDEX IF EXISTS {index_namn};"))
    dbExecute(con, glue("CREATE INDEX {index_namn} ON {schema_graf}.{tabell_ny_natverk} USING GIST({geometri_graf});"))
    dbExecute(con, glue("ANALYZE {schema_graf}.{tabell_ny_natverk};"))
    #dbExecute(con, glue("CREATE INDEX ON {schema_graf}.{tabell_ny_natverk} USING GIST({geometri_graf});"))
    print(glue("‚úÖ Nytt n√§tverk {tabell_ny_natverk} skapat."))
    
    dbCommit(con)
    
    # fyll p√• variabler som ska vara till metadatabasen 
    meta_graf <- postgres_meta(
      con = con,
      query = glue("WHERE schema = '{schema_graf}' AND tabell = '{tabell_graf}'")) %>% 
      select(version_datum, version_tid, kommentar)
    
    frantabell_ver_db <- meta_graf$kommentar
    
  }, error = function(e) {
    dbRollback(con)
    cat("üö® Fel i processen:", e$message, "\n")
    
    frantabell_ver_db <- glue("{e$message}")
    lyckad_uppdatering <- FALSE
    
  }, finally = {
    # St√§ng anslutningen om den var tempor√§r
    if (skapad_i_funktionen) dbDisconnect(con_till_databas)
    
    # huvudtabellen, tex. nvdb_bil_adresser
    postgres_metadata_uppdatera(
      con = con,
      schema = schema_graf,
      tabell = tabell_ny_natverk,
      version_datum = meta_graf$version_datum,
      version_tid = meta_graf$version_tid,
      lyckad_uppdatering = lyckad_uppdatering,
      kommentar = frantabell_ver_db
    )
    
    # narmaste_punkt-tabellen
    postgres_metadata_uppdatera(
      con = con,
      schema = schema_graf,
      tabell = paste0(tabell_ny_natverk, "_narmaste_punkt"),
      version_datum = meta_graf$version_datum,
      version_tid = meta_graf$version_tid,
      lyckad_uppdatering = lyckad_uppdatering,
      kommentar = frantabell_ver_db
    )
    
    # klusterpunkt-tabellen
    postgres_metadata_uppdatera(
      con = con,
      schema = schema_graf,
      tabell = paste0(tabell_ny_natverk, "_klusterpunkt"),
      version_datum = meta_graf$version_datum,
      version_tid = meta_graf$version_tid,
      lyckad_uppdatering = lyckad_uppdatering,
      kommentar = frantabell_ver_db
    )
    
    sluttid <- Sys.time()
    message(sprintf("‚è± Total tid: %.1f sekunder", as.numeric(difftime(sluttid, starttid, units = "secs"))))
  })
}


# ====== 3. Funktion f√∂r att skapa graf av tabell med linjer, ex.vis nvdb
# H√§r skapar vi sj√§lva grafen fr√•n en tabell med linjer (ex.vis nvdb) som vi har f√∂rberett i funktionerna ovan.
# Det √§r inte ett krav att funktionerna ovan k√∂rs men det kommer att ge en b√§ttre graf

pgrouting_tabell_till_pgrgraf <- function(
    con = "ruttanalyser",                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
    schema_graf = "grafer",                           # schema d√§r tabellen som ska bli graf ligger. Default: nvdb
    tabell_graf = "nvdb_alla_adresser",     # Tabellen som ska f√∂rberedas f√∂r pgrouting. Default: graf_nvdb_adresser_dalarna
    id_kol_graf = "rad_id",                         # Kolumnen med id i den tabell som ska bli graf
    geom_kol_graf = "geom",                     # Namn p√• kolumnen som inneh√•ller geometrin i tabellen som ska bli graf
    tolerans = 0.001           # Toleransv√§rdet f√∂r hur n√§ra segment m√•ste vara f√∂r att ansluta. 
){
  # Starta tidstagning
  starttid <- Sys.time()
  
  # om man skickat med ett con (dvs. ska skriva resultatet till annan databas)
  if (!is.null(con)) {
    # testar om det √§r ett con-objekt, i s√• fall g√∂r vi ingenting utan utg√•r fr√•n att det √§r korrekt
    if (!inherits(con, "DBIConnection")){
      # om det inte √§r ett con-objekt s√• beh√∂ver vi skapa det men d√• kr√§vs keyring-paketet och en service som heter rd_geodata
      if (!requireNamespace("keyring", quietly = TRUE)) {
        stop("Funktionen kr√§ver paketet 'keyring' f√∂r att hantera databasuppkopplingar. Installera det med install.packages('keyring').")
      }
      # om man har paketet keyring m√•ste ocks√• servicen "rd_geodata" finnas, som ska inneh√•lla inloggningsuppgifter till databasen
      if (!"rd_geodata" %in%  keyring::key_list()$service) {
        stop("Keyring-service 'rd_geodata' saknas. Skapa den och l√§gg in anv√§ndare och l√∂senord till databasen d√§r.")
      }
      con <- uppkoppling_adm(con)
      skapad_i_funktionen <- TRUE
    } else skapad_i_funktionen <- FALSE # slut test om att det inte √§r ett con-objekt, om det √§r ett con-objekt g√∂rs inget mer utan vi anv√§nder det bara
  } else {
    stop("En anslutning till databasen m√•ste skickas med, som con-objekt eller som namn p√• databasen man vill koppla upp mot.")
  } 
  
  # Skapa topologi till pgrouting
  # Anv√§nder BEGIN och COMMIT tillsammans med tryCatch f√∂r att s√§kerst√§lla att allt g√∂rs eller inget
  tryCatch({
    dbBegin(con)
    # Kolla om topologi-tabellen redan finns, isf ta bort den
    res <- dbGetQuery(con, glue("SELECT table_name FROM information_schema.tables WHERE table_schema = '{schema_graf}' AND table_name = '{tabell_graf}_vertices_pgr';"))
    
    if (nrow(res) == 1) {
      dbExecute(con, glue("DROP TABLE {schema_graf}.{tabell_graf}_vertices_pgr;"))
      print(glue("Tabellen {tabell_graf}_vertices_pgr fanns redan och har tagits bort."))
    }
    
    # se till att id √§r av typen integer
    dbExecute(con, glue("ALTER TABLE {schema_graf}.{tabell_graf} ALTER COLUMN {id_kol_graf} TYPE integer USING {id_kol_graf}::integer;"))
    # l√§gg till kolumnen "source"
    dbExecute(con, glue("ALTER TABLE {schema_graf}.{tabell_graf} ADD COLUMN IF NOT EXISTS source integer;"))
    # l√§gg till kolumnen "target"
    dbExecute(con, glue("ALTER TABLE {schema_graf}.{tabell_graf} ADD COLUMN IF NOT EXISTS target integer;"))
    # skapa topologi i pgrouting
    dbExecute(con, glue("SELECT pgr_createTopology('{schema_graf}.{tabell_graf}', '{tolerans}', the_geom := '{geom_kol_graf}', id := '{id_kol_graf}');"))
    
    
    
    # analysera den nyligen skapade topologin
    dbExecute(con, glue("SELECT pgr_analyzeGraph('{schema_graf}.{tabell_graf}', {tolerans}, the_geom := '{geom_kol_graf}', id := '{id_kol_graf}');"))
    
    
    #Om allt g√•tt bra, committa
    dbCommit(con)
    
    # fyll p√• variabler som ska vara till metadatabasen 
    meta_graf <- postgres_meta(
      con = con,
      query = glue("WHERE schema = '{schema_graf}' AND tabell = '{tabell_graf}'")) %>% 
      select(version_datum, version_tid, kommentar)
    
    nu <- now()
    dag <- as.integer(format(with_tz(nu, tzone = Sys.timezone()), "%d"))
    manad_ar <- tolower(format(with_tz(nu, tzone = Sys.timezone()), "%b%Y"))
    tid <- format(nu, "%H%M")
    pgr_graf_ver <- paste0(dag, manad_ar, "_", tid)
    
    frantabell_ver_db <- glue("pgr_graf ver: {pgr_graf_ver}, {meta_graf$kommentar}") 
    
    
    #Om n√•got fel skett i blocket, k√∂r en rollback
  }, error = function(e) {
    dbRollback(con)
    stop("Transaktionen misslyckades: ", e$message)
    
    frantabell_ver_db <- glue("{e$message}")
    lyckad_uppdatering <- FALSE
    
  }, finally = {
    
    # Koppla ner om uppkopplingen har skapats i funktionen
    if(skapad_i_funktionen){
      dbDisconnect(con)
      print("Uppkopplingen avslutad!")
    }
    
    # fyll p√• metadata-tabellen
    postgres_metadata_uppdatera(
      con = con,
      schema = schema_graf,
      tabell = tabell_graf,
      version_datum = as.Date(nu),
      version_tid = format(nu, "%H:%M"),
      lyckad_uppdatering = lyckad_uppdatering,
      kommentar = frantabell_ver_db
    )
    
    # Ber√§kna och skriv ut tids√•tg√•ng
    sluttid <- Sys.time()
    tidstagning <- sluttid - starttid
    message(sprintf("Processen skapa graf tog %s minuter att k√∂ra", tidstagning %>% round(., 1)))
  }
  )
}

#====== 4. Funktion f√∂r att koppla tabell med punkter till pgRoutinggraf
# Denna ska k√∂ras f√∂r att f√• ett nid p√• v√•ra punkt tabeller. 
# Den ska k√∂ras tv√• g√•nger en p√• fr√•n_tabellen och en p√• till_tabellen
# 
# Obs!! Om det √§r s√• att du vill kolla mellan tv√• adresser beh√∂ver du inte k√∂ra den tv√• g√•nger.

pgrouting_punkttabell_koppla_till_pgr_graf <- function(
    con = "ruttanalyser",                      # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
    schema_punkter = "punktlager",             # schema d√§r punkterna finns, default √§r punktlager
    tabell_punkter = "adresser",               # tabell med punkter som ska kopplas till grafen, default √§r adresser_dalarna
    geom_kol_punkter = "geom",                 # geometri-kolumnen i punkttabellen, default √§r geom
    id_kol_punkter = "gml_id",                 # id-kolumnen i punkttabellen, default √§r gml_id
    schema_natverk = "grafer",                 # schema d√§r grafen finns, default √§r nvdb
    tabell_natverk = "nvdb_alla_adresser",     # tabell med grafen som ska anv√§ndas, default √§r graf_nvdb_adresser_dalarna
    generella_namn_prova = TRUE                # TRUE om man ska testa kolumnnamn "id" respektive "geom"/"geometry" om inte medskickad id-kolumnnamn eller geokolumnnamn finns
){
  
  # Starta tidstagning
  starttid <- Sys.time()
  
  # om man skickat med ett con (dvs. ska skriva resultatet till annan databas)
  if (!is.null(con)) {
    # testar om det √§r ett con-objekt, i s√• fall g√∂r vi ingenting utan utg√•r fr√•n att det √§r korrekt
    if (!inherits(con, "DBIConnection")){
      # om det inte √§r ett con-objekt s√• beh√∂ver vi skapa det men d√• kr√§vs keyring-paketet och en service som heter rd_geodata
      if (!requireNamespace("keyring", quietly = TRUE)) {
        stop("Funktionen kr√§ver paketet 'keyring' f√∂r att hantera databasuppkopplingar. Installera det med install.packages('keyring').")
      }
      # om man har paketet keyring m√•ste ocks√• servicen "rd_geodata" finnas, som ska inneh√•lla inloggningsuppgifter till databasen
      if (!"rd_geodata" %in%  keyring::key_list()$service) {
        stop("Keyring-service 'rd_geodata' saknas. Skapa den och l√§gg in anv√§ndare och l√∂senord till databasen d√§r.")
      }
      con <- uppkoppling_adm(con)
      skapad_i_funktionen <- TRUE
    } else skapad_i_funktionen <- FALSE # slut test om att det inte √§r ett con-objekt, om det √§r ett con-objekt g√∂rs inget mer utan vi anv√§nder det bara
  } else {
    stop("En anslutning till databasen m√•ste skickas med, som con-objekt eller som namn p√• databasen man vill koppla upp mot.")
  } 
  
  id_kol_finns <- TRUE
  geom_kol_finns <- TRUE
  # kolla om id-kolum samt geometri-kolumn finns, prova andra namn om generella_namn_prova = TRUE 
  if (generella_namn_prova) {
    # prova om id-kolumn f√∂r punkter finns, om inte, testa "id" annars blir id_kol_finns = FALSE
    if (!postgres_finns_schema_tabell_kolumner(con = con,
                                          schema = schema_punkter,
                                          tabell = tabell_punkter,
                                          kolumner = id_kol_punkter,
                                          stoppa_vid_fel = FALSE)$allt_finns) {
      
    } else if (!postgres_finns_schema_tabell_kolumner(con = con,
                                               schema = schema_punkter,
                                               tabell = tabell_punkter,
                                               kolumner = "id",
                                               stoppa_vid_fel = FALSE)$allt_finns) {
      id_kol_punkter <- "id"
      
    } else id_kol_finns <- FALSE
    
    # prova om geo-kolumn f√∂r punkter finns, om inte, testa "geom" och "geometry" annars blir geom_kol_finns = FALSE
    
    if (!postgres_finns_schema_tabell_kolumner(con = con,
                                               schema = schema_punkter,
                                               tabell = tabell_punkter,
                                               kolumner = geom_kol_punkter,
                                               stoppa_vid_fel = FALSE)$allt_finns) {
      
    } else if (!postgres_finns_schema_tabell_kolumner(con = con,
                                                      schema = schema_punkter,
                                                      tabell = tabell_punkter,
                                                      kolumner = "geometry",
                                                      stoppa_vid_fel = FALSE)$allt_finns) {
      geom_kol_punkter <- "geometry"
      
    } else if (!postgres_finns_schema_tabell_kolumner(con = con,
                                                      schema = schema_punkter,
                                                      tabell = tabell_punkter,
                                                      kolumner = "geom",
                                                      stoppa_vid_fel = FALSE)$allt_finns) {
      geom_kol_punkter <- "geom"
      
    } else geom_kol_finns <- FALSE
    
  } else {             # om generella_namn_prova = FALSE
    if (!postgres_finns_schema_tabell_kolumner(con = con,
                                               schema = schema_punkter,
                                               tabell = tabell_punkter,
                                               kolumner = id_kol_punkter,
                                               stoppa_vid_fel = FALSE)$allt_finns) id_kol_finns <- FALSE
    if (!postgres_finns_schema_tabell_kolumner(con = con,
                                                schema = schema_punkter,
                                               tabell = tabell_punkter,
                                               kolumner = geom_kol_punkter,
                                               stoppa_vid_fel = FALSE)$allt_finns) geom_kol_finns <- FALSE
  } # slut kontroll om kolumnnamn finns
  
  if (id_kol_finns & geom_kol_finns) {
    tryCatch({
      dbBegin(con)
      # vi b√∂rjar med att skapa en ny kolumn i den nya tabellen
      dbExecute(con, glue("ALTER TABLE {schema_punkter}.{tabell_punkter} ADD COLUMN IF NOT EXISTS nid_{tabell_natverk} bigint;"))
      # T√∂m kolumnen om d√§r redan finns v√§rden
      dbExecute(con, glue("UPDATE {schema_punkter}.{tabell_punkter} SET nid_{tabell_natverk} = NULL;"))
      # d√§refter g√∂r vi en spatial join fr√•n mittpunkten till noderna i nvdb
      sql_koppla_toponode <- glue("
                      UPDATE {schema_punkter}.{tabell_punkter} AS f
                      SET nid_{tabell_natverk} = n.id
                      FROM (
                        SELECT f2.{id_kol_punkter} AS punkt_id, v.id
                        FROM {schema_punkter}.{tabell_punkter} AS f2
                        JOIN LATERAL (
                          SELECT id
                          FROM {schema_natverk}.{tabell_natverk}_vertices_pgr AS v
                          ORDER BY f2.{geom_kol_punkter} <-> v.the_geom
                          LIMIT 1
                        ) AS v ON TRUE
                      ) AS n
                      WHERE f.{id_kol_punkter} = n.punkt_id;
                    ")
      dbExecute(con, sql_koppla_toponode)        
      
      
      # Om allt g√•tt bra, committa
      dbCommit(con)
      print(glue("Punkterna i {schema_punkter}.{tabell_punkter} har nu nid_{tabell_natverk} kopplat till sig fr√•n grafen {schema_natverk}.{tabell_natverk}."))
      
      # skapa variabler f√∂r att fylla p√• metadata-tabellen
      meta_punkter <- postgres_meta(
        con = con,
        query = glue("WHERE schema = '{schema_punkter}' AND tabell = '{tabell_punkter}'")
      ) %>% 
        select(version_datum, version_tid, kommentar)
      
      meta_pgr_graf <- postgres_meta(
        con = con,
        query = glue("WHERE schema = '{schema_natverk}' AND tabell = '{tabell_natverk}'")
      ) %>% 
        select(version_datum, version_tid, kommentar)
      
      tabell_ver_db <- glue("{meta_punkter$kommentar}, {meta_pgr_graf$kommentar}") %>%    # l√§gg ihop och ta bort dubletter
        str_split(",\\s*") %>%        # Dela upp p√• kommatecken
        unlist() %>%                  # G√∂r till vektor
        unique() %>%                  # Ta bort dubbletter
        str_c(collapse = ", ")        # S√§tt ihop igen
      
      lyckad_uppdatering <- TRUE
      
    }, error = function(e) {
      # Om n√•got g√•tt fel under processen, √•terst√§ll databasen till innan denna funktion
      dbRollback(con)
      message(glue("Transaktionen misslyckades: {e$message}"))
      
      tabell_ver_db <- glue("{e$message}")
      lyckad_uppdatering <- FALSE
      
    }, finally = {
      # kod som k√∂rs oavsett om skriptet fungerade att k√∂ra eller inte
      # h√§mta metadata f√∂r fran-tabellen
      
      postgres_metadata_uppdatera(
        con = con,
        schema = schema_punkter,
        tabell = tabell_punkter,
        version_datum = meta_punkter$version_datum,
        version_tid = meta_punkter$version_tid,
        lyckad_uppdatering = lyckad_uppdatering,
        kommentar = tabell_ver_db
      )
    }) # slut tryCatch() 
  } else {
    # om inte b√•de id-kolumn och geometri-kolumn finns
    if (!id_kol_finns) cat("Angiven id-kolumn saknas, kontrollera namnet och k√∂r igen med korrekt id-kolumnnamn.")
    if (!geom_kol_finns) cat("Angiven geometri-kolumn saknas, kontrollera namnet och k√∂r igen med korrekt geometri-kolumnnamn.")
  }
    
    
  # Koppla ner om uppkopplingen har skapats i funktionen
  if(skapad_i_funktionen){
    dbDisconnect(con)
    #print("Uppkopplingen avslutad!")
  }
  
} # slut funktion

#====== 4,5. Funktion f√∂r att skapa kostnadskolumner f√∂r alla transports√§tt
# K√∂rs f√∂r att f√• kostnad f√∂r g√•ng, cykel, elcykel och bil (ut√∂ver meter)

pgrouting_kostnadskolumner_transporttyp_graf <- function(
    con = "ruttanalyser",                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
    schema_natverk = "grafer",                        # schema d√§r grafen finns, default √§r nvdb
    tabell_natverk = "nvdb_alla_adresser",   # tabell med grafen som ska anv√§ndas, default √§r graf_nvdb_adresser_dalarna
    kostnadskolumn_bil_f = "hastighetsgrans_f",
    kostnadskolumn_bil_b = "hastighetsgrans_b",
    kostnadskolumn_meter = "kostnad_meter",
    berakna_kostnad_bil = TRUE,              # f√∂r att kunna st√§nga av vissa transports√§tt, kostnadskolumn m√•ste finnas annars ber√§knas det √§nd√• inte
    berakna_kostnad_gang = TRUE,
    berakna_kostnad_cykel = TRUE,
    berakna_kostnad_elcykel = TRUE
    ){
  
  # Starta tidstagning
  starttid <- Sys.time()
  
  # om man skickat med ett con (dvs. ska skriva resultatet till annan databas)
  if (!is.null(con)) {
    # testar om det √§r ett con-objekt, i s√• fall g√∂r vi ingenting utan utg√•r fr√•n att det √§r korrekt
    if (!inherits(con, "DBIConnection")){
      # om det inte √§r ett con-objekt s√• beh√∂ver vi skapa det men d√• kr√§vs keyring-paketet och en service som heter rd_geodata
      if (!requireNamespace("keyring", quietly = TRUE)) {
        stop("Funktionen kr√§ver paketet 'keyring' f√∂r att hantera databasuppkopplingar. Installera det med install.packages('keyring').")
      }
      # om man har paketet keyring m√•ste ocks√• servicen "rd_geodata" finnas, som ska inneh√•lla inloggningsuppgifter till databasen
      if (!"rd_geodata" %in%  keyring::key_list()$service) {
        stop("Keyring-service 'rd_geodata' saknas. Skapa den och l√§gg in anv√§ndare och l√∂senord till databasen d√§r.")
      }
      con <- uppkoppling_adm(con)
      skapad_i_funktionen <- TRUE
    } else skapad_i_funktionen <- FALSE # slut test om att det inte √§r ett con-objekt, om det √§r ett con-objekt g√∂rs inget mer utan vi anv√§nder det bara
  } else {
    stop("En anslutning till databasen m√•ste skickas med, som con-objekt eller som namn p√• databasen man vill koppla upp mot.")
  } 
  
  tryCatch({
    dbBegin(con)
    # vi b√∂rjar med att skapa en ny kolumn i den nya tabellen f√∂r de
    # transports√§tt som vi vill ha med och har underlag f√∂r (kostnadskolumn)
    kolumner_att_lagga_till <- c()
    
    if (berakna_kostnad_gang && !is.null(kostnadskolumn_meter)) {
      kolumner_att_lagga_till <- c(kolumner_att_lagga_till,
                                   "ADD COLUMN IF NOT EXISTS kostnad_gang_min double precision"
      )
    }
    
    if (berakna_kostnad_cykel && !is.null(kostnadskolumn_meter)) {
      kolumner_att_lagga_till <- c(kolumner_att_lagga_till,
                                   "ADD COLUMN IF NOT EXISTS kostnad_cykel_min double precision"
      )
    }
    
    if (berakna_kostnad_elcykel && !is.null(kostnadskolumn_meter)) {
      kolumner_att_lagga_till <- c(kolumner_att_lagga_till,
                                   "ADD COLUMN IF NOT EXISTS kostnad_elcykel_min double precision"
      )
    }
    
    if (berakna_kostnad_bil && !is.null(kostnadskolumn_bil_f)) {
      kolumner_att_lagga_till <- c(kolumner_att_lagga_till,
                                   "ADD COLUMN IF NOT EXISTS kostnad_bil_f_min double precision"
      )
    }
    
    if (berakna_kostnad_bil && !is.null(kostnadskolumn_bil_b)) {
      kolumner_att_lagga_till <- c(kolumner_att_lagga_till,
                                   "ADD COLUMN IF NOT EXISTS kostnad_bil_b_min double precision"
      )
    }
    
    # K√∂r bara om det finns n√•got att l√§gga till
    if (length(kolumner_att_lagga_till) > 0) {
      alter_sql <- glue::glue("
    ALTER TABLE {schema_natverk}.{tabell_natverk}
    {glue::glue_collapse(kolumner_att_lagga_till, sep = ',\n    ')}
    ;")
      DBI::dbExecute(con, alter_sql)
    }
    
    # g√∂r ber√§kningarna
    berakningar <- c()
    
    if (berakna_kostnad_gang && !is.null(kostnadskolumn_meter)) {
      berakningar <- c(berakningar,
                       glue("kostnad_gang_min = {kostnadskolumn_meter} / ({pgrouting_hastighet_gang()} / 3.6) / 60")
      )
    }
    
    if (berakna_kostnad_cykel && !is.null(kostnadskolumn_meter)) {
      berakningar <- c(berakningar,
                       glue("kostnad_cykel_min = {kostnadskolumn_meter} / ({pgrouting_hastighet_cykel()} / 3.6) / 60")
      )
    }
    
    if (berakna_kostnad_elcykel && !is.null(kostnadskolumn_meter)) {
      berakningar <- c(berakningar,
                       glue("kostnad_elcykel_min = {kostnadskolumn_meter} / ({pgrouting_hastighet_elcykel()} / 3.6) / 60")
      )
    }
    
    if (berakna_kostnad_bil && !is.null(kostnadskolumn_bil_f)) {
      berakningar <- c(berakningar,
                       glue("kostnad_bil_f_min = {kostnadskolumn_meter} / (NULLIF({kostnadskolumn_bil_f}, 0) / 3.6) / 60")
      )
    }
    
    if (berakna_kostnad_bil && !is.null(kostnadskolumn_bil_b)) {
      berakningar <- c(berakningar,
                       glue("kostnad_bil_b_min = {kostnadskolumn_meter} / (NULLIF({kostnadskolumn_bil_b}, 0) / 3.6) / 60")
      )
    }
    
    # Om det finns n√•got att ber√§kna
    if (length(berakningar) > 0) {
      update_sql <- glue::glue("
    UPDATE {schema_natverk}.{tabell_natverk}
    SET {glue::glue_collapse(berakningar, sep = ',\n        ')}
  ")
      DBI::dbExecute(con, update_sql)
    }
    
    # Om allt g√•tt bra, committa
    dbCommit(con)
    print(glue("Kostnadskolumner i {schema_natverk}.{tabell_natverk} har ber√§knats."))
    
    # skapa variabler f√∂r att fylla p√• metadata-tabellen
    meta_kostnader <- postgres_meta(
      con = con,
      query = glue("WHERE schema = '{schema_natverk}' AND tabell = 'nvdb_{natverkstyp}_{punkter_till_tabell}'")
    ) %>% 
      select(version_datum, version_tid, kommentar)
    
    nu <- now()
    dag <- as.integer(format(with_tz(nu, tzone = Sys.timezone()), "%d"))
    manad_ar <- tolower(format(with_tz(nu, tzone = Sys.timezone()), "%b%Y"))
    tid <- format(nu, "%H%M")
    kostnad_ver <- paste0(dag, manad_ar, "_", tid)
    
    
    frantabell_ver_db <- glue("{meta_kostnader$kommentar}, kostnader ver: {kostnad_ver}")
    lyckad_uppdatering <- TRUE
    
    
  }, error = function(e) {
    # Om n√•got g√•tt fel under processen, √•terst√§ll databasen till innan denna funktion
    dbRollback(con)
    message(glue("Transaktionen misslyckades: {e$message}"))
    
    frantabell_ver_db <- glue("{e$message}")
    lyckad_uppdatering <- FALSE
    
  }, finally = {
  
  # # kod som k√∂rs oavsett om skriptet fungerade att k√∂ra eller inte
  # # h√§mta metadata f√∂r fran-tabellen
  # postgres_metadata_uppdatera(
  #   con = con,
  #   schema = schema_natverk,
  #   tabell = glue("nvdb_{natverkstyp}_{punkter_till_tabell}"),
  #   version_datum = meta_kostnader$version_datum,
  #   version_tid = meta_kostnader$version_tid,
  #   lyckad_uppdatering = lyckad_uppdatering,
  #   kommentar = frantabell_ver_db
  # )
    
  }) # slut tryCatch()
  
  # Koppla ner om uppkopplingen har skapats i funktionen
  if(skapad_i_funktionen){
    dbDisconnect(con)
    #print("Uppkopplingen avslutad!")
  }
  
} # slut funktion

#====== 5. Ber√§kna restid/avst√•nd mellan fr√•n punkter och till-punkter

pgrouting_skapa_geotabell_rutt_fran_till <- function(
    con = "ruttanalyser",                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)    schema_output,
    schema_fran = "punktlager",
    tabell_fran = "adresser",
    schema_till,
    tabell_till,
    schema_graf = "grafer",
    tabell_graf = "nvdb_alla_adresser",
    schema_output = "resultat",
    tabell_till_namnkol = "mottagnings_namn",
    tabell_till_idkol = "gml_id",
    urval_till_tabell = NULL,        # f√∂r att g√∂ra ett urval med wheresats glue("where malpunkt_namn != 'N√§rakut Ludvika' ") eller glue("where malpunkt_namn != 'Akutmottagning Avesta' ")
    urval_till_namn = "",            # f√∂r att d√∂pa lagret s√• att man vet att det √§r ett urval, tex. "utan_ludvika"
    hastighet_gang = NULL,           # om NULL anv√§nds pgrouting_hastighet_gang(), dvs. standardv√§rde f√∂r hastighet g√•ng
    hastighet_cykel = NULL,          # om NULL anv√§nds pgrouting_hastighet_cykel(), dvs. standardv√§rde f√∂r hastighet cykel
    hastighet_elcykel = NULL,        # om NULL anv√§nds pgrouting_hastighet_elcykel(), dvs. standardv√§rde f√∂r hastighet elcykel
    batch_storlek = 1000,            # Parameter f√∂r batch-storlek, l√§mna som den √§r om inte v√§ldigt goda sk√§l finns att √§ndra det
    antal_batcher_test = NULL        # NULL n√§r man k√∂r skarpt, annars antal batcher om man vill begr√§nsa en k√∂rning i ett test, heltal (tex 2 om man vill k√∂ra 2 batcher)
){
  # Funktion f√∂r att skapa en geotabell f√∂r n√§rmaste rutt fr√•n alla rader i fr√•ntabell till
  # n√§rmaste punkt i till-tabellen dijkstraNear() med pgrouting, inklusive alla rutter som
  # linjer
  
  # Starta tidstagning
  starttid <- Sys.time()
  
  # om man skickat med ett con (dvs. ska skriva resultatet till annan databas)
  if (!is.null(con)) {
    # testar om det √§r ett con-objekt, i s√• fall g√∂r vi ingenting utan utg√•r fr√•n att det √§r korrekt
    if (!inherits(con, "DBIConnection")){
      # om det inte √§r ett con-objekt s√• beh√∂ver vi skapa det men d√• kr√§vs keyring-paketet och en service som heter rd_geodata
      if (!requireNamespace("keyring", quietly = TRUE)) {
        stop("Funktionen kr√§ver paketet 'keyring' f√∂r att hantera databasuppkopplingar. Installera det med install.packages('keyring').")
      }
      # om man har paketet keyring m√•ste ocks√• servicen "rd_geodata" finnas, som ska inneh√•lla inloggningsuppgifter till databasen
      if (!"rd_geodata" %in%  keyring::key_list()$service) {
        stop("Keyring-service 'rd_geodata' saknas. Skapa den och l√§gg in anv√§ndare och l√∂senord till databasen d√§r.")
      }
      con <- uppkoppling_adm(con)
      skapad_i_funktionen <- TRUE
    } else skapad_i_funktionen <- FALSE # slut test om att det inte √§r ett con-objekt, om det √§r ett con-objekt g√∂rs inget mer utan vi anv√§nder det bara
  } else {
    stop("En anslutning till databasen m√•ste skickas med, som con-objekt eller som namn p√• databasen man vill koppla upp mot.")
  } 
  
  # h√§mta v√§rden f√∂r hastigheter per transports√§tt om de inte man skickat med det
  if (is.null(hastighet_gang)) hastighet_gang <- pgrouting_hastighet_gang() 
  if (is.null(hastighet_cykel)) hastighet_cykel <- pgrouting_hastighet_cykel() 
  if (is.null(hastighet_elcykel)) hastighet_elcykel <- pgrouting_hastighet_elcykel() 
  
  
  tryCatch({
  # Skapa en ny tabell med alla unika nid i tabell_fran om den inte redan finns. Om den finns s√• t√∂m tabellen f√∂rst
  # 1. SKapa den nya tabellens namn, en kombination av de tv√• tabellerna fran och till
  
  # f√∂rst tar vi reda p√• vilken typ av n√§tverk det √§r, tex. "alla" eller "bil"
  natverkstyp <- str_remove(tabell_graf, fixed(tabell_fran)) %>%
    str_remove("_$") %>%
    str_extract("[^_]+$")
  
  if (rlang::is_empty(urval_till_tabell)){
    tabell_ny <- glue("{tabell_fran}_till_{tabell_till}_{natverkstyp}")
    urval_till_tabell = ""
  } else {
    tabell_ny <- glue("{tabell_fran}_till_{tabell_till}_{urval_till_namn}_{natverkstyp}")
  }
  
  # h√§r h√§mtas kolumner fr√•n fr√•n-tabellen, men tar inte med
  # geom, geometry eller nid, dessa tas med i resultat-tabellerna
  frantabell_kolumner <- dbGetQuery(con, glue("
    SELECT column_name, data_type
    FROM information_schema.columns
    WHERE table_schema = '{schema_fran}'
      AND table_name = '{tabell_fran}'
    ORDER BY ordinal_position;
  ")) %>%
    filter(
      !column_name %in% c("geom", "geometry"),
      !str_detect(column_name, "nid_")
    ) %>% 
    mutate(data_type = ifelse(data_type == "USER-DEFINED", "geometry", data_type),
           data_type = ifelse(data_type == "text", "varchar", data_type),
           definition = glue("{column_name} {data_type}"))
  
  # kolumner som tas med fr√•n m√•lpunkterna samt ruttanalysen som genomf√∂rs
  # med pgr_dijkstraNear(), dessa l√§ggs efter kolumnerna fr√•n "fr√•n"-tabellen ovan
  malpunkt_rutt_kolumner <- "malpunkt_id varchar,
                            malpunkt_namn varchar,
                            start_vid int, 
                            end_vid int, 
                            kostnad_meter double precision,
                            kostnad_gang_min double precision,
                            kostnad_cykel_min double precision,
                            kostnad_elcykel_min double precision,
                            kostnad_bil_min double precision,
                            geom geometry" %>% 
    str_split(",\\s*\n?") %>%                      # Dela upp str√§ngen i en lista med ett element per kolumndefinition (separerat p√• kommatecken, ev. f√∂ljt av radbrytning)
    pluck(1) %>%                                   # extrahera vektorn (f√∂rsta elementet) ur listan som str_split() returnerar.
    str_trim() %>%                                 # k√∂r en trim (ta bort blanksteg i b√∂rjan eller i slutet av str√§ngen)
    str_match("^([a-zA-Z0-9_]+)\\s+(.+)$") %>%     # Plocka ut kolumnnamn och datatyp med regex. F√∂rsta gruppen (([a-zA-Z0-9_]+)) √§r kolumnnamnet, andra ((.+)) √§r datatypen
    as_tibble(.name_repair = "minimal") %>%        # G√∂r en tibble av detta
    setNames(c("tabort", "column_name", "data_type")) %>%       # d√∂p kolumnerna i tibble:n
    select(-tabort) %>%                                         # ta bort den f√∂rsta kolumnen som vi inte beh√∂ver
    mutate(definition = glue("{column_name} {data_type}"))      # skapa en kolumn av kolumnnamn + mellanslag + datatyp, det anv√§nder vi i sql-kod nedan
  
  # 2. Kolla om den redan finns, isf t√∂m den
  res <- dbGetQuery(con, glue("SELECT table_name FROM information_schema.tables WHERE table_schema = '{schema_output}' AND table_name = '{tabell_ny}';"))
  if (nrow(res) == 0) {
    
    # sql_query_drop <- glue("DROP table {schema_output}.{tabell_ny};") # Droppa den nya om det √§r s√• att du vill g√∂ra en f√∂r√§ndring p√• den nya tabellen
    # dbExecute(con, sql_query_drop)
    
    sql_query_create <- glue("CREATE table IF NOT EXISTS {schema_output}.{tabell_ny} (
                            {frantabell_kolumner$definition %>% paste(collapse = ',\n')},
                            {malpunkt_rutt_kolumner$definition %>% paste(collapse = ',\n')}
                            );")
    
    
    # Skapa den nya tabellen med samma kolumnnamn som djikstra_result
    dbExecute(con, sql_query_create)
    
    print(glue("Tabellen {tabell_ny} har skapats."))
  } else {
    #dbExecute(con, glue("TRUNCATE TABLE {schema_output}.{tabell_ny};"))
    dbExecute(con, glue("TRUNCATE TABLE {schema_output}.{tabell_ny};"))
    print(glue("Tabellen {tabell_ny} fanns redan och har t√∂mts p√• v√§rden."))
  }
  # Skapa tempor√§ra tabeller f√∂r nidn fr√•n tabell_fran och tabell_till, skall anv√§ndas i djikstranearcost
  temp_fran <- glue("temp_{tabell_fran}")
  temp_till <- glue("temp_{tabell_till}")
  
  dbExecute(con, glue("DROP TABLE IF EXISTS {temp_fran};"))
  dbExecute(con, glue("DROP TABLE IF EXISTS {temp_till};"))
  
  dbExecute(con, glue("CREATE TEMP TABLE {temp_fran} AS SELECT DISTINCT nid_{tabell_graf} FROM {schema_fran}.{tabell_fran};"))
  dbExecute(con, glue("CREATE TEMP TABLE {temp_till} AS SELECT DISTINCT nid_{tabell_graf} FROM {schema_till}.{tabell_till};"))
  
  # Skapa index till temptabellerna, beh√∂ver ej droppas efter de f√∂rsvinner automagiskt n√§r tabellen droppas
  dbExecute(con, glue("CREATE INDEX temp_fran_nidx ON {temp_fran}(nid_{tabell_graf});"))
  dbExecute(con, glue("CREATE INDEX temp_till_nidx ON {temp_till}(nid_{tabell_graf})"))
  
  # Skapa f√∂ruts√§ttningar f√∂r batchk√∂rning
  # R√§kna antalet rader i tabell_ny
  antal_noder <- dbGetQuery(con, glue("SELECT COUNT(*) as antal FROM {temp_fran}"))$antal
  
  # Ber√§kna antalet batcher
  antal_batcher <- ceiling(antal_noder / batch_storlek)
  
  
  # ================ om test - k√∂r antal batcher som finns i antal_batcher_test
  if (!is.null(antal_batcher_test)) antal_batcher <- antal_batcher_test
  
  # skapa kostnad utifr√•n om vi vill m√§ta kortast str√§cka med 
  # restid bil eller avst√•nd i meter (restid bil √§r rimligt n√§r man g√∂r
  # ett dedikerat biln√§tverk, annars √§r meter rimligast)
  if (natverkstyp == "bil") {
    # skapa tv√• CASE-satser, en f√∂r hastighetsgrans_f och en f√∂r hastighetsgrans_b
    # och s√• k√∂r vi directed := true, f√∂r att k√∂ra riktat n√§tverk
    kostnad_berakning <- "CASE 
    WHEN hastighetsgrans_f IS NOT NULL THEN kostnad_meter / (hastighetsgrans_f / 3.6)
    ELSE -1 
  END AS cost,
  CASE 
    WHEN hastighetsgrans_b IS NOT NULL THEN kostnad_meter / (hastighetsgrans_b / 3.6)
    ELSE -1 
  END AS reverse_cost"
    #kostnad_berakning <- "kostnad_meter / (hastighetsgrans_f / 3.6) AS cost, \nkostnad_meter / (hastighetsgrans_b / 3.6) AS reverse_cost"
    #kostnad_berakning_b <- ", kostnad_meter / (hastighetsgrans_b / 3.6) AS reverse_cost \n"
    #kostnad_filter <- " AND hastighetsgrans_f > 0"
    kostnad_filter <- ""
    kostnad_as_sats <- " AS segment_tid_bil"
    kostnad_sum <- "SUM(segment_tid_bil) AS kostnad_tid_bil,"
    vagnat_directed <- "true"
  } else {
    kostnad_berakning <- "kostnad_meter AS cost"
    #kostnad_berakning_b <- ""
    kostnad_filter <- ""
    kostnad_as_sats <- ""
    kostnad_sum <- "NULL AS kostnad_tid_bil,"
    vagnat_directed <- "false"
  }
  
  print(glue("Letar efter kortaste v√§gen fr√•n {antal_noder} noder i {antal_batcher} batcher."))
  total_start <- Sys.time()
  #for(i in 1:antal_batcher){
  walk((1:antal_batcher), function(i){  
    start_tid <- Sys.time()
    tryCatch({
      offset <- (i - 1) * batch_storlek
      
      # K√∂r pgr_dijkstraNear() med start- och slutvid fr√•n temptabellerna med unika noder och stoppa in i tabell_ny
      # Denna k√∂r dijkstraNear() en g√•ng och kopplar sedan p√• kostnader fr√•n nvdb_grafen. 
      
      sql_query <- glue("
         INSERT INTO {schema_output}.{tabell_ny} (
            {frantabell_kolumner$column_name %>% paste(collapse = ',\n')}, 
            {malpunkt_rutt_kolumner$column_name %>% paste(collapse = ',\n')}
          )
      WITH dijkstra_raw AS (
        SELECT *
        FROM pgr_dijkstraNear(
          'SELECT rad_id AS id,
                  source,
                  target,
                  {kostnad_berakning}
           FROM {schema_graf}.{tabell_graf}
           WHERE kostnad_meter IS NOT NULL{kostnad_filter}',
          ARRAY(
            SELECT DISTINCT nid_{tabell_graf} 
            FROM {schema_fran}.{tabell_fran} LIMIT {batch_storlek} OFFSET {offset}
          )::INT[],
          ARRAY(
            SELECT DISTINCT nid_{tabell_graf} 
            FROM {schema_till}.{tabell_till} {urval_till_tabell}
          )::INT[],
          directed := {vagnat_directed},
          cap := 1,
          global := false
        )
      ),
      rutter AS (
        SELECT
          d.path_seq,
          d.start_vid,
          d.end_vid,
          d.edge,
          v.kostnad_meter,
          d.cost{kostnad_as_sats},
          v.geom
        FROM dijkstra_raw d
        JOIN {schema_graf}.{tabell_graf} v ON d.edge = v.rad_id
      ),
      summerad_rutt AS (
        SELECT
          start_vid,
          end_vid,
          SUM(kostnad_meter) AS kostnad_meter,
          {kostnad_sum}
          ST_LineMerge(ST_Union(ARRAY_AGG(geom ORDER BY path_seq))) AS rutt_geom
        FROM rutter
        WHERE edge != -1
        GROUP BY start_vid, end_vid
      )
      SELECT
        {frantabell_kolumner$column_name %>% paste0('fran.', ., collapse = ',\n')},
        till.{tabell_till_idkol} AS malpunkt_id,
        till.{tabell_till_namnkol} AS malpunkt_namn,
        r.start_vid,
        r.end_vid,
        r.kostnad_meter,
        r.kostnad_meter / ({hastighet_gang} / 3.6) / 60 AS kostnad_gang_min,
        r.kostnad_meter / ({hastighet_cykel} / 3.6) / 60 AS kostnad_cykel_min,
        r.kostnad_meter / ({hastighet_elcykel} / 3.6) / 60 AS kostnad_elcykel_min,
        CAST(r.kostnad_tid_bil AS double precision) / 60 AS kostnad_bil_min,
        -- CAST(r.kostnad_tid_bil AS double precision) AS kostnad_bil_min,
        r.rutt_geom AS geom
      FROM summerad_rutt r
      JOIN {schema_fran}.{tabell_fran} fran ON r.start_vid = fran.nid_{tabell_graf}
      JOIN {schema_till}.{tabell_till} till ON r.end_vid = till.nid_{tabell_graf}
      ORDER BY r.start_vid;
    ")
      
      #print(glue("K√∂r batch {i} av {antal_batcher} med {batch_storlek} noder."))
      #print(sql_query)
      #print(sql_query)     # fels√∂kning
      
      dbExecute(con, sql_query)
      # tid <- difftime(Sys.time(), start_tid, units = "secs") %>% as.numeric() %>% round(.,1)
      # print(glue("Batch {i} av {antal_batcher} bearbetad, denna batch tog {tid} sekunder att k√∂ra."))
      #Sys.sleep(90)
    }, warning = function(w) {
      message("Varning uppt√§ckt: ", w)
    }, error = function(e) {
      
      print(glue("Fel under bearbetning av batch {i}: ", e$message))
    }
    )
  }, .progress = TRUE)
  total_tid <- difftime(Sys.time(), total_start, units = "mins") %>% as.numeric() %>% round(.,1)
  print(glue("Samtliga {antal_batcher} batcher √§r bearbetade, hela k√∂rningen tog {total_tid} minuter att k√∂ra."))
  
  # Leta noder d√§r start och slutnod √§r samma och s√§tt kostnad till 0
  sql_query <- glue("INSERT INTO {schema_output}.{tabell_ny} (start_vid, end_vid, kostnad_meter, kostnad_gang_min, kostnad_cykel_min, kostnad_elcykel_min, kostnad_bil_min)
                        SELECT t.nid_{tabell_graf}, tt.nid_{tabell_graf}, 0, 0, 0, 0, 0
                        FROM {temp_till} tt
                        INNER JOIN {temp_fran} t ON tt.nid_{tabell_graf} = t.nid_{tabell_graf}
                        WHERE NOT EXISTS (
                            SELECT 1
                            FROM {schema_output}.{tabell_ny} ny
                            WHERE ny.start_vid = t.nid_{tabell_graf}
                        );")
  #print(sql_query)     # fels√∂kning
  dbExecute(con, sql_query)
  
  # ===== vi skapar ett punktlager av fr√•nlagret med m√•lpunkts-
  # id respektive namn samt kostnadskolumnerna
  dbExecute(con, glue("DROP TABLE IF EXISTS {schema_output}.{tabell_ny}_punkt;"))
  
  dbExecute(con, glue("CREATE TABLE {schema_output}.{tabell_ny}_punkt AS
  SELECT 
    a.*,
    r.malpunkt_id,
    r.malpunkt_namn,
    r.kostnad_meter,
    r.kostnad_gang_min,
    r.kostnad_cykel_min,
    r.kostnad_elcykel_min,
    r.kostnad_bil_min
  FROM {schema_fran}.{tabell_fran} a
  LEFT JOIN (
      SELECT DISTINCT ON (start_vid)
        *
  FROM {schema_output}.{tabell_ny} ) r
    ON a.nid_{tabell_graf} = r.start_vid;"))
  
  # Skapa spatialt index
  dbExecute(con, glue("
  CREATE INDEX ON {schema_output}.{tabell_ny}_punkt USING GIST (geom);
"))
  
  # Droppa temptabellen
  dbExecute(con, glue("DROP TABLE IF EXISTS {temp_fran};"))
  dbExecute(con, glue("DROP TABLE IF EXISTS {temp_till};"))
  
  #Om allt g√•tt bra, committa
  dbCommit(con)
  
  # Kolla hur m√•nga rader som finns i den nya tabellen, b√∂r st√§mma med antalet unika noder
  antal_rader <- dbGetQuery(con, glue("SELECT COUNT(*) as antal FROM {schema_output}.{tabell_ny}"))$antal
  
  print(glue("Det tog {round(difftime(Sys.time(), starttid, units = \"mins\"),1)} minuter att fylla tabellen {schema_output}.{tabell_ny} med {antal_rader} rader, att j√§mf√∂ra med {antal_noder} unika noder."))
  
  if(antal_rader != antal_noder){
    print("Det finns en differens mellan f√∂rv√§ntat och faktiskt resultat vilket indikerar att det finns fler adress rader som √§r kopplade till unika noder.")
  }
  
  # skapa variabler f√∂r att fylla p√• metadata-tabellen
  meta_punkter_fran <- postgres_meta(
    con = con,
    query = glue("WHERE schema = '{schema_fran}' AND tabell = '{tabell_fran}'")
  ) %>% 
    dplyr::pull(kommentar) %>% 
    str_extract("^[^,]+")
  
  meta_punkter_till <- postgres_meta(
    con = con,
    query = glue("WHERE schema = '{schema_till}' AND tabell = '{tabell_till}'")
  ) %>% 
    dplyr::pull(kommentar) %>% 
    str_extract("^[^,]+")
  
  meta_pgr_graf <- postgres_meta(
    con = con,
    query = glue("WHERE schema = '{schema_graf}' AND tabell = '{tabell_graf}'")
  ) %>% 
    dplyr::pull(kommentar)
  
  ruttreslutat_ver_db <- glue("{meta_pgr_graf}, fran punkter {meta_punkter_fran}, till punkter {meta_punkter_till}")
  
  
  
  
  
  
  # fyll p√• variabler som ska vara till metadatabasen 
  meta_ruttresultat <- postgres_meta(
    con = con,
    query = glue("WHERE schema = '{schema_graf}' AND tabell = '{tabell_graf}'")) %>% 
    select(version_datum, version_tid, kommentar)
  
  nu <- now()
  dag <- as.integer(format(with_tz(nu, tzone = Sys.timezone()), "%d"))
  manad_ar <- tolower(format(with_tz(nu, tzone = Sys.timezone()), "%b%Y"))
  tid <- format(nu, "%H%M")
  pgr_graf_ver <- paste0(dag, manad_ar, "_", tid)
  
  ruttreslutat_ver_db <- glue("pgr_graf ver: {pgr_graf_ver}, {meta_ruttresultat$kommentar}") 
  
  
  #Om n√•got fel skett i blocket, k√∂r en rollback
  }, error = function(e) {
    dbRollback(con)
    stop("Transaktionen misslyckades: ", e$message)
    
    ruttreslutat_ver_db <- glue("{e$message}")
    lyckad_uppdatering <- FALSE
    
  }, finally = {
    
    # fyll p√• metadata-tabellen
    postgres_metadata_uppdatera(
      con = con,
      schema = schema_graf,
      tabell = tabell_graf,
      version_datum = as.Date(nu),
      version_tid = format(nu, "%H:%M"),
      lyckad_uppdatering = lyckad_uppdatering,
      kommentar = ruttreslutat_ver_db
    )
    
    # Ber√§kna och skriv ut tids√•tg√•ng
    sluttid <- Sys.time()
    tidstagning <- sluttid - starttid
    message(sprintf("Processen skapa graf tog %s minuter att k√∂ra", tidstagning %>% round(., 1)))
  }) # slut p√• trycatch
  
  # Koppla ner om uppkopplingen har skapats i funktionen
  if(skapad_i_funktionen){
    dbDisconnect(con)
    #print("Uppkopplingen avslutad!")
  }
} # slut pgr_dijkstraNear()-funktion


pgrouting_skapa_ny_graf_nvdb_koppla_till_punkter <- function(
    natverkstyp = "bil",            # "bil" eller "alla", "alla" k√∂r kortaste rutt p√• avst√•nd, "bil" p√• restid med bil (ofta men inte alltid samma rutter), planer p√• att skapa n√§tverk med bara v√§gar man kan cykla p√• (inte alla bilv√§gar)
    punkter_fran_schema = "adresser",
    punkter_fran_tabell = "dalarna",
    punkter_till_tabell = "adresser",
    punkter_till_schema = "punktlager"
) {
  
  # Funktion f√∂r att vid ny version av NVDB uppdatera graf f√∂r adresser
  # i Dalarna s√• att vi alltid har f√§rdiga grafer att k√∂ra ruttanalyser
  # eller skapa isokroner utifr√•n.
  
  con_geodb <- uppkoppling_adm("geodata")
  con_rutt <- uppkoppling_adm("ruttanalyser")
  
  # 1. Kopiera nvdb till en ny tabell och bearbeta lagret s√• att det fungerar bra med adresser
  
  # om man vill ha urval i n√§tverket, typ bara ta med bilv√§gar ("bil"), eller bara v√§gar som g√•r att cykla p√• (inte implementerat √§nnu)
  # eller alla v√§gar (natverkstyp == "alla")
  natverk_urval <- case_when(natverkstyp == "bil" ~ "WHERE vagtrafiknat_nattyp = 1",
                             TRUE ~ "")
  
  
  pgrouting_klipp_natverk_skapa_tabell(
    con = con_geodb,
    con_till_databas = con_rutt,
    buffer_m = 30000,                      # Om man vill klippa n√§tverket utanf√∂r en gr√§ns (tex. l√§nsgr√§ns), ange hur m√•nga meter
    natverk_schema = "nvdb",               # schema i vilket n√§tverket finns, default √§r nvdb
    natverk_tabell = "dala_med_grannlan",  # tabell som anv√§nds att klippa i, default √§r dala_med_grannlan 
    natverk_geokol = "geom",               # geometry-kolumnen i n√§tverkstabellen, default √§r geom
    region_schema = "karta",               # schema f√∂r region att klippa n√§tverk med, default √§r karta
    region_tabell = "lan_lm",              # tabell f√∂r region att klippa n√§tverk med, default √§r lan_lm, som √§r l√§nsgr√§nser som √§r korrekta men inte snygga (som scb:s l√§ns- och kommungr√§nser)
    regionkod_kol = "lankod",              # regionkoderna ligger i denna kolumn, tex. l√§nskoder eller kommunkoder
    regionkoder = "20",                    # man kan ha en eller skicka med en vektor med regionkoder, t.ex. c("20", "21")
    region_geokol = "geom",                # geometry-kolumnen i region-tabellen, default √§r geom
    output_schema = "grafer",              # schema att spara output-tabellen i, default √§r nvdb
    output_tabell = glue("nvdb_{natverkstyp}"),           # tabell att spara output i, default √§r nvdb_alla     (alla f√∂r bil + g√•ng och cykelv√§g, annars tex bil), detta lager √§r klippt f√∂r att koppla b√§ttre mot adresspunkterna
    urval_fran_natverk = natverk_urval                # om man vill v√§lja n√•got specifikt fr√•n n√§tverkstabellen, ska d√• vara i formatet "WHERE vagtrafiknat_nattyp = 1", annars ska det vara ""
  )
  
  # 2. Kopiera adresser fr√•n geodatabasen till ruttanalyser-databasen                                )
  
  postgis_kopiera_tabell_mellan_databaser(
    con_fran_databas = con_geodb,                # fr√•n geodatabasen
    con_till_databas = con_rutt,                 # till ruttanalyser-databasen
    schema_fran = punkter_fran_schema,                    # schema i geodatabasen d√§r adresserna finns
    tabell_fran = punkter_fran_tabell,                     # tabell i geodatabasen d√§r adresserna finns
    schema_till = punkter_till_schema,                  # schema i ruttanalyser-databasen d√§r adresserna ska kopieras till
    tabell_till = punkter_till_tabell,            # tabell i ruttanalyser-databasen d√§r adresserna ska kopieras till
    lagg_till_metadata_i_till_databas = TRUE
  )
  
  # 3. Hitta n√§rmaste punkt p√• n√§tverket f√∂r varje adress, och skapa klusterpunkter
  
  pgrouting_hitta_narmaste_punkt_pa_natverk(
    con = con_rutt,                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
    schema_punkter_fran = "punktlager",             # att k√∂ra med adresser √§r default, men det g√•r att k√∂ra med andra tabeller, schema och fr√•n annan databas
    tabell_punkter_fran = punkter_till_tabell,       # tabellen som anv√§nds, default √§r "adresser_dalarna" som √§r alla adresser i Dalarna
    geometri_kol_punkter_fran = "geom",             # geometri-kolumnen i punkttabellen fr√•n. 
    id_kol_punkter_fran = "gml_id",                 # id-kolumnen i punkttabellen fr√•n, default √§r "gml_id"
    schema_graf = "grafer",                         # schema f√∂r grafen, dvs. n√§tverket som ska anv√§ndas, default √§r nvdb
    tabell_graf = glue("nvdb_{natverkstyp}"),                       # tabell f√∂r grafen, dvs. n√§tverket som ska anv√§ndas, default √§r graf_nvdb
    geometri_graf = "geom",                         # geometri-kolumnen i grafen, dvs. n√§tverket som ska anv√§ndas, default √§r geom
    id_graf = "rad_id",                             # id-kolumnen i grafen, dvs. n√§tverket som ska anv√§ndas, default √§r rad_id
    tolerans_avstand = 3                            # f√∂r att bygga kluster av punkter och spara k√∂rtid, 0 = d√• skapar vi i praktiken inga kluster
  )
  
  # 4. Skapa en graf med det nya n√§tverket som har klippts med de klusterpunkter som skapades ovan
  
  pgrouting_tabell_till_pgrgraf(
    con = con_rutt,                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
    schema_graf = "grafer",                           # schema d√§r tabellen som ska bli graf ligger. Default: nvdb
    tabell_graf = glue("nvdb_{natverkstyp}_{punkter_till_tabell}"),     # Tabellen som ska f√∂rberedas f√∂r pgrouting. Default: graf_nvdb_adresser_dalarna
    id_kol_graf = "rad_id",                         # Kolumnen med id i den tabell som ska bli graf
    geom_kol_graf = "geom",                     # Namn p√• kolumnen som inneh√•ller geometrin i tabellen som ska bli graf
    tolerans = 0.001           # Toleransv√§rdet f√∂r hur n√§ra segment m√•ste vara f√∂r att ansluta. 
  )
  
  # 5. Ber√§kna kostnader i graf-tabellen
  pgrouting_kostnadskolumner_transporttyp_graf(
    con = "ruttanalyser",                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
    schema_natverk = "grafer",                        # schema d√§r grafen finns, default √§r nvdb
    tabell_natverk = glue("nvdb_{natverkstyp}_{punkter_till_tabell}"),   # tabell med grafen som ska anv√§ndas, default √§r graf_nvdb_adresser_dalarna
    kostnadskolumn_bil_f = "hastighetsgrans_f",
    kostnadskolumn_bil_b = "hastighetsgrans_b",
    kostnadskolumn_meter = "kostnad_meter",
    berakna_kostnad_bil = if (natverkstyp == "bil") TRUE else FALSE,              # f√∂r att kunna st√§nga av vissa transports√§tt, kostnadskolumn m√•ste finnas annars ber√§knas det √§nd√• inte
    berakna_kostnad_gang = TRUE,
    berakna_kostnad_cykel = TRUE,
    berakna_kostnad_elcykel = TRUE
  )
  
  # 6. Flytta de tabeller som inte beh√∂vs till schemat underlag_grafer
  
  # l√§gg de tabeller vi ska flytta i en vektor
  tabeller_flytt <- c(
    glue("nvdb_{natverkstyp}"),
    glue("nvdb_{natverkstyp}_{punkter_till_tabell}_narmaste_punkt"),
    glue("nvdb_{natverkstyp}_{punkter_till_tabell}_klusterpunkt")
  )
  
  # vi k√∂r samma kod p√• alla tre tabeller som ska flyttas
  walk(tabeller_flytt, function(tabell_namn) {
    # kopiera tabeller till schemat underlag_grafer, skriv √∂ver om de redan finns
    postgis_kopiera_tabell(
      con = con_rutt,
      schema_fran = "grafer",
      tabell_fran = tabell_namn,
      schema_till = "underlag_grafer",
      tabell_till = tabell_namn,
      skriv_over = TRUE
    )
    
    # ta bort dem i schemat grafer
    postgres_tabell_ta_bort(
      con = con_rutt,
      schema = "grafer",
      tabell = tabell_namn
    )
    
    # och sedan √§ndrar vi deras schema i metadata-tabellen
    DBI::dbExecute(con_rutt, glue::glue("
    WITH senaste AS (
      SELECT id
      FROM metadata.uppdateringar
      WHERE tabell = '{tabell_namn}' AND schema = 'grafer'
      ORDER BY version_datum DESC, version_tid DESC
      LIMIT 1
      )
      UPDATE metadata.uppdateringar
      SET schema = 'underlag_grafer'
      WHERE id IN (SELECT id FROM senaste);
    "))
    
  }) # slut walk-funktion
  
  # 7. Koppla punkter till n√§tverket, vi k√∂r samtliga punktlager till samtliga grafer
  
  # h√§mta grafer fr√•n ruttanalyser-db i schemat "grafer"
  grafer <- postgres_lista_scheman_tabeller(con = con_rutt) %>%
    pluck("grafer") %>% 
    .[!str_detect(., "vertices_pgr")]
  
  # h√§mta punktlager fr√•n ruttanalyser-db i schemat "punktlager"
  punktlager <- postgres_lista_scheman_tabeller(con = con_rutt) %>%
    pluck("punktlager")
  
  kombinationer <- expand_grid(punkttabell = punktlager, graf = grafer)
  
  pwalk(kombinationer, function(punkttabell, graf) {
    pgrouting_punkttabell_koppla_till_pgr_graf(
      con = con_rutt,                           # databas d√§r punkterna finns, default √§r ruttanalyser (dvs. Region Dalarnas databas f√∂r ruttanalyser)
      schema_punkter = "punktlager",                  # schema d√§r punkterna finns, default √§r punktlager
      tabell_punkter = punkttabell,            # tabell med punkter som ska kopplas till grafen, default √§r adresser_dalarna
      geom_kol_punkter = "geom",                      # geometri-kolumnen i punkttabellen, default √§r geom
      id_kol_punkter = "gml_id",                      # id-kolumnen i punkttabellen, default √§r gml_id
      schema_natverk = "grafer",                        # schema d√§r grafen finns, default √§r nvdb
      tabell_natverk = graf   # tabell med grafen som ska anv√§ndas, default √§r graf_nvdb_adresser_dalarna
    )
  })
  
  dbDisconnect(con_geodb)
  dbDisconnect(con_rutt)
} # slut funktion


# definiera hastigheter f√∂r g√•ng, cykel och elcykel
pgrouting_hastighet_gang <- function() 5
pgrouting_hastighet_cykel <- function() 16
pgrouting_hastighet_elcykel <- function() 22


# √§ldre pgrouting-funktioner, avn√§nds inte l√§ngre
las_in_rutor_xlsx_till_postgis_skapa_pgr_graf <- 
  function(inlas_mapp = "G:/Samh√§llsanalys/GIS/rutor/",
           inlas_filer,        # enbart filnamnen p√• filerna som ska l√§sas in
           inlas_tabellnamn,   # de tabellnamn de nya filerna ska f√• i postgis
           rutstorlek = 100,
           schema_rut = "rutor",
           schema_natverk = "nvdb",
           tabell_natverk = "nvdb20buff30") {
    
    #  L√§s in och bearbeta excelfiler med rutdata 
    
    df_list <- map(inlas_filer, ~read.xlsx(paste0(inlas_mapp, .x)))
    gis_list <- list()
    
    # loopa igenom listan med df:s som ska l√§sas in till postgis
    for (df_item in 1:length(df_list)){
      
      # om inte rutid finns som kolumnnamn, skapa ett rutid fr√•n x- och y-koordinaterna som s√§tts ihop
      if (!"rutid" %in% names(df_list[[df_item]])) df_list[[df_item]]$rutid <- paste0(df_list[[df_item]]$ruta_x, df_list[[df_item]]$ruta_y) 
      # flytta rutid s√• att den ligger f√∂rst av kolumnerna
      df_list[[df_item]] <- df_list[[df_item]] %>% relocate(rutid, .before = ruta_x)
      
      # ber√§kna mittpunkt f√∂r varje ruta (halva rutstorlekten adderas x- och y-koordinaten, som √§r nedre v√§nstra h√∂rnet i SCB-rutor)
      df_list[[df_item]] <- berakna_mittpunkter(df_list[[df_item]], "ruta_x", "ruta_y", rutstorlek)
      
      # skapa geometrikolumn f√∂r (mitt)punkter
      gis_list[[df_item]] <- st_as_sf(df_list[[df_item]], coords = c("mitt_y", "mitt_x"), crs = 3006)
      names(gis_list[[df_item]])[names(gis_list[[df_item]]) == "geometry"] <- "geom_point"        # d√∂p om geom-kolumnen
      st_geometry(gis_list[[df_item]]) <- "geom_point"         # man m√•ste tala om igen att den omd√∂pta kolumnen √§r geom-kolumn
      
      # skapa en andra geometrikolumn d√§r vi skapar polygoner runt mittpunkten som utg√∂r sj√§lva rutan
      gis_list[[df_item]]$geom_polygon <- st_buffer(gis_list[[df_item]]$geom_point,(rutstorlek/2), endCapStyle = "SQUARE")
      
      # s√§kerst√§ll att alla kolumnnamn √§r i gemener, st√§ller inte till problem i postigis d√•
      names(df_list[[df_item]]) <- tolower(names(df_list[[df_item]]))
      
      # l√§gg √∂ver till postgis
      
      con <- dbConnect(          # use in other settings
        RPostgres::Postgres(),
        # without the previous and next lines, some functions fail with bigint data 
        #   so change int64 to integer
        bigint = "integer",  
        user = Sys.getenv("userid_postgres_adm"),
        password = Sys.getenv("pwd_postgres_adm"),
        host = "WFALTSTVS427.ltdalarna.se",
        port = 5432,
        dbname = "postgis_31_db",
        options="-c search_path=public")
      
      # k√∂r sql-kod f√∂r att skapa ett nytt schema med namn definierat ovan
      dbExecute(con, paste0("create schema if not exists ", schema_rut, ";"))
      
      # skriv rut-lagren till postgis 
      starttid = Sys.time()
      st_write(obj = gis_list[[df_item]],
               dsn = con,
               Id(schema=schema_rut, table = inlas_tabellnamn[df_item]))
      print(paste0("Det tog ", round(difftime(Sys.time(), starttid, units = "sec"),1), " sekunder att l√§sa in ", inlas_tabellnamn[df_item], " till postgis."))
      
      # skapa spatialt index, finns det sedan tidigare, ta bort
      dbExecute(con, paste0("DROP INDEX IF EXISTS ", schema_rut, ".geom_point_idx;")) 
      dbExecute(con, paste0("CREATE INDEX geom_point_idx ON ", schema_rut, ".", inlas_tabellnamn[df_item], " USING GIST (geom_point);"))
      dbExecute(con, paste0("DROP INDEX IF EXISTS ", schema_rut, ".geom_polygon_idx;")) 
      dbExecute(con, paste0("CREATE INDEX geom_polygon_idx ON ", schema_rut, ".", inlas_tabellnamn[df_item], " USING GIST (geom_polygon);"))
      
      # g√∂r rutid till id-kolumn i tabellen
      dbExecute(con, paste0("ALTER TABLE ", schema_rut, ".", inlas_tabellnamn[df_item], " ADD PRIMARY KEY (rutid);"))
      
      # g√∂r en spatial join f√∂r mittpunkten i rutorna till nvdb 
      
      # vi b√∂rjar med att skapa en ny kolumn i den nya tabellen
      dbExecute(con, paste0("ALTER TABLE ", schema_rut, ".", inlas_tabellnamn[df_item],
                            " ADD COLUMN IF NOT EXISTS toponode_id bigint;"))
      
      # d√§refter g√∂r vi en spatial join fr√•n mittpunkten till noderna i nvdb
      dbExecute(con, paste0("UPDATE ", schema_rut, ".", inlas_tabellnamn[df_item],
                            " SET toponode_id = (",
                            "SELECT ", schema_natverk, ".", tabell_natverk, "_vertices_pgr.id ",
                            "FROM ", schema_natverk, ".", tabell_natverk, "_vertices_pgr ",
                            "ORDER BY ", schema_rut, ".", inlas_tabellnamn[df_item], ".geom_point <-> ",
                            schema_natverk, ".", tabell_natverk, "_vertices_pgr.the_geom ASC NULLS LAST ",
                            "LIMIT 1);"))
      
      dbDisconnect(con)           # st√§ng postgis-anslutningen igen
    } # slut for-loop som loopar igenom inl√§sningsfiler
  } # slut funktion


las_in_fil_skapa_punkter_till_postgis_skapa_pgr_graf <- 
  function(inlas_mapp,
           inlas_filer,        # enbart filnamnen p√• filerna som ska l√§sas in
           inlas_tabellnamn,   # de tabellnamn de nya filerna ska f√• i postgis
           schema_malpunkter,
           malpunkter_id_kol,
           malpunkter_x_koord_kol,
           malpunkter_y_koord_kol,
           malpunkter_crs = 3006,
           malpunkter_till_crs = 3006,
           schema_natverk = "nvdb",
           tabell_natverk = "nvdb20buff30",
           pg_db_user = Sys.getenv("userid_postgres_adm"),
           pg_db_pwd = Sys.getenv("pwd_postgres_adm"),
           pg_db_host = "WFALTSTVS427.ltdalarna.se",
           pg_db_port = 5432,
           pg_db_name_db = "postgis_31_db") {
    
    # Skript f√∂r att l√§sa in en tabell som inneh√•ller m√•lpunkter som man vill g√∂ra ber√§kningar mot 
    # f√∂retr√§delsevis fr√•n boenderutor p√• avst√•nd eller restid med kortaste eller snabbaste resv√§g
    # fr√•n rutor (eller annan geografi som punkter) till n√§rmaste m√•lpunkt i denna tabell.
    # Det kan vara restid till n√§rmaste skola, v√•rdcentral eller bussh√•llplats fr√•n samtliga 
    # boenderutor i en geografi
    #
    # F√∂ljande parametrar skickas med funktionen:
    # inlas_mapp = mapp i vilken tabellen finns som inneh√•ller m√•lpunkterna, m√•ste inneh√•lla kolumner
    #              f√∂r x- och y- koordinat
    # inlas_filer = en vektor med den eller de filer som ska l√§sas in, m√•ste finnas i inlas_mapp
    # inlas_tabellnamn = en textstr√§ng eller vektor om det finns flera filer med tabellnamnet som 
    #                    m√•lpunkterna ska ha i postgisdatabasen (b√∂r vara gemener och utan konstiga tecken)
    # schema_malpunkter = det schema i postgisdatabasen som m√•lpunktstabellen ska ligga under
    # malpunkter_id_kol = den kolumn som inneh√•ller ett unikt ID och g√∂rs till prim√§rnyckelkolumn, m√•ste finnas!
    # malpunkter_id
    # schema_natverk = det schema d√§r n√§tverket mot vilket vi ska koppla m√•lpunkterna finns 
    # tabell_natverk = den tabell d√§r n√§tverket mot vilket vi ska koppla m√•lpunkterna finns, m√•ste 
    #                  finnas under schemat ovan
    # pg_db_user = anv√§ndare f√∂r den postgisdatabas man ansluter till
    # pg_db_pwd = l√∂senord f√∂r anv√§ndaren ovan, OBS! Aldrig i klartext!
    # pg_db_host = adress till den server d√§r postgis-databasen finns
    # pg_db_port = den port som databasen ansluts via
    # pg_db_name_db = den databas i postgis som man ansluter till
    
    # L√§s in och bearbeta excelfiler med punktkoordinater
    
    df_list <- map(inlas_filer, ~read.xlsx(paste0(inlas_mapp, .x)))
    gis_list <- list()
    
    # loopa igenom listan med df:s som ska l√§sas in till postgis
    for (df_item in 1:length(df_list)){
      
      # skapa geometrikolumn f√∂r punkter utifr√•n koordinat-kolumner
      gis_list[[df_item]] <- st_as_sf(df_list[[df_item]], coords = c(malpunkter_x_koord_kol, malpunkter_y_koord_kol), crs = malpunkter_crs)
      names(gis_list[[df_item]])[names(gis_list[[df_item]]) == "geometry"] <- "geom"        # d√∂p om geom-kolumnen
      st_geometry(gis_list[[df_item]]) <- "geom"         # man m√•ste tala om igen att den omd√∂pta kolumnen √§r geom-kolumn
      
      # s√§kerst√§ll att alla kolumnnamn √§r i gemener, st√§ller inte till problem i postigis d√•
      names(gis_list[[df_item]]) <- tolower(names(gis_list[[df_item]]))
      
      # om data inte √§r i r√§tt projektionssystem, konvertera till r√§tt
      if (malpunkter_crs != malpunkter_till_crs) gis_list[[df_item]] <- st_transform(gis_list[[df_item]], crs = malpunkter_till_crs)
      
      # l√§gg √∂ver till postgis
      
      con <- dbConnect(          # use in other settings
        RPostgres::Postgres(),
        # without the previous and next lines, some functions fail with bigint data 
        #   so change int64 to integer
        bigint = "integer",  
        user = pg_db_user,
        password = pg_db_pwd,
        host = pg_db_host,
        port = pg_db_port,
        dbname = pg_db_name_db,
        options="-c search_path=public")
      
      # k√∂r sql-kod f√∂r att skapa ett nytt schema med namn definierat ovan
      dbExecute(con, paste0("create schema if not exists ", schema_malpunkter, ";"))
      
      
      # skriv m√•lpunkts-lagren till postgis 
      starttid = Sys.time()
      st_write(obj = gis_list[[df_item]],
               dsn = con,
               Id(schema=schema_malpunkter, table = inlas_tabellnamn[df_item]))
      print(paste0("Det tog ", round(difftime(Sys.time(), starttid, units = "sec"),1), " sekunder att l√§sa in ", inlas_tabellnamn[df_item], " till postgis."))
      
      # skapa spatialt index, finns det sedan tidigare, ta bort
      dbExecute(con, paste0("DROP INDEX IF EXISTS ", schema_malpunkter, ".geom_idx;")) 
      dbExecute(con, paste0("CREATE INDEX geom_idx ON ", schema_malpunkter, ".", inlas_tabellnamn[df_item], " USING GIST (geom);"))
      
      # g√∂r skickad id-kolumn till prim√§rnyckelkolumn i tabellen
      dbExecute(con, paste0("ALTER TABLE ", schema_malpunkter, ".", inlas_tabellnamn[df_item], " ADD PRIMARY KEY (", malpunkter_id_kol, ");"))
      
      # vi b√∂rjar med att skapa en ny kolumn i den nya tabellen
      dbExecute(con, paste0("ALTER TABLE ", schema_malpunkter, ".", inlas_tabellnamn[df_item],
                            " ADD COLUMN IF NOT EXISTS toponode_id bigint;"))
      
      # d√§refter g√∂r vi en spatial join fr√•n punkterna till noderna i nvdb
      dbExecute(con, paste0("UPDATE ", schema_malpunkter, ".", inlas_tabellnamn[df_item],
                            " SET toponode_id = (",
                            "SELECT ", schema_natverk, ".", tabell_natverk, "_vertices_pgr.id ",
                            "FROM ", schema_natverk, ".", tabell_natverk, "_vertices_pgr ",
                            "ORDER BY ", schema_malpunkter, ".", inlas_tabellnamn[df_item], ".geom <-> ",
                            schema_natverk, ".", tabell_natverk, "_vertices_pgr.the_geom ASC NULLS LAST ",
                            "LIMIT 1);"))
      
      dbDisconnect(con)           # st√§ng postgis-anslutningen igen
    } # slut for-loop som loopar igenom inl√§sningsfiler
  } # slut funktion


las_in_geosf_skapa_punkter_till_postgis_skapa_pgr_graf <- 
  function(inlas_df,
           inlas_tabellnamn,   # de tabellnamn de nya filerna ska f√• i postgis
           schema_malpunkter = "malpunkter",
           malpunkter_id_kol,
           malpunkter_geo_kol,
           malpunkter_till_crs,
           schema_natverk = "nvdb",
           tabell_natverk = "nvdb20buff30",
           pg_db_user = Sys.getenv("userid_postgres_adm"),
           pg_db_pwd = Sys.getenv("pwd_postgres_adm"),
           pg_db_host = "WFALTSTVS427.ltdalarna.se",
           pg_db_port = 5432,
           pg_db_name_db = "postgis_31_db") {
    
    # Skript f√∂r att l√§sa in en tabell som inneh√•ller m√•lpunkter som man vill g√∂ra ber√§kningar mot 
    # f√∂retr√§delsevis fr√•n boenderutor p√• avst√•nd eller restid med kortaste eller snabbaste resv√§g
    # fr√•n rutor (eller annan geografi som punkter) till n√§rmaste m√•lpunkt i denna tabell.
    # Det kan vara restid till n√§rmaste skola, v√•rdcentral eller bussh√•llplats fr√•n samtliga 
    # boenderutor i en geografi
    #
    # F√∂ljande parametrar skickas med funktionen:
    # inlas_mapp = mapp i vilken tabellen finns som inneh√•ller m√•lpunkterna, m√•ste inneh√•lla kolumner
    #              f√∂r x- och y- koordinat
    # inlas_filer = en vektor med den eller de filer som ska l√§sas in, m√•ste finnas i inlas_mapp
    # inlas_tabellnamn = en textstr√§ng eller vektor om det finns flera filer med tabellnamnet som 
    #                    m√•lpunkterna ska ha i postgisdatabasen (b√∂r vara gemener och utan konstiga tecken)
    # schema_malpunkter = det schema i postgisdatabasen som m√•lpunktstabellen ska ligga under
    # malpunkter_id_kol = den kolumn som inneh√•ller ett unikt ID och g√∂rs till prim√§rnyckelkolumn, m√•ste finnas!
    # malpunkter_geo_kol = geometry-kolumnen
    # schema_natverk = det schema d√§r n√§tverket mot vilket vi ska koppla m√•lpunkterna finns 
    # tabell_natverk = den tabell d√§r n√§tverket mot vilket vi ska koppla m√•lpunkterna finns, m√•ste 
    #                  finnas under schemat ovan
    # pg_db_user = anv√§ndare f√∂r den postgisdatabas man ansluter till
    # pg_db_pwd = l√∂senord f√∂r anv√§ndaren ovan, OBS! Aldrig i klartext!
    # pg_db_host = adress till den server d√§r postgis-databasen finns
    # pg_db_port = den port som databasen ansluts via
    # pg_db_name_db = den databas i postgis som man ansluter till
    
    # L√§s in och bearbeta excelfiler med rutdata
    
    
    # s√§kerst√§ll att alla kolumnnamn √§r i gemener, st√§ller inte till problem i postigis d√•
    names(inlas_df) <- tolower(names(inlas_df))
    
    # l√§gg √∂ver till postgis
    
    con <- dbConnect(          # use in other settings
      RPostgres::Postgres(),
      # without the previous and next lines, some functions fail with bigint data 
      #   so change int64 to integer
      bigint = "integer",  
      user = pg_db_user,
      password = pg_db_pwd,
      host = pg_db_host,
      port = pg_db_port,
      dbname = pg_db_name_db,
      options="-c search_path=public")
    
    # k√∂r sql-kod f√∂r att skapa ett nytt schema med namn definierat ovan
    dbExecute(con, paste0("create schema if not exists ", schema_malpunkter, ";"))
    
    #  skriv rut-lagren till postgis 
    starttid = Sys.time()
    st_write(obj = inlas_df,
             dsn = con,
             Id(schema=schema_malpunkter, table = inlas_tabellnamn))
    print(paste0("Det tog ", round(difftime(Sys.time(), starttid, units = "sec"),1), " sekunder att l√§sa in ", inlas_tabellnamn, " till postgis."))
    
    # skapa spatialt index, finns det sedan tidigare, ta bort
    dbExecute(con, paste0("DROP INDEX IF EXISTS ", schema_malpunkter, ".", malpunkter_geo_kol, "_idx;")) 
    dbExecute(con, paste0("CREATE INDEX ", malpunkter_geo_kol, "_idx ON ", schema_malpunkter, ".", inlas_tabellnamn, " USING GIST (", malpunkter_geo_kol, ");"))
    
    # g√∂r rutid till id-kolumn i tabellen
    dbExecute(con, paste0("ALTER TABLE ", schema_malpunkter, ".", inlas_tabellnamn, " ADD PRIMARY KEY (", malpunkter_id_kol ,");"))
    
    # g√∂r en spatial join f√∂r mittpunkten i rutorna till nvdb
    
    # vi b√∂rjar med att skapa en ny kolumn i den nya tabellen
    dbExecute(con, paste0("ALTER TABLE ", schema_malpunkter, ".", inlas_tabellnamn,
                          " ADD COLUMN IF NOT EXISTS toponode_id bigint;"))
    
    # d√§refter g√∂r vi en spatial join fr√•n mittpunkten till noderna i nvdb
    dbExecute(con, paste0("UPDATE ", schema_malpunkter, ".", inlas_tabellnamn,
                          " SET toponode_id = (",
                          "SELECT ", schema_natverk, ".", tabell_natverk, "_vertices_pgr.id ",
                          "FROM ", schema_natverk, ".", tabell_natverk, "_vertices_pgr ",
                          "ORDER BY ", schema_malpunkter, ".", inlas_tabellnamn, ".", malpunkter_geo_kol, " <-> ",
                          schema_natverk, ".", tabell_natverk, "_vertices_pgr.the_geom ASC NULLS LAST ",
                          "LIMIT 1);"))
    
    dbDisconnect(con)           # st√§ng postgis-anslutningen igen
    
  } # slut funktion


koppla_punkter_postgis_tabell_till_pgr_graf <- 
  function(punkter_schema,
           punkter_tabellnamn,   
           punkter_geo_kol,
           schema_natverk = "nvdb",
           tabell_natverk = "nvdb20buff30",
           pg_db_user,
           pg_db_pwd ,
           pg_db_host,
           pg_db_port = 5432,
           pg_db_name_db) {
    
    # Skript f√∂r att l√§sa in en postgis-tabell som inneh√•ller m√•lpunkter som man vill g√∂ra ber√§kningar mot 
    # f√∂retr√§delsevis fr√•n boenderutor p√• avst√•nd eller restid med kortaste eller snabbaste resv√§g
    # fr√•n rutor (eller annan geografi som punkter) till n√§rmaste m√•lpunkt i denna tabell.
    # Det kan vara restid till n√§rmaste skola, v√•rdcentral eller bussh√•llplats fr√•n samtliga 
    # boenderutor i en geografi
    #
    # F√∂ljande parametrar skickas med funktionen:
    # malpunkter_tabellnamn = en textstr√§ng eller vektor om det finns flera filer med tabellnamnet som 
    #                    m√•lpunkterna ska ha i postgisdatabasen (b√∂r vara gemener och utan konstiga tecken)
    # schema_malpunkter = det schema i postgisdatabasen som m√•lpunktstabellen ska ligga under
    # malpunkter_id_kol = den kolumn som inneh√•ller ett unikt ID och g√∂rs till prim√§rnyckelkolumn, m√•ste finnas!
    # malpunkter_geo_kol = geometry-kolumnen
    # schema_natverk = det schema d√§r n√§tverket mot vilket vi ska koppla m√•lpunkterna finns 
    # tabell_natverk = den tabell d√§r n√§tverket mot vilket vi ska koppla m√•lpunkterna finns, m√•ste 
    #                  finnas under schemat ovan
    # pg_db_user = anv√§ndare f√∂r den postgisdatabas man ansluter till
    # pg_db_pwd = l√∂senord f√∂r anv√§ndaren ovan, OBS! Aldrig i klartext!
    # pg_db_host = adress till den server d√§r postgis-databasen finns
    # pg_db_port = den port som databasen ansluts via
    # pg_db_name_db = den databas i postgis som man ansluter till
    
    # L√§s in och bearbeta excelfiler med rutdata
    
    
    con <- dbConnect(          # use in other settings
      RPostgres::Postgres(),
      # without the previous and next lines, some functions fail with bigint data 
      #   so change int64 to integer
      bigint = "integer",  
      user = pg_db_user,
      password = pg_db_pwd,
      host = pg_db_host,
      port = pg_db_port,
      dbname = pg_db_name_db,
      options="-c search_path=public")
    
    # g√∂r en spatial join f√∂r mittpunkten i rutorna till nvdb
    
    # vi b√∂rjar med att skapa en ny kolumn i den nya tabellen
    dbExecute(con, paste0("ALTER TABLE ", punkter_schema, ".", punkter_tabellnamn,
                          " ADD COLUMN IF NOT EXISTS toponode_id bigint;"))
    
    # d√§refter g√∂r vi en spatial join fr√•n mittpunkten till noderna i nvdb
    dbExecute(con, paste0("UPDATE ", punkter_schema, ".", punkter_tabellnamn,
                          " SET toponode_id = (",
                          "SELECT ", schema_natverk, ".", tabell_natverk, "_vertices_pgr.id ",
                          "FROM ", schema_natverk, ".", tabell_natverk, "_vertices_pgr ",
                          "ORDER BY ", punkter_schema, ".", punkter_tabellnamn, ".", punkter_geo_kol, " <-> ",
                          schema_natverk, ".", tabell_natverk, "_vertices_pgr.the_geom ASC NULLS LAST ",
                          "LIMIT 1);"))
    
    dbDisconnect(con)           # st√§ng postgis-anslutningen igen
    
  } # slut funktion


skapa_n_narmaste_malpunkter_tabell <- function(
    n_narmaste = 10,                                  # hur m√•nga m√•lpunkter ska ber√§kningen g√∂ras p√•
    malpunkt_schema,                                  # schema d√§r m√•lpunkterna finns och d√§r rutorna finns  
    malpunkt_tabell,                                  # tabell som inneh√•ller de m√•lpunkter som ska ber√§knas
    malpunkt_toponode_id = "toponode_id",             # id-kolumn f√∂r toponode (f√∂r m√•lpunkt fr√•n rutt-grafen)
    malpunkt_id_kol = "id",                           # id-kolumn f√∂r m√•lpunktstabell
    malpunkt_ovr_kolumner = NA,                       # fylls p√• med vektor med kolumner som ocks√• ska med fr√•n m√•lpunktslagret
    mal_tab_n_narmaste,                               # ny tabell med n narmaste malpunkter f√∂r varje ruta
    startpunkt_schema,
    startpunkt_tabell,                                       # tabell som inneh√•ller de rutor d√§r slutresultaten ska l√§ggas i
    startpunkt_tabell_id_kol,                      # id-kolumn f√∂r ruttabell
    startpunkt_geom_kol, 
    startpunkt_toponode_id = "toponode_id",                  # id-kolumn f√∂r toponode (f√∂r rutlager fr√•n rutt-grafen)
    startpunkt_tabell_malschema,
    pg_db_user,
    pg_db_pwd,
    pg_db_host,
    pg_db_port,
    pg_db_name_db
){
  
  # ber√§kna n n√§rmaste malpunkter till varje ruta 
  starttid <- Sys.time()
  
  # skapa textvariabel av medskickade m√•lpunktskolumner
  if (!is.na(malpunkt_ovr_kolumner[1])) {
    
    # f√∂r anv√§ndning i f√∂rsta delen av sql-skriptet
    malp_ovr_kol <- malpunkt_ovr_kolumner
    malp_ovr_kol <- paste0("malp.", malp_ovr_kol, collapse = ", ")
    malp_ovr_kol <- paste0(malp_ovr_kol, ", ")
    
    # f√∂r anv√§ndning i f√∂rsta delen av sql-skriptet
    m_ovr_kol <- malpunkt_ovr_kolumner
    m_ovr_kol <- paste0("m.", m_ovr_kol, collapse = ", ")
    m_ovr_kol <- paste0(m_ovr_kol, ", ")
    
  } else {
    malp_ovr_kol <- ""
    m_ovr_kol <- ""
  }
  
  con_n_narmaste <- dbConnect(          # use in other settings
    RPostgres::Postgres(),
    # without the previous and next lines, some functions fail with bigint data 
    #   so change int64 to integer
    bigint = "integer",  
    user = pg_db_user,
    password = pg_db_pwd,
    host = pg_db_host,
    port = pg_db_port,
    dbname = pg_db_name_db,
    options="-c search_path=public")  
  
  # ta bort tabell om den redan finns
  dbExecute(con_n_narmaste, paste0("DROP TABLE IF EXISTS ", 
                                   malpunkt_schema, ".", mal_tab_n_narmaste, ";"))
  
  # skapa en tabell med alla startpunkter och de n n√§rmaste m√•lpunkterna f√•gelv√§gen
  # denna tabell anv√§nds sedan f√∂r att ber√§kna n√§rmaste m√•lpunkt i grafen/n√§tverket
  dbExecute(con_n_narmaste, paste0("CREATE TABLE ",
                                   malpunkt_schema, ".", mal_tab_n_narmaste, " AS ",
                                   "(SELECT start.", startpunkt_tabell_id_kol, ", ",
                                   "start.", startpunkt_toponode_id, " AS start_toponode_id, ",
                                   #"rut.geom_polygon AS rut_geom_polygon, ", 
                                   "start.", startpunkt_geom_kol, " AS start_geom_point, ",
                                   "malp.", malpunkt_id_kol, ", ",
                                   "malp.", malpunkt_toponode_id, " AS mal_toponode_id, ",
                                   malp_ovr_kol,
                                   "malp.geom AS mal_geom, ", 
                                   "malp.dist ",
                                   "FROM ", malpunkt_schema, ".", startpunkt_tabell_malschema, " AS start ",
                                   "CROSS JOIN LATERAL (",
                                   "SELECT m.", malpunkt_id_kol, ", ",
                                   "m.", malpunkt_toponode_id, ", ",
                                   "m.geom, ",
                                   m_ovr_kol, 
                                   "m.geom <-> start.", startpunkt_geom_kol, " AS dist ",
                                   "FROM ", malpunkt_schema, ".", malpunkt_tabell, " AS m ",
                                   "ORDER BY dist ", 
                                   "LIMIT ", n_narmaste, " ",
                                   ") AS malp );"))
  
  dbDisconnect(con_n_narmaste)           # st√§ng postgis-anslutningen igen
  print(paste0("Det tog ", round(difftime(Sys.time(), starttid, units = "min"),2) , 
               " minuter att ber√§kna f√•gelavst√•nd till de ", n_narmaste , 
               " n√§rmaste m√•lpunkterna fr√•n varje startpunkt i k√∂rningen."))
  
}

berakna_pgr_dijkstracost_n_narmaste_tab <- function(
    natverk_schema,
    natverk_tabell,
    start_toponode_id,
    mal_toponode_id,
    malpunkt_schema,
    mal_tab_n_narmaste,
    cost_col_natverk,
    cost_col_ny,
    pg_db_user,
    pg_db_pwd,
    pg_db_host,
    pg_db_port,
    pg_db_name_db){
  
  starttid <- Sys.time()
  
  con_dijkstra <- dbConnect(          # use in other settings
    RPostgres::Postgres(),
    # without the previous and next lines, some functions fail with bigint data 
    #   so change int64 to integer
    bigint = "integer",  
    user = pg_db_user,
    password = pg_db_pwd,
    host = pg_db_host,
    port = pg_db_port,
    dbname = pg_db_name_db,
    options="-c search_path=public")  
  
  # ber√§kna avst√•nd meter f√∂r alla m√•lpunkter 
  # Skapa kolumn f√∂r avst√•nd i meter mellan ruta och m√•lpunkt
  dbExecute(con_dijkstra, paste0("ALTER TABLE ", 
                                 malpunkt_schema, ".", mal_tab_n_narmaste, " ",
                                 "ADD COLUMN IF NOT EXISTS ", cost_col_ny, " double precision;"))
  
  # d√§refter uppdaterar vi kolumnen med v√§rdet fr√•n pgRoutring - dijkstraCost
  dbExecute(con_dijkstra, paste0("UPDATE ", malpunkt_schema, ".", mal_tab_n_narmaste, " ",
                                 "SET ", cost_col_ny, " = a.agg_cost ", 
                                 "FROM (",
                                 "SELECT * FROM pgr_dijkstraCost(",
                                 "'SELECT id, source, target, ", cost_col_natverk, " as cost FROM ",
                                 natverk_schema, ".", natverk_tabell, "',",
                                 "'SELECT ", rut_toponode_id, " as source, ", 
                                 mal_toponode_id, " as target FROM ", malpunkt_schema, ".", 
                                 mal_tab_n_narmaste, "', ",
                                 "FALSE)) as a ",
                                 "WHERE (", malpunkt_schema, ".", mal_tab_n_narmaste, ".", 
                                 rut_toponode_id, " = a.start_vid AND ", 
                                 malpunkt_schema, ".", mal_tab_n_narmaste, ".", mal_toponode_id, " = a.end_vid);"))
  
  # byt ut NULL mot 0 om startnoden (ruta) √§r samma som slutnoden (h√•llplats)
  dbExecute(con_dijkstra, paste0("UPDATE ", malpunkt_schema, ".", mal_tab_n_narmaste, " ",
                                 "SET ", cost_col_ny, " = 0 ",
                                 "WHERE ", rut_toponode_id, " = ", mal_toponode_id, ";"))
  
  dbDisconnect(con_dijkstra)           # st√§ng postgis-anslutningen igen
  print(paste0("Det tog ", round(difftime(Sys.time(), starttid, units = "min"),2) , " minuter att ber√§kna pgr_Dijkstra"))
  
  
}

join_narmaste_malpunkt_fran_n_narmaste <- function(
    malpunkt_schema,
    mal_start_tabell,
    mal_n_narmaste_tab,
    cost_col_n_narmaste_tab,
    cost_mal_start_tab_ny,
    namn_malpunkt_kol = "",
    n_narm_tab_startid_kol, 
    mal_start_tab_startid_kol,
    pg_db_user,
    pg_db_pwd,
    pg_db_host,
    pg_db_port,
    pg_db_name_db){
  
  starttid <- Sys.time()
  
  con_join <- dbConnect(          # use in other settings
    RPostgres::Postgres(),
    # without the previous and next lines, some functions fail with bigint data 
    #   so change int64 to integer
    bigint = "integer",  
    user = pg_db_user,
    password = pg_db_pwd,
    host = pg_db_host,
    port = pg_db_port,
    dbname = pg_db_name_db,
    options="-c search_path=public") 
  
  # skapa en textstr√§ng om namn_malpunkt_kol har ett v√§rde (som inte √§r "") f√∂r att skapa kolumn och f√∂r att koda v√§rdet
  if (namn_malpunkt_kol == ""){ 
    lagg_till_namn_malpunkt_kol <- ""
    set_namn <- " "
    from_namn <- ""
    groupby_namn <- ""
  } else {
    lagg_till_namn_malpunkt_kol <- paste0(", ADD COLUMN IF NOT EXISTS ", cost_mal_start_tab_ny, "_", namn_malpunkt_kol, " text")
    set_namn <- paste0(", ", cost_mal_start_tab_ny, "_", namn_malpunkt_kol, " = B.", namn_malpunkt_kol, " ")
    from_namn <- paste0(", ", namn_malpunkt_kol)
    groupby_namn <- paste0(", ", namn_malpunkt_kol)
  }
  
  # skapa kolumn om den inte redan finns
  dbExecute(con_join, paste0("ALTER TABLE ", malpunkt_schema, ".", mal_start_tabell, " ",
                             "ADD COLUMN IF NOT EXISTS ", cost_mal_start_tab_ny, " double precision", 
                             lagg_till_namn_malpunkt_kol, ";"))
  
  # och s√• joinar vi p√• kolumnen fr√•n aktuell tabell
  dbExecute(con_join, paste0("UPDATE ", malpunkt_schema, ".", mal_start_tabell, " AS A ",
                             "SET ", cost_mal_start_tab_ny, " = B.minavst", set_namn,
                             "FROM (SELECT DISTINCT ON(", n_narm_tab_startid_kol, ") ",
                             n_narm_tab_startid_kol, from_namn, ", ", cost_col_n_narmaste_tab, " AS minavst ",
                             " FROM ", malpunkt_schema, ".", mal_n_narmaste_tab, " ",
                             "ORDER BY ", n_narm_tab_startid_kol, ", ", cost_col_n_narmaste_tab, ") ",
                             "AS B ",
                             "WHERE A.", mal_start_tab_startid_kol, " = B.", n_narm_tab_startid_kol, ";"))
  
  
  # MIN(", cost_col_n_narmaste_tab, ") as minavst, ", n_narm_tab_startid_kol,
  # from_namn, " FROM ", malpunkt_schema, ".", mal_n_narmaste_tab, " ", 
  # "GROUP BY ", n_narm_tab_startid_kol, groupby_namn, ") ",
  # "AS B ",
  # "WHERE A.", mal_rut_tab_rutid_kol, " = B.", n_narm_tab_startid_kol, ";"))
  
  dbDisconnect(con_join)           # st√§ng postgis-anslutningen igen
  
  print(paste0("Det tog ", round(difftime(Sys.time(), starttid, units = "min"),2) , " minuter att k√∂ra funktionen"))
  
}


koppla_kommun_till_geokol_i_tabell <- function(
    schema,                              # det schema i vilken tabellen finns som man vill h√§mta
    tabell,                              # den tabell i postgisdatabasen man vill h√§mta
    geo_kol,                             # geometrikolumn som ska anv√§ndas (b√∂r helst vara punktgeometrier)
    filter_lan = "",                     # l√§nskod att filtrera p√• om man vill, vid "" s√• g√∂rs ingen filtrering
    kommunnamn_ny_kol = "kommun",        # vad kommunnamnskolumnen d√∂ps till
    kommunkod_ny_kol = "kommunkod",      # vad kommunkodskolumnen d√∂ps till
    kommun_schema = "karta",             # schema d√§r kommunpolygonerna finns som vi anv√§nder att spatial-joina fr√•n
    kommun_tabell = "kommun_polygon",    # tabell d√§r kommunpolygonerna finns som vi anv√§nder att spatial-joina fr√•n
    kommun_kommunkod = "kommunkod",        # kolumn d√§r kommunkoden finns i tabell som vi anv√§nder f√∂r att joina fr√•n
    kommun_lanskod = "lankod",          # kolumn d√§r l√§nskoden finns i tabell som vi anv√§nder f√∂r att joina fr√•n
    kommun_kommunnamn = "kommun",    # kolumn d√§r kommunnamnet finns i tabell som vi anv√§nder f√∂r att joina fr√•n
    kommun_geokol = "geom",              # geometrikolumn i tabell f√∂r kommunpolygoner
    pg_db_user,
    pg_db_pwd,
    pg_db_host,
    pg_db_port,
    pg_db_name_db) {
  
  starttid <- Sys.time()
  
  con_join_kommun <- dbConnect(          # use in other settings
    RPostgres::Postgres(),
    # without the previous and next lines, some functions fail with bigint data 
    #   so change int64 to integer
    bigint = "integer",  
    user = pg_db_user,
    password = pg_db_pwd,
    host = pg_db_host,
    port = pg_db_port,
    dbname = pg_db_name_db,
    options="-c search_path=public") 
  
  if (filter_lan == "") {
    # om filter_lan √§r tomt, dvs. vi ska inte g√∂ra n√•gon filtrering
    filter_lan <- paste0(")")
  } else {
    # om l√§nskod √§r medskickad
    filter_lan <- paste0(") AND k.", kommun_lanskod, " = '", filter_lan, "'")
  }
  
  # vi b√∂rjar med att skapa kolumner f√∂r kommunkod och kommunnamn
  dbExecute(con_join_kommun, paste0("ALTER TABLE ", schema, ".", tabell, " ",
                                    "ADD COLUMN IF NOT EXISTS ", kommunkod_ny_kol, " character varying, ",
                                    "ADD COLUMN IF NOT EXISTS ", kommunnamn_ny_kol, " character varying;"))
  
  # d√§refter kopplar vi kommunkod till varje punkt i tabellen
  dbExecute(con_join_kommun, paste0("UPDATE ", schema, ".", tabell, " ",
                                    "SET ", kommunkod_ny_kol, " = (SELECT ", kommun_kommunkod, " ",
                                    "FROM ", kommun_schema, ".", kommun_tabell, " AS k ",
                                    "WHERE st_contains(k.", kommun_geokol, ", ", schema, ".", tabell, ".",
                                    geo_kol, filter_lan, ");"))
  
  # och s√• kopplar vi √§ven kommunnamn till varje punkt i tabellen
  dbExecute(con_join_kommun, paste0("UPDATE ", schema, ".", tabell, " ",
                                    "SET ", kommunnamn_ny_kol, " = (SELECT ", kommun_kommunnamn, " ",
                                    "FROM ", kommun_schema, ".", kommun_tabell, " AS k ",
                                    "WHERE st_contains(k.", kommun_geokol, ", ", schema, ".", tabell, ".",
                                    geo_kol, filter_lan, ");"))
  
  dbDisconnect(con_join_kommun)           # st√§ng postgis-anslutningen igen
  
  print(paste0("Det tog ", round(difftime(Sys.time(), starttid, units = "sec"),2) , " sekunder att koppla kommuner till tabellen."))
  
}

# ================================= Qgis funktioner ================================================


# ------------------- kraftf√§lt -------------------------


# Skapad av Henrik Ald√©n fr√•n SWECOS skript G:/skript/gis/sweco_dec_2022/orginalskript/ del1_kraftf√§lt_QGIS_plugin(_uppdaterad).r

# F√∂r att funktionen ska fungera, k√∂r f√∂rst funktionen skapa_vagnatverk_tatort() som finns i func_GIS. Denna funktion skapar n√∂dv√§ndiga tabeller i PostGIS.
# en uppdatering kommer att g√∂ras f√∂r att skapa dessa tabeller direkt i funktionen eller att det ska g√• at l√§sa in sf_objekt ist√§llet f√∂r att anv√§nda PostGIS.

# source("https://raw.githubusercontent.com/Region-Dalarna/funktioner/main/func_GIS.R", encoding = "utf-8", echo = FALSE)
# skapa_vagnatverk_tatort()

# LOGIKEN F√ñR ANALYSEN F√ñLJER
# 
# enskilt_troskelvarde=15%
# totalt_troskelvarde=40%
# 
# LA: 
#   ingen enskild utpendlingsrelation √∂ver 15% och total utpendling under 40%
#   
#   Solit√§r: 
#   ingen enskild utpendlingsrelation √∂ver 15% och total utpendling √∂ver 40%
#   
#   Satellit:
#   minst en enskild utpendlingsrelation √∂ver 15% (oberoende av total utpendling)
# 
# CommonLA:
#   tv√• orter som ej √§r LA enskilt (utan satelliter) men har st√∂rst pendling till varandra som √§r √∂ver 15%
# 
# Prim√§rtLA/Sekund√§rtLA:
#   en satellit kan tillh√∂ra tv√• LA och dom rankas d√• baserat p√• utpendlingsandel.
# t√§torten som st√∂rst andel av utpendling sker till klassas som prim√§rtLA och n√§st st√∂rst blir sekund√§rtLA.
# - l√§gre niv√•er (som tredje st√∂rsta) tas ej med.
# 

#   metod √§r att:
#   1. klassificera t√§torter som LA/Solit√§r/Satelliter/CommonLA
#   2. ber√§kna vilka LA som satelliter tillh√∂r samt prim√§rt/sekund√§rt LA
#   3. k√∂ra ruttning mellan satelliter och LA (k√∂r √§ven ruttning mellan satelliter och solit√§rer och andra satelliter)
#   4. skapa kraftf√§ltspolygoner genom buffer av resv√§g mellan satelliter f√∂r LA t√§torter.
# 

# h√§mta data fr√•n sekretessdatabasen
# tabell med pendlingsrelationer
# tabell_pend_relation <- postgis_postgistabell_till_sf(
#   schema = "rutor",
#   tabell = "pend_relation_tatorter",
#   con = uppkoppling_db(service = "rd_geodata", db_name = "sekretess")
# )

pendling_kraftfalt <- function(
    tabell_pend_relation, # Dataframe med pendlingsrelationer h√§mtas f√∂rslagsvis p√• MONA
    ut_mapp = NA, # data ut ur funktionen
    gpkg_namn = NA, # namn p√• geopackage i utmappen
    enskilt_troskelvarde = 20, # enskilt troskelv√§rde
    totalt_troskelvarde = 35, # totalt troskelv√§rde
    primar_la_buffer = 2000, # buffer f√∂r prim√§rt LA
    sekundar_la_buffer = 1000, # buffer f√∂r sekund√§rt LA
    gemensam_la_buffer = 5000, # har ej sett denna i resultat! 
    con = NA, # uppkoppling till PostGIS, kr√§vs en connection, om inte anges finns et default v√§rde till Region Dalarnas databas
    dist = 2000, # max avst√•nd till v√§gn√§tet
    skriv_till_gpkg = FALSE # TRUE om resultatet ska skrivas till geopackage, annars returneras som en lista
) { 
  library(readxl)
  library(stringr)
  library(dplyr)
  library(sf)
  library(DBI)
  library(RPostgres)
  library(purrr)
  
  #source("https://raw.githubusercontent.com/Region-Dalarna/funktioner/main/func_GIS.R", encoding = "utf-8", echo = FALSE)
  
  # fyll i som ett argument till funktionen annars anv√§nds default v√§rden
  if (is.na(ut_mapp)) {
    ut_mapp <- "G:/skript/gis/sweco_dec_2022/utdata"
  }
  # det namn du ger din geopackage annars anv√§nds default v√§rden
  if (is.na(gpkg_namn)) {
    gpkg_namn <- "kraftf√§lt.gpkg"
  }
  # uppkoppling till din Postgres databas annars anv√§nds default v√§rden till Region Dalarnas databas med keyring()
  if (is.na(con)) {
    con <- uppkoppling_db(service = "rd_geodata")
  }
  
  dbExecute(con, "SET search_path TO grafer, public;") # denna √§r lite mystisk, men det funkar...
  
  # nedan 4 objekt kommer fr√•n funktionen skapa_vagnatverk_tatort() och ligger i schemat grafer
  kant_tabell <- "nvdb_noded" # en graf av v√§gn√§tet
  nod_tabell <- "grafer.nvdb_noded_vertices_pgr"# en graf av v√§gn√§tet
  
  kost_kol = "dist_cost" # kolumn i nvdb_noded med kostnad
  omvand_kost_kol = "dist_reverse_cost" # kolumn i nvdb_noded med omv√§nd kostnad
  
  # simpel funktion f√∂r att skriva postgis tabell till gpkg om skriv_till_gpkg=TRUE
  skriv_pg_tab_gpkg <- function(lyrname, ut_mapp, gpkg_namn, append=FALSE, delete_dsn=FALSE) {
    lyr <- st_read(con, lyrname)
    st_write(lyr, 
             file.path(ut_mapp, gpkg_namn),
             lyrname, 
             append=append,
             delete_dsn=delete_dsn
    )  
  }  
  
  # # l√§s in pendlingsdata
  # tabell_pend_relation <- read_csv(tabell_pend_relation, locale = locale(encoding = "ISO-8859-1"))%>%
  #   mutate(
  #     from_id = substr(from_id, 3, 11), # tar bort l√§nskoden och t√§tortsnamnet fr√•n t.ex. 202084TC101 Avesta
  #     to_id = substr(to_id, 3, 11)      # tar bort l√§nskoden och t√§tortsnamnet fr√•n t.ex. 202080TC108 Falun
  #   ) %>% 
  #   select(from_id, to_id, n) # v√§ljer ut kolumner fr√•n_id, to_id och antal pendlare (n)
  # 
  if (!all(c("from_id", "to_id", "n") %in% colnames(tabell_pend_relation))) { # tabell_pend_relation_ruta m√•ste inneh√•lla dessa kolumner
    stop("`tabell_pend_relation` must contain the columns: 'from_id', 'to_id', 'n'.") # felmeddelande om inte dessa kolumner finns i tabell_pend_relation_ruta
  }
  
  # dbWriteTable(con, 'grafer.data', data, overwrite=TRUE, temporary=FALSE) # denna skriv till grafer.grafer.data !!
  dbWriteTable(con, 'data', tabell_pend_relation, overwrite=TRUE, temporary=FALSE) # skriver till grafer.data s√•ledes schema grafer
  
  
  # hitta n√§rmaste vertex i v√§gn√§tet till varje t√§tort
  query <- str_glue("CREATE TEMP TABLE tatort_vertex AS
                      SELECT t.tokod, e.id, e.dist
                      FROM tatort t
                      JOIN lateral(
                        SELECT id, e.geom <-> t.geom as dist
                          FROM {nod_tabell} e
                        ORDER BY t.geom <-> e.geom
                        LIMIT 1
                      ) AS e
                      ON true
                      WHERE dist < {dist};")
  dbExecute(con, "DROP TABLE IF EXISTS tatort_vertex;")
  dbExecute(con, query)
  
  query <- str_glue("CREATE TABLE commute_combinations AS
                      with temp_pendlings_data as (
                      	SELECT
                      	      from_id,
                      	      to_id,
                      	      n,
                      	      sum(n) OVER w AS totalworkers, /* totalt antal arbetare i from_id */
                      	      sum(n) FILTER (WHERE from_id=to_id) OVER w AS localworkers /* totalt antal lokala arbetare i from_id */
                        from grafer.data
                        WHERE from_id IN (SELECT tokod FROM tatort_vertex)
                        WINDOW w AS (PARTITION BY from_id)
                      )
                      SELECT
                            from_id,
                            to_id,
                            n,
                            totalworkers,
                            localworkers,
                            100*n::DECIMAL/totalworkers AS perc, /* %-andel arbetare fr√•n from_id till to_id*/
                            100-100*localworkers/totalworkers as perc_total_commuters, /* %-andel totala pendlare fr√•n from_id*/
                            case 
                            	when from_id=to_id then 0 /* relationen from_id till from_id f√•r ranking 0 */
                            	else count(*) FILTER (WHERE from_id <> to_id) OVER wd /* ranking av relationer fr√•n mest pendlare till minst */
                            end AS ranking 
                      FROM temp_pendlings_data
                      WHERE to_id IN (SELECT tokod FROM tatort_vertex)
                      window wd AS (PARTITION BY from_id ORDER BY n DESC)
                      order by from_id, n desc;")
  dbExecute(con, "DROP TABLE IF EXISTS commute_combinations;")
  dbExecute(con, query)
  
  
  # la
  query <- str_glue("CREATE TEMP TABLE la AS
                  SELECT 
                      c.from_id AS id, c.totalworkers, 
                      c.localworkers, c.perc_total_commuters,
                      t.tobeteckn, t.lan, t.kommun, 
                      t.kommunnamn, t.geom 
                  FROM commute_combinations c
                  JOIN grafer.tatort t ON t.tokod = c.from_id
                  WHERE ranking = 1 
                    AND perc <= {enskilt_troskelvarde} 
                    AND perc_total_commuters <= {totalt_troskelvarde};")
  dbExecute(con, "DROP TABLE IF EXISTS la;")
  dbExecute(con, query)
  
  # skriv till geopackage
  # skriv_pg_tab_gpkg(str_glue("la"), ut_mapp, gpkg_namn)
  
  # solit√§r
  query <- str_glue("CREATE TEMP TABLE solitary AS
                  select 
                    	c.from_id as id, c.totalworkers, 
                    	c.localworkers, c.perc_total_commuters,
                    	t.tobeteckn, t.lan,t.kommun, 
                    	t.kommunnamn,t.geom 
                    from commute_combinations c
                    join grafer.tatort t on t.tokod=c.from_id
                  where ranking=1 and perc <= {enskilt_troskelvarde}
                  and perc_total_commuters > {totalt_troskelvarde}
                  ;")
  dbExecute(con, "DROP TABLE IF EXISTS solitary;")
  dbExecute(con, query)
  # skriv till geopackage
  # skriv_pg_tab_gpkg(str_glue("solitary"), ut_mapp, gpkg_namn)
  
  
  # common la
  query <- str_glue("CREATE TEMP TABLE common_la AS
                  WITH sats AS (
                     SELECT *
                     FROM commute_combinations
                     WHERE ranking > 1 AND perc > {enskilt_troskelvarde}
                  ), common_la_cte AS (
                     SELECT a.*
                     FROM sats a
                     JOIN sats b ON a.from_id = b.to_id AND a.to_id = b.from_id
                  )
                  SELECT
                     c.from_id AS id, c.to_id AS common_la, 
                     c.totalworkers, c.localworkers, c.perc_total_commuters,
                     t.tobeteckn, t.lan, t.kommun, t.kommunnamn, t.geom
                  FROM common_la_cte c
                  JOIN grafer.tatort t ON t.tokod = c.from_id;")
  
  dbExecute(con, "DROP TABLE IF EXISTS common_la;")
  dbExecute(con, query)
  # skriv till geopackage
  # skriv_pg_tab_gpkg(str_glue("common_la"), ut_mapp, gpkg_namn)
  
  # satelit
  query <- str_glue("CREATE TEMP TABLE satellites AS
                  WITH sats AS (
                      SELECT *
                      FROM commute_combinations
                      WHERE ranking IN (1, 2) 
                        AND perc > {enskilt_troskelvarde}
                        AND from_id NOT IN (SELECT id FROM common_la)
                  ), la_id AS (
                      SELECT id FROM la 
                      UNION 
                      SELECT id FROM common_la
                  ), agg AS (
                      SELECT 
                          from_id, 
                          array_agg(to_id ORDER BY ranking) AS id_array_all,
                          array_agg(to_id ORDER BY ranking) FILTER (WHERE to_id IN (SELECT id FROM la_id)) AS id_array
                      FROM sats
                      GROUP BY from_id
                  )
                  SELECT 
                      a.from_id AS id,
                      id_array[1] AS primary_la, 
                      id_array[2] AS secondary_la,
                      id_array_all[1] AS primary_destination,
                      id_array_all[2] AS secondary_destination,
                      s.totalworkers, s.localworkers, s.perc_total_commuters,
                      t.tobeteckn, t.lan, t.kommun, t.kommunnamn, t.geom
                  FROM agg a
                  JOIN sats s ON a.from_id = s.from_id
                  JOIN grafer.tatort t ON t.tokod = s.from_id;")
  dbExecute(con, "DROP TABLE IF EXISTS satellites;")
  dbExecute(con, query)
  
  # skriv till geopackage
  # skriv_pg_tab_gpkg(str_glue("satellites"), ut_mapp, gpkg_namn)
  
  # ruttningsanalys
  
  # tabell med allar rutter som ska k√∂ras (satelliter+commonLA)
  query <- str_glue("CREATE TEMP TABLE route_combinations AS
                    with sats as (
                    	select from_id, to_id, ranking
                    	from commute_combinations
                    	where ranking in (1,2) 
                    		and perc > {enskilt_troskelvarde}
                    )
                    select s.*, f.id as start_vid, t.id as end_vid
                    from sats s
                    JOIN tatort_vertex f ON f.tokod=s.from_id
                    JOIN tatort_vertex t ON t.tokod=s.to_id
                  ;")
  dbExecute(con, "DROP TABLE IF EXISTS route_combinations;")
  dbExecute(con, query)
  
  
  query <- str_glue("CREATE TEMP TABLE routes AS
                  WITH astar AS( 
                    SELECT * FROM pgr_aStar(
                      'SELECT id, source, target,
                              {kost_kol} AS cost,
                              {omvand_kost_kol} AS reverse_cost,
                              x1, y1, x2, y2
                  	   FROM grafer.{kant_tabell}',
                      'SELECT 
                        start_vid AS source, 
                        end_vid AS target
                      FROM route_combinations'
                    )
                  ), paths AS(
                    SELECT 
                      a.start_vid, 
                      a.end_vid,
                      sum(a.cost) AS cost,
                      max(a.agg_cost) AS agg_cost,
                      st_LineMerge(st_union(r.geom)) AS geom
                    FROM astar a JOIN grafer.{kant_tabell} r ON a.edge=r.id
                    GROUP BY a.start_vid, a.end_vid
                  )
                  SELECT c.*, p.agg_cost, p.geom
                  FROM route_combinations c 
                  JOIN paths p ON c.start_vid=p.start_vid 
                    and c.end_vid=p.end_vid")
  dbExecute(con, "DROP TABLE IF EXISTS routes;")
  dbExecute(con, query)
  # skriv_pg_tab_gpkg(str_glue("routes"), ut_mapp, gpkg_namn)
  
  
  # rutter till secondary LA
  query <- str_glue("CREATE TEMP TABLE secla_areas AS
          select
            to_id, MAX(ranking) AS max_ranking,
            st_buffer(st_collect(r.geom), {sekundar_la_buffer}) as geom
          from satellites s
          join routes r on s.id=r.from_id and s.secondary_la=r.to_id
          group by to_id
          ;")
  dbExecute(con, "DROP TABLE IF EXISTS secla_areas;")
  dbExecute(con, query)
  # skriv_pg_tab_gpkg(str_glue("secla_areas"), ut_mapp, gpkg_namn)
  
  # rutter till primary LA
  query <- str_glue("CREATE TEMP TABLE primla_areas AS
          select
            to_id, max(ranking),
            st_buffer(st_collect(r.geom), {primar_la_buffer}) as geom
          from satellites s
          join routes r on s.id=r.from_id and s.primary_la=r.to_id
          group by to_id
          ;")
  dbExecute(con, "DROP TABLE IF EXISTS primla_areas;")
  dbExecute(con, query)
  # skriv_pg_tab_gpkg(str_glue("primla_areas"), ut_mapp, gpkg_namn)
  
  # rutter mellan CommonLA
  query <- str_glue("CREATE TEMP TABLE commonla_areas AS
          select
            from_id, to_id, ranking,
            st_buffer(r.geom, {gemensam_la_buffer}) as geom
          from common_la s
          join routes r on s.id=r.from_id and s.common_la=r.to_id
          ;")
  dbExecute(con, "DROP TABLE IF EXISTS commonla_areas;")
  dbExecute(con, query)
  # skriv_pg_tab_gpkg(str_glue("commonla_areas"), ut_mapp, gpkg_namn)
  
  # Define layers to process
  layers <- c(
    "la", 
    "solitary", 
    "common_la", 
    "satellites", 
    "routes", 
    "secla_areas", 
    "primla_areas", 
    "commonla_areas"
  )
  
  # Write layers to GeoPackage or return as a list
  if (skriv_till_gpkg) {
    # Write only non-empty layers to the GeoPackage
    purrr::walk(
      layers,
      ~ {
        tryCatch({
          # Check if the layer exists in the database
          query <- str_glue("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '{str_remove(.x, 'grafer.')}')")
          layer_exists <- dbGetQuery(con, query)[1, 1]
          
          if (layer_exists) {
            lyr <- st_read(con, query = str_glue("SELECT * FROM {.x}"))
            if (nrow(lyr) > 0) { # Only write if the layer is non-empty
              skriv_pg_tab_gpkg(
                lyrname = str_remove(.x, "grafer."), # Remove schema prefix for GPKG
                ut_mapp = ut_mapp,
                gpkg_namn = gpkg_namn,
                append = TRUE # Append layers to the same GeoPackage
              )
            } else {
              message(glue("Layer `{.x}` is empty, skipping..."))
            }
          } else {
            message(glue("Layer `{.x}` does not exist, skipping..."))
          }
        }, error = function(e) {
          message(glue("Error processing layer `{.x}`: {e$message}"))
        })
      }
    )
    message(glue("Finished writing non-empty layers to {file.path(ut_mapp, gpkg_namn)}"))
  } else {
    # Create a named list with all layers, include NULL for missing or empty layers
    results <- purrr::map(
      layers,
      ~ {
        tryCatch({
          query <- str_glue("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '{str_remove(.x, 'grafer.')}')")
          layer_exists <- dbGetQuery(con, query)[1, 1]
          
          if (layer_exists) {
            lyr <- st_read(con, query = str_glue("SELECT * FROM {.x}"))
            if (nrow(lyr) > 0) {
              return(lyr) # Return non-empty layer
            } else {
              message(glue("Layer `{.x}` is empty, skipping..."))
              return(NULL)
            }
          } else {
            message(glue("Layer `{.x}` does not exist, skipping..."))
            return(NULL)
          }
        }, error = function(e) {
          message(glue("Error processing layer `{.x}`: {e$message}"))
          return(NULL)
        })
      }
    )
    # Name results list with the layer names (sans schema)
    names(results) <- str_remove(layers, "grafer.")
    return(results)
  }
}

# # # # Exempel p√• hur funktionen kan anv√§ndas
# # # 
# kraftfalt_15_35 <- pendling_kraftfalt(tabell_pend_relation = tabell_pend_relation, 
#                                       enskilt_troskelvarde = 15, 
#                                       totalt_troskelvarde = 35)
# #
# # # Define custom colors for better readability
# road_color <- "#4D4D4D" # Dark gray for roads
# area_color <- "green" # Green for areas
# point_color_primary <- "red" # Red for primary points
# point_color_secondary <- "orange" # Orange for secondary points
# #
# # # Update mapview layers
# mapview::mapview(kraftfalt_15_35$la, col.regions = area_color, alpha.regions = 0.5, cex = 6) +
#   mapview::mapview(kraftfalt_15_35$solitary, col.regions = point_color_secondary, cex = 4) +
#   mapview::mapview(kraftfalt_15_35$routes, color = road_color, lwd = 2)  +
#   mapview::mapview(kraftfalt_15_35$satellites, col.regions = point_color_primary, cex = 3)+
#   mapview::mapview(kraftfalt_15_35$primla_areas, col.regions = "blue", alpha.regions = 0.3)+
#   mapview::mapview(kraftfalt_15_35$secla_areas, col.regions = "orange", alpha.regions = 0.4)

# ------------------- pendlingsn√§tverk -------------------------

# Funktionen skapar ett pendlingsn√§tverk och ber√§knar det sammanlagda antalet pendlare per v√§gstr√§cka. 
# Resultatet kan sparas som ett GeoPackage eller returneras som ett R-objekt. 
# Skriptet kr√§ver en tabell med pendlingsrelationer och v√§gn√§t h√§mtas fr√•n en PostGIS-databas.

# F√∂r att funktionen ska fungera, k√∂r f√∂rst funktionen skapa_vagnatverk_tatort() som finns i func_GIS. Denna funktion skapar n√∂dv√§ndiga tabeller i PostGIS.
# en uppdatering kommer att g√∂ras f√∂r att skapa dessa tabeller direkt i funktionen eller att det ska g√• at l√§sa in sf_objekt ist√§llet f√∂r att anv√§nda PostGIS.

# source("https://raw.githubusercontent.com/Region-Dalarna/funktioner/main/func_GIS.R", encoding = "utf-8", echo = FALSE)
# skapa_vagnatverk_tatort()

# tabell med pendlingsrelationer
# tabell_pend_relation <- postgis_postgistabell_till_sf(
#   schema = "rutor",
#   tabell = "pend_relation_tatorter",
#   con = uppkoppling_db(service = "rd_geodata", db_name = "sekretess")
# )

pendling_natverk <- function(
    tabell_pend_relation, # Dataframe med pendlingsrelationer h√§mtas f√∂rslagsvis p√• MONA
    con = NA, # uppkoppling till PostGIS, kr√§vs en connection, om inte anges finns et default v√§rde till Region Dalarnas databas
    dist = 2000, # max avst√•nd till v√§gn√§tet
    skriv_till_gpkg = FALSE, # flagga f√∂r att skriva till geopackage
    ut_mapp = NA, # mapp att skriva till
    gpkg_namn = NA # namn p√• geopackage
) { 
  
  library(readxl)
  library(stringr)
  library(dplyr)
  library(sf)
  library(DBI)
  library(RPostgres)
  
  #source("https://raw.githubusercontent.com/Region-Dalarna/funktioner/main/func_GIS.R", encoding = "utf-8", echo = FALSE)
  
  # Hantera NA i parametrar
  # d√§r du eventuellt sparar data lokalt
  if (is.na(ut_mapp)) {
    ut_mapp <- "G:/skript/gis/sweco_dec_2022/utdata"
  }
  # det namn du ger din geopackage
  if (is.na(gpkg_namn)) {
    gpkg_namn <- "pendling_natverk.gpkg"
  }
  # uppkoppling till din Postgres databas
  if (is.na(con)) {
    con <- uppkoppling_db(service = "rd_geodata")
  }
  
  dbExecute(con, "SET search_path TO grafer, public;") # denna √§r lite mystisk, men det funkar...
  
  # v√§gn√§tet skapat med skapa_vagnatverk_tatort() ligger i schema grafer
  kant_tabell <- "nvdb_noded" 
  nod_tabell <- "grafer.nvdb_noded_vertices_pgr" 
  
  kost_kol = "dist_cost" # kolumn i nvdb_noded med kostnad
  omvand_kost_kol = "dist_reverse_cost" # kolumn i nvdb_noded med omv√§nd kostnad
  
  # # l√§s in pendlingsdata
  # tabell_pend_relation <- read_csv(tabell_pend_relation, locale = locale(encoding = "ISO-8859-1"))%>%
  #   mutate(
  #     from_id = substr(from_id, 3, 11), # tar bort l√§nskoden och t√§tortsnamnet fr√•n t.ex. 202084TC101 Avesta
  #     to_id = substr(to_id, 3, 11)      # tar bort l√§nskoden och t√§tortsnamnet fr√•n t.ex. 202080TC108 Falun
  #   ) %>% 
  #   select(from_id, to_id, n)
  # 
  if (!all(c("from_id", "to_id", "n") %in% colnames(tabell_pend_relation))) { # tabell_pend_relation_ruta m√•ste inneh√•lla dessa kolumner
    stop("`tabell_pend_relation` must contain the columns: 'from_id', 'to_id', 'n'.") # felmeddelande om inte dessa kolumner finns i tabell_pend_relation_ruta
  }
  
  # dbWriteTable(con, 'grafer.data', data, overwrite=TRUE, temporary=FALSE) # denna skriv till grafer.grafer.data !!
  dbWriteTable(con, 'data', tabell_pend_relation, overwrite=TRUE, temporary=FALSE) # skriver till grafer.data s√•ledes schema grafer √§ndra till TEMP
  
  
  # hitta n√§rmaste vertex i v√§gn√§tet till varje t√§tort
  query <- str_glue("CREATE TEMP TABLE tatort_vertex AS
                      SELECT t.tokod, e.id, e.dist
                      FROM tatort t
                      JOIN lateral(
                        SELECT id, e.geom <-> t.geom as dist
                          FROM {nod_tabell} e
                        ORDER BY t.geom <-> e.geom
                        LIMIT 1
                      ) AS e
                      ON true
                      WHERE dist < {dist};")
  dbExecute(con, "DROP TABLE IF EXISTS tatort_vertex;")
  dbExecute(con, query)
  
  # skapa tabell med relationer f√∂r routing
  query <- ("CREATE TEMP TABLE combinations AS
            SELECT c.*, t.id AS start_vid, f.id AS end_vid 
            FROM data c
            JOIN tatort_vertex t ON c.from_id = t.tokod
            JOIN tatort_vertex f ON c.to_id = f.tokod
            WHERE c.from_id <> c.to_id;")
  dbExecute(con, "DROP TABLE IF EXISTS combinations;")
  dbExecute(con, query)
  
  # k√∂r routing och samla ihop resultatet
  query <- str_glue("WITH astar AS( 
                      SELECT * FROM pgr_aStar(
                        'SELECT id, source, target, 
                                {kost_kol} AS cost, 
                                {omvand_kost_kol} AS reverse_cost,
                                x1, y1, x2, y2
                    	  FROM {kant_tabell}',
                        'SELECT 
                          start_vid AS source,
                          end_vid AS target
                        FROM combinations'
                      )
                    ), edges AS(
                      SELECT edge as edge_id, sum(n) AS antal_pend
                      FROM astar a 
                      JOIN combinations d ON a.start_vid = d.start_vid
                                  AND a.end_vid = d.end_vid
                      WHERE edge <> -1
                      GROUP BY edge
                    )
                    SELECT * 
                    FROM edges e
                      JOIN {kant_tabell} r ON e.edge_id = r.id;")
  
  natverk <- st_read(con, query = query)
  
  # Check if output is to a geopackage or as R object
  if (skriv_till_gpkg) {
    # Write to geopackage
    output_path <- file.path(ut_mapp, gpkg_namn)
    st_write(natverk, output_path, delete_dsn = TRUE)
    message(glue("Results written to {output_path}"))
  } else {
    # Return the natverk as an R object
    return(natverk)
  }
}


# Exempel p√• anv√§ndning:
# natverk <- pendling_natverk(tabell_pend_relation = tabell_pend_relation, skriv_till_gpkg = FALSE)
# #
# # # Load necessary library
# # library(mapview)
# 
# # Define a custom color palette
# custom_colors <- colorRampPalette(c("lightblue", "blue", "lightgreen", "green", "yellow", "orange", "red", "darkred"))
# 
# # Apply the mapview with custom colors
# mapview::mapview(
#   natverk,
#   zcol = "antal_pend",           # Column to control the color gradient
#   lwd = "antal_pend",            # Column to control line width
#   alpha = 0.5,                   # Transparency
#   color = custom_colors    # Apply the custom color palette
# )



# ------------------- in och utpendling p√• ruta -------------------------

# funktionen √§r skapad av Henrik Ald√©n fr√•n SWECOS skript G:/skript/gis/sweco_dec_2022/orginalskript/del3_rut_pendling.r

# tv√• versioner av skriptet finns som argument. Postgis versionen √§r snabbare vid stora dataset

# testa med system.time() f√∂r att j√§mf√∂ra exekveringstid p√• r och pg

# skriptet funkar med vector-data, allts√• punkter, linjer och (s√•ledes inte endast med) polygoner

# exempel p√• polygoner
# polygon <- hamta_karta(karttyp = "deso", regionkoder = 2085) %>%
#   group_by(kommun) %>%
#   summarise(geometry = st_union(geometry))

# polygon <- st_read("G:/skript/gis/sweco_dec_2022/godtycklig_polygon_test.gpkg")
# 
# polygon <- st_read("G:/skript/gis/sweco_dec_2022/mora_lassarett_test.gpkg")
# 

# h√§mta pendlingsdata fr√•n sekretessdatabasen
# tabell_pend_relation_ruta <- postgis_postgistabell_till_sf(
#   schema = "rutor",
#   tabell = "pend_relation_rutor_1000m",
#   con = uppkoppling_db(service = "rd_geodata", db_name = "sekretess")
# )

# rutor <- postgis_postgistabell_till_sf(
#   schema = "rutor",
#   tabell = "dag_natt_bef_rutor_1000m",
#   con = uppkoppling_db(service = "rd_geodata", db_name = "sekretess")
# )

pendling_ruta <- function(version = c("PostGIS", "R"), # M√•ste v√§lja mellan PostGIS och R
                          con = NA, # Om PostGIS, kr√§vs en connection
                          tabell_pend_relation_ruta, # Dataframe med pendlingsrelationer
                          rutor, # Grid
                          polygon,  # l√§gg till valfritt sf_objekt med geometri; punkt, linje eller polygon
                          ut_mapp = NA, # Optional output folder
                          grid_epsg = 3006, # Optional EPSG code for the grid
                          skriv_till_gpkg = FALSE, # Optional flag to write to GeoPackage
                          gpkg_namn = NA) # Optional name for GeoPackage file
{
  
  # Load necessary libraries
  library(stringr)
  library(dplyr)
  library(sf)
  library(DBI)
  library(RPostgres)
  
  #source("https://raw.githubusercontent.com/Region-Dalarna/funktioner/main/func_GIS.R", encoding = "utf-8", echo = FALSE)
  
  # Validate arguments
  version <- match.arg(version, choices = c("R", "PostGIS")) # verkar vara antingen eller!!
  
  
  
  # Error handling: check required inputs
  if (!inherits(rutor, "sf")) stop("`rutor` must be an sf object.") # rutor m√•ste vara sf object
  if (!inherits(polygon, "sf")) stop("`polygon` must be an sf object.") # polygon m√•ste vara sf object
  if (!all(c("boruta", "arbruta", "antalpend") %in% colnames(tabell_pend_relation_ruta))) { # tabell_pend_relation_ruta m√•ste inneh√•lla dessa kolumner
    stop("`tabell_pend_relation_ruta` must contain the columns: 'boruta', 'arbruta', 'antalpend'.") # felmeddelande om inte dessa kolumner finns i tabell_pend_relation_ruta
  }
  
  if (is.na(con)) {
    if (exists("uppkoppling_db")) {
      con <- uppkoppling_db(service = "rd_geodata")
    } else {
      stop("No connection provided and `uppkoppling_db` is not available. Please specify a valid connection.")
    }
  }
  
  if (version == "PostGIS" && (is.null(con) || !inherits(con, "PqConnection"))) {
    stop("For PostGIS version, a valid `con` database connection must be provided.")
  }
  
  if (!dbIsValid(con)) {
    stop("Database connection is not valid. Please check your connection settings.")
  }
  
  
  # Set default values for optional parameters
  if (is.na(ut_mapp)) {
    ut_mapp <- "G:/skript/gis/sweco_dec_2022/utdata"
  }
  if (is.na(gpkg_namn)) {
    gpkg_namn <- "pendling_ruta.gpkg"
  }
  
  # Ensure CRS consistency
  if (st_crs(polygon) != st_crs(rutor)) {
    polygon <- st_transform(polygon, st_crs(rutor))
  }
  
  # Intersect polygonen med rutor
  vald_polygon <- st_intersection(rutor, polygon)
  
  if (nrow(vald_polygon) == 0) stop("Ingen intersection mellan polygon och rutor.")
  
  # Branch based on the utvalda_rutor version
  if (version == "PostGIS") {
    dbWriteTable(con, "ruta", rutor, overwrite = TRUE, temporary = TRUE)
    dbWriteTable(con, "rutpendling", tabell_pend_relation_ruta, overwrite = TRUE, temporary = TRUE)
    
    utvalda_rutor <- st_read(con, layer = "ruta") %>% st_filter(vald_polygon)
    utvalda_rutor_ids <- paste(utvalda_rutor$rut_id, collapse = ", ")
    
    # In-commuting
    query <- str_glue("WITH commuters_in AS (
                      SELECT
                        boruta, 
                        sum(antalpend) AS total
                      FROM rutpendling
                      WHERE arbruta::BIGINT IN ({utvalda_rutor_ids}) 
                        AND boruta::BIGINT NOT IN ({utvalda_rutor_ids}) 
                      GROUP BY boruta
                      ) 
                        SELECT c.*, r.geom 
                        FROM commuters_in c 
                          JOIN ruta r ON c.boruta = r.rut_id")
    in_pendling <- st_read(con, query = query)
    
    # Out-commuting
    query <- str_glue("WITH commuters_out AS (
                      SELECT
                        arbruta,
                        sum(antalpend) AS total
                      FROM rutpendling
                      WHERE boruta::BIGINT IN ({utvalda_rutor_ids})
                        AND arbruta::BIGINT NOT IN ({utvalda_rutor_ids}) 
                      GROUP BY arbruta
                      )
                      SELECT c.*, r.geom 
                      FROM commuters_out c 
                        JOIN ruta r ON c.arbruta = r.rut_id")
    ut_pendling <- st_read(con, query = query)
    
    if (skriv_till_gpkg) {
      st_write(utvalda_rutor, file.path(ut_mapp, "rut_pendling_pg.gpkg"), "omr√•de", delete_dsn = TRUE, append = FALSE)
      st_write(in_pendling, file.path(ut_mapp, "rut_pendling_pg.gpkg"), "in_pend", append = FALSE)
      st_write(ut_pendling, file.path(ut_mapp, "rut_pendling_pg.gpkg"), "ut_pend", append = FALSE)
    }
    
    return(list("utvalda_rutor" = utvalda_rutor, "in_pendling" = in_pendling, "ut_pendling" = ut_pendling))
    
  } else if (version == "R") {
    utvalda_rutor <- st_filter(rutor, vald_polygon)
    
    # Define helper functions
    pendlare_fran_utvalda_rutor <- function(pendlings_data) {
      pendlings_data %>%
        group_by(boruta) %>%
        summarise(pendlare_fran = sum(antalpend))
    }
    pendlare_till_utvalda_rutor <- function(pendlings_data) {
      pendlings_data %>%
        group_by(arbruta) %>%
        summarise(pendlare_till = sum(antalpend))
    }
    filter_med_utvalda_rutor <- function(pendlings_data, utvalda_rutor) {
      fran_utvalda_rutor <- filter(pendlings_data,
                                   (boruta %in% utvalda_rutor$rut_id) &
                                     !(arbruta %in% utvalda_rutor$rut_id))
      till_utvalda_rutor <- filter(pendlings_data,
                                   (arbruta %in% utvalda_rutor$rut_id) &
                                     !(boruta %in% utvalda_rutor$rut_id))
      list("fran_utvalda_rutor" = fran_utvalda_rutor, "till_utvalda_rutor" = till_utvalda_rutor)
    }
    
    data <- filter_med_utvalda_rutor(tabell_pend_relation_ruta, utvalda_rutor)
    from_c <- pendlare_fran_utvalda_rutor(data$till_utvalda_rutor)
    to_c <- pendlare_till_utvalda_rutor(data$fran_utvalda_rutor)
    
    full_table <- full_join(from_c, to_c, by = c("boruta" = "arbruta")) %>%
      rename("rut_id" = "boruta")
    result <- merge(rutor, full_table, by = "rut_id")
    
    in_pendling <- filter(result, !is.na(pendlare_fran)) %>% dplyr::select(-pendlare_till)
    ut_pendling <- filter(result, !is.na(pendlare_till)) %>% dplyr::select(-pendlare_fran)
    
    if (skriv_till_gpkg) {
      st_write(utvalda_rutor, file.path(ut_mapp, "rut_pendlingR.gpkg"), "omr√•de", delete_dsn = TRUE, append = FALSE)
      st_write(in_pendling, file.path(ut_mapp, "rut_pendlingR.gpkg"), "in_pend", append = FALSE)
      st_write(ut_pendling, file.path(ut_mapp, "rut_pendlingR.gpkg"), "ut_pend", append = FALSE)
    }
    
    return(list(
      "utvalda_rutor" = if (exists("utvalda_rutor") && nrow(utvalda_rutor) > 0) utvalda_rutor else NULL,
      "in_pendling" = if (exists("in_pendling") && nrow(in_pendling) > 0) in_pendling else NULL,
      "ut_pendling" = if (exists("ut_pendling") && nrow(ut_pendling) > 0) ut_pendling else NULL
    ))
  }
}

# ================================= √ñvriga funktioner ================================================


adresser_inv_reg_folke_bearbeta <- function(skickad_df) {
  
  #Lagt till "," i vektorn f√∂r tecken att ta bort /leomik 20240314
  ta_bort_vekt <- c(" nb", " bv", " uv", " 1tr", " 1 tr", ",1tr", ", 1 tr", " 2 tr", " 2tr", " v√•n1", " v√•n 1", 
                    " v√•n2", " v√•n 2", " v√•n3", " v√•n 3", " 3tr", " 3 tr", " 4tr", " 4 tr", " v√•n0", " v√•n 0",
                    " 6tr", " 6 tr", " 1/2tr", " 1/2 tr", " 2:a", " lgh", " l√§g", ",")
  
  ta_bort_vekt_or = paste0(ta_bort_vekt, collapse="|")                   # vi l√§gger hela ta_bort_vekt som en or-sats med samtliga element
  
  # h√§r st√§dar vi lite men √§ndrar inte originalkolumnerna utan l√§gger till adress_join som √§r den adress vi joinar p√• samt √§ven postnr_join som vi ocks√• joinar p√•
  #inv_adresser_df <- if (str_sub(filsokvag, nchar(filsokvag)-2, nchar(filsokvag)) == "csv") fread(filsokvag) else read_xlsx(filsokvag)
  inv_adresser_df <- skickad_df %>% 
    mutate(adress_join = adress %>% tolower(),                              # g√∂r om alla till gemener, s√• slipper vi fel f√∂r att man k√∂r med olika gemener och versaler
           adress_join = adress_join %>% str_replace("(?<=[a-z])(?=\\d)", " "),                      # l√§gg till ett mellanslag mellan bokst√§ver och siffror som sitter ihop
           adress_join = adress_join %>% str_replace("(?<=\\d)(?=[a-z])", " "),                     # l√§gg till ett mellanslag mellan siffror och bokst√§ver som sitter ihop
           adress_join = adress_join %>% str_squish(),
           ta_bort_pos = str_locate(adress_join, ta_bort_vekt_or)[,1] - 1,                            # f√∂rst hittar vi postition f√∂r en tr√§ff med n√•gon av elementen i ta_bort_vekt, och tar minus 1 f√∂r att hitta slutet p√• det vi vill beh√•lla (allts√• allt fr√•n och med ta bort-m√∂nstret och till h√∂ger ska bort)
           adress_join = ifelse(!is.na(ta_bort_pos), str_sub(adress_join, 1, ta_bort_pos), adress_join)
           # ,
           # uttags_datum = uttags_datum
    ) %>%      # d√§refter tar vi bort allt fr√•n s√∂kstr√§ngen och till h√∂ger med str_sub och med ta_bort_pos som vi skapade ovan
    select(-ta_bort_pos)
  
  return(inv_adresser_df)
  
} # slut funktion

library(sf)
library(dplyr)

# Funktion som skapar eller fyller p√• ett sf-objekt
skapa_punkt_sf_av_koordinatpar <- function(koordinater, malpunktsnamn, sf_obj = NULL, vald_crs = 4326) {
  # Kontrollera att antalet koordinater matchar antalet m√•lpunktsnamn
  if (length(koordinater) != length(malpunktsnamn)) {
    stop("Antalet koordinater m√•ste vara samma som antalet m√•lpunktsnamn.")
  }
  
  # Skapa en dataram fr√•n koordinater och namn
  malpunkter_df <- data.frame(
    id = seq_len(length(koordinater)),
    malpunkt_namn = malpunktsnamn,
    stringsAsFactors = FALSE
  )
  
  # Extrahera latitud och longitud fr√•n koordinater
  koordinat_matrix <- purrr::map(koordinater, ~ as.numeric(strsplit(.x, ",\\s*")[[1]])) %>% 
    do.call(rbind, .)
  
  # L√§gg till latitud och longitud i dataramen
  malpunkter_df$lat <- koordinat_matrix[, 1]
  malpunkter_df$lon <- koordinat_matrix[, 2]
  
  # Konvertera till sf-objekt med CRS WGS84 (EPSG:4326)
  malpunkter_sf <- st_as_sf(malpunkter_df, coords = c("lon", "lat"), crs = vald_crs)
  
  # Om ett sf-objekt skickas med, fyll p√• det, annars returnera det nya
  if (!is.null(sf_obj)) {
    if (!inherits(sf_obj, "sf")) {
      stop("Det medskickade objektet m√•ste vara ett sf-objekt.")
    }
    return(bind_rows(sf_obj, malpunkter_sf))
  } else {
    return(malpunkter_sf)
  }
}


gdb_extrahera_kolumnnamn_per_gislager <- function(gdb_sokvag,
                                                  tabort_paranteser = TRUE,
                                                  byt_ut_slash_mot_understreck = TRUE,
                                                  byt_ut_mellanslag_mot_understreck = TRUE,
                                                  enbart_gemener = TRUE,
                                                  byt_ut_svenska_tecken = TRUE,
                                                  nytt_namn_id_kol = "nvdb_id",         # NA = beh√•ll gamla, annat v√§rde blir namnet p√• kolumnen
                                                  nytt_namn_geo_kol = "geom"
) {
  
  # En funktion f√∂r att extrahera kolumnnamn ur de gis-lager som finns i en .gdb-fil, 
  # dvs. en ESRI Geodatabase vilket √§r det format som Trafikverket levererar sina 
  # homogeniserade lager i. Och eftersom st_read() trunkerar kolumnnamn s√• kan man med
  # denna funktion extrahera vettiga kolumnnamn i en namnsatt vektor som kan anv√§ndas till 
  # att d√∂pa om ett sf-objekt som l√§sts in fr√•n ESRI Geodatabase.
  
  # definiera en funktion som anv√§nds nedan
  hitta_ogrinfo <- function() {
    program_files <- Sys.getenv("ProgramFiles")
    
    # Lista kataloger under Program Files och filtrera p√• de som b√∂rjar med QGIS
    qgis_dirs <- list.dirs(program_files, recursive = FALSE) %>%
      keep(~ str_starts(basename(.x), "QGIS"))
    
    # Kontrollera varje QGIS-katalog om ogrinfo.exe finns i bin-mappen
    ogrinfo_path <- qgis_dirs %>%
      map(~ file.path(.x, "bin", "ogrinfo.exe")) %>%
      #keep(file.exists()) %>%
      first()
    
    # Returnera s√∂kv√§g eller NULL om ingen fil hittades
    ogrinfo_path %||% NULL
  } # slut funktion
  
  # Vi kollar om ogrinfo.exe finns tillg√§ngligt och om inte tittar vi efter
  # QGIS och om ogrinfo.exe finns d√§r, hittas den inte d√§r stoppas funktionen
  if (Sys.which("ogrinfo") == "") {
    
    ogr_sokvag <- hitta_ogrinfo()
    if (is.null(hitta_ogrinfo())) stop("GDAL-programvaran ogrinfo.exe kr√§vs f√∂r att k√∂ra denna funktion. Installera programvaran om du vill anv√§nda funktionen.")  
  } else ogr_sokvag <- "ogrinfo"
  
  
  # Steg 1: H√§mta namnet p√• alla gis-lager som finns i geodatabasen
  alla_lager_i_gdb <- st_layers(gdb_sokvag)$name
  
  #  Steg 2: Extrahera kolumnnamn f√∂r alla lager och l√§gg i en lista
  lager_kolumnnamn_lista <- map(alla_lager_i_gdb, function(lager_namn) {
    kolumner_namn <- system(glue('"{ogr_sokvag}" {gdb_sokvag} {lager_namn} -so'), intern = TRUE)
    id_kol <- str_extract(str_subset(kolumner_namn, "FID Column"), "(?<= = ).*") # extrahera namn p√• id_kolumn
    geo_kol <- str_extract(str_subset(kolumner_namn, "Geometry Column"), "(?<= = ).*") # extrahera namn p√• geo-kolumn
    
    # hitta startelement f√∂r d√§r kolumnnamnen finns
    kolumner_start <- str_which(kolumner_namn, "Geometry Column = ") + 1
    kolumner_namn <- kolumner_namn[kolumner_start:length(kolumner_namn)]
    kolumner_namn <- c(paste0(id_kol, ":"), kolumner_namn, paste0(geo_kol, ":"))
    
    kolumnnamn_ny <- set_names(
      map_chr(kolumner_namn, ~ {
        old_name <- str_extract(.x, "^[^:]+")
        new_name <- str_extract(.x, 'alternative name=\\"([^"]+)\\"') %>%
          str_replace_all('\\"', "") %>%
          str_remove("alternative name=") %>%
          str_trim()
        
        retur_vekt <- ifelse(is.na(new_name), old_name, new_name)
        
        # korrigera utifr√•n parametrar i funktionen
        retur_vekt <- retur_vekt %>%
          { if (tabort_paranteser) str_remove_all(., "\\(|\\)") %>% str_trim() else . } %>%
          { if (byt_ut_slash_mot_understreck) str_replace_all(., "/", "_") else . } %>%
          { if (byt_ut_mellanslag_mot_understreck) str_replace_all(., " ", "_") else . } %>%
          { if (enbart_gemener) tolower(.) else . } %>%
          { if (byt_ut_svenska_tecken) svenska_tecken_byt_ut(.) else . }
        retur_vekt
      }),
      map_chr(kolumner_namn, ~ str_extract(.x, "^[^:]+"))
    )
    
    # √Ñndra kolumnnamn f√∂r id-kolumn om anv√§ndaren valt det
    if (!is.null(id_kol) && !is.na(id_kol) && !is.na(nytt_namn_id_kol)) {
      kolumnnamn_ny[id_kol] <- nytt_namn_id_kol
    }
    
    # √Ñndra kolumnnamn f√∂r geo-kolumn om anv√§ndaren valt det
    if (!is.null(geo_kol) && !is.na(geo_kol) && !is.na(nytt_namn_geo_kol)) {
      kolumnnamn_ny[geo_kol] <- nytt_namn_geo_kol
    }
    
    return(kolumnnamn_ny)
  })
  
  # d√∂p alla element efter vad dess gis-lager heter
  names(lager_kolumnnamn_lista) <- alla_lager_i_gdb
  
  # Returnera resultatet
  return(lager_kolumnnamn_lista)
}

raster_till_vektor <- function(
    rasterlager,
    vardekolumn,                           # h√§r anges namnet p√• kolumnen som inneh√•ller v√§rdet
    filtrera_bort_na = TRUE,
    behall_varden_over = 0                # st√∂rre √§n detta tal beh√•lls, NA = ingen filtrering
) {
  
  rasterlager <- rasterlager %>% 
    NAflag()
  
  rutor_rast_mask <- mask(rutor_rast, rutor_rast, maskvalues=NA)
  
  rutor_sf <- as.polygons(rutor_rast, dissolve=FALSE, na.rm=filtrera_bort_na) %>% 
    st_as_sf() %>% 
    rename(varde = 1) 
  
  
  if (!is.na(behall_varden_over)) {
    rutor_sf <- rutor_sf %>% 
      filter(varde > behall_varden_over)
  }
  
  return(rutor_sf)
  
}
